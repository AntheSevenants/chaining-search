{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chaining search\n",
    "\n",
    "\n",
    "\n",
    "## Sphinx documentatie: https://pythonhosted.org/an_example_pypi_project/sphinx.html\n",
    "## in voorbeelden handige python functies opnemen\n",
    "## zoals ; .sort_values(ascending=False,by=['raw_freq']));  list enz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library functions: Search\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T14:39:41.904717Z",
     "start_time": "2019-01-22T14:39:41.899150Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Args:\n",
    "    df: Pandas DataFrame to filter on\n",
    "    df: column on which we filter\n",
    "    method: \"regex\" of \"isin\"\n",
    "    regex_or_set: Regular expression (if method==\"regex\") or set (if method==\"isin\")\n",
    "'''\n",
    "\n",
    "def filter_df(df, column, method, regex_or_set):\n",
    "    if method==\"regex\":\n",
    "        filter_condition = df[column].str.contains(regex_or_set)\n",
    "    elif method==\"isin\":\n",
    "        filter_condition = df[column].isin(regex_or_set)\n",
    "    else:\n",
    "        raise ValueError(\"method should be one of regex or isin\")\n",
    "    return df[filter_condition]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T14:35:31.937772Z",
     "start_time": "2019-01-22T14:35:31.893616Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "import urllib\n",
    "#import wx   # for interaction popups          TODO -> omzetten naar JS of zo\n",
    "import itertools # for frequency list function\n",
    "import numpy     # idem\n",
    "from IPython.display import FileLink, FileLinks\n",
    "AVAILABLE_CORPORA = ['chn', 'opensonar', 'zeebrieven', 'gysseling', 'nederlab']\n",
    "RECORDS_PER_PAGE = 1000\n",
    "\n",
    "# Get rid of ellipsis in display (otherwise relevant data might not be shown)\n",
    "pd.set_option('display.max_colwidth',1000)\n",
    "\n",
    "# Search methods\n",
    "\n",
    "def search_corpus_allwords(corpus, pos):\n",
    "    query = r'[word=\".*\"]'\n",
    "    if pos is not None:\n",
    "        query = r'[word=\".*\" & pos=\"'+pos+r'\"]'\n",
    "    return search_corpus(query, corpus)\n",
    "\n",
    "def search_corpus_alllemmata(corpus, pos):\n",
    "    query = r'[lemma=\".*\"]'\n",
    "    if pos is not None:\n",
    "        query = r'[lemma=\".*\" & pos=\"'+pos+r'\"]'\n",
    "    return search_corpus(query, corpus) \n",
    "\n",
    "def search_corpus(query, corpus, start_position=1, hits_only=True):\n",
    "    # show wait indicator\n",
    "    #app = wx.App()\n",
    "    #msg_to_user = wx.BusyInfo('Searching '+corpus+' corpus')\n",
    "    if corpus not in AVAILABLE_CORPORA:\n",
    "        raise ValueError(\"Unknown corpus: \" + corpus)\n",
    "    try:\n",
    "        # Do request to federated content search corpora, so we get same output format for every corpus\n",
    "        url = \"http://portal.clarin.inl.nl/fcscorpora/clariah-fcs-endpoints/sru?operation=searchRetrieve&queryType=fcs&maximumRecords=1000&x-fcs-context=\" + corpus + \"&query=\" + urllib.parse.quote(query)\n",
    "        print(url)\n",
    "        response = requests.get(url)\n",
    "        response_text = response.text    \n",
    "        df, next_page = _parse_xml(response_text, hits_only)\n",
    "        # If there are next pages, call search_corpus recursively\n",
    "        print(next_page)\n",
    "        if next_page > 0:\n",
    "            df_more = search_corpus(query, corpus, next_page, hits_only)\n",
    "            df = df.append(df_more, ignore_index=True)\n",
    "        # show message out of xml, if some error has occured (prevents empty output)\n",
    "        _show_error_if_any(response_text)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise ValueError(\"An error occured when searching corpus \" + corpus + \": \"+ str(e))\n",
    "    #finally:\n",
    "    #    # remove wait indicator, and return dataframe\n",
    "    #    del msg_to_user        \n",
    "\n",
    "def search_corpus_multiple(queries, corpus):\n",
    "    result_dict = {}\n",
    "    for query in queries:\n",
    "        result_dict[query] = search_corpus(query,corpus)\n",
    "    return result_dict\n",
    "   \n",
    "\n",
    "def search_lexicon_alllemmata(lexicon, pos):\n",
    "    query = lexicon_query_alllemmata(lexicon, pos)\n",
    "    return search_lexicon(query, lexicon)\n",
    "\n",
    "def search_lexicon(query, lexicon):\n",
    "     # show wait indicator, so the user knows what's happening\n",
    "    #app = wx.App()\n",
    "    #msg_to_user = wx.BusyInfo('Searching '+lexicon+' lexicon')\n",
    "    # default endpoint, except when diamant is invoked\n",
    "    endpoint = \"http://172.16.4.56:8890/sparql\"\n",
    "    if (lexicon==\"diamant\"):\n",
    "        endpoint = \"http://svprre02:8080/fuseki/tdb/sparql\"\n",
    "    \n",
    "    try:\n",
    "        # Accept header is needed for virtuoso, it isn't otherwise!\n",
    "        response = requests.post(endpoint, data={\"query\":query}, headers = {\"Accept\":\"application/sparql-results+json\"})\n",
    "        \n",
    "        response_json = json.loads(response.text)\n",
    "        records_json = response_json[\"results\"][\"bindings\"]\n",
    "        records_string = json.dumps(records_json)    \n",
    "        df = pd.read_json(records_string, orient=\"records\")\n",
    "    \n",
    "        # make sure cells containing NULL are added too, otherwise we'll end up with ill-formed data\n",
    "        # TODO: maybe this can be replaced by:\n",
    "        # df = df.fillna('')\n",
    "        df = df.applymap(lambda x: '' if pd.isnull(x) else x[\"value\"])         \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise ValueError(\"An error occured when searching lexicon \" + lexicon + \": \"+ str(e))\n",
    "    #finally:\n",
    "    #    # remove wait indicator, \n",
    "    #    del msg_to_user\n",
    "        \n",
    "\n",
    "# Processing methods\n",
    "\n",
    "def column_difference(df_column1, df_column2):\n",
    "    set_df1 = set(df_column1)\n",
    "    set_df2 = set(df_column2)\n",
    "    diff_left = set_df1.difference(set_df2)\n",
    "    diff_right = set_df2.difference(set_df1)\n",
    "    intersec = set_df1.intersection(set_df2)\n",
    "    return diff_left, diff_right, intersec\n",
    "\n",
    "def diamant_get_synonyms(df):\n",
    "    # Depending on the result type, we return the lemma or the definition text\n",
    "    lemmas = set(df[df[\"inputMode\"]==\"defText\"][\"n_ontolex_writtenRep\"])\n",
    "    defTexts = set(df[df[\"inputMode\"]==\"lemma\"][\"n_syndef_definitionText\"])\n",
    "    return lemmas|defTexts\n",
    "\n",
    "def _parse_xml(text, hits_only=True):\n",
    "    \n",
    "    # if hits_only=True, we'll only fetch info about the hits\n",
    "    # if hits_only=False, we'll fetch info about all the words\n",
    "    \n",
    "    # TODO: should we secure against untrusted XML?\n",
    "    root = ET.fromstring(text)\n",
    "    records = []\n",
    "    n_words_in_hit = 0\n",
    "    computed_nwih = False\n",
    "    layers_processed = 0\n",
    "    \n",
    "    for entry in root.iter(\"{http://clarin.eu/fcs/resource}ResourceFragment\"):    \n",
    "        \n",
    "        for dataView in entry.findall(\"{http://clarin.eu/fcs/resource}DataView\"):            \n",
    "            \n",
    "            # ----- [part 1] ----- \n",
    "            # in 'hits only' mode, we'll gather the hits, otherwise we'll gather all the words of the sentences\n",
    "            \n",
    "            # We only take into account hits, ignore metadata and segmenting dataViews\n",
    "            if (hits_only is True and dataView.get(\"type\")==\"application/x-clarin-fcs-hits+xml\"):\n",
    "                layers_processed = layers_processed + 1\n",
    "                result = dataView.find(\"{http://clarin.eu/fcs/dataview/hits}Result\")\n",
    "                left_context = result.text if result.text is not None else ''\n",
    "                hits = list(result)\n",
    "                if len(hits)==0:\n",
    "                    print([w for w in result.itertext()])\n",
    "                    print(\"no hit in kwic, skip\")\n",
    "                    continue\n",
    "                last_hit = hits[-1]\n",
    "                right_context = last_hit.tail if last_hit.tail is not None else ''\n",
    "                hit_words = [hit.text for hit in hits]\n",
    "                \n",
    "                if not computed_nwih:\n",
    "                    n_words_in_hit = len(hits)\n",
    "                    computed_nwih=True\n",
    "            \n",
    "            # Get each word\n",
    "            if ( hits_only is False and dataView.get(\"type\")==\"application/x-clarin-fcs-adv+xml\"):\n",
    "                layers_processed = layers_processed + 1             \n",
    "                for layer in dataView.findall(\".//{http://clarin.eu/fcs/dataview/advanced}Layer\"):                    \n",
    "                    if (layer.get(\"id\")==\"http://www.ivdnt.org/annotation-layers/word\"):\n",
    "                        hit_words = []\n",
    "                        path = \".//{http://clarin.eu/fcs/dataview/advanced}Span\"\n",
    "                        for one_span in layer.findall(path):\n",
    "                            span_text = one_span.text            \n",
    "                            hit_words.append(span_text)\n",
    "                if not computed_nwih:\n",
    "                    n_words_in_hit = len(hit_words)\n",
    "                    computed_nwih=True\n",
    "                \n",
    "            \n",
    "            # ----- [part 2] ----- \n",
    "            # gather info about each hit (=hits only mode) or about each word (=NOT hits only mode)\n",
    "                \n",
    "            # Get lemma of each hit\n",
    "            if (dataView.get(\"type\")==\"application/x-clarin-fcs-adv+xml\"):\n",
    "                layers_processed = layers_processed + 1             \n",
    "                for layer in dataView.findall(\".//{http://clarin.eu/fcs/dataview/advanced}Layer\"):                    \n",
    "                    if (layer.get(\"id\")==\"http://www.ivdnt.org/annotation-layers/lemma\"):\n",
    "                        hit_lemmata = []\n",
    "                        path = \".//{http://clarin.eu/fcs/dataview/advanced}Span\"\n",
    "                        if (hits_only is True):\n",
    "                            path = path+\"[@highlight='h1']\" \n",
    "                        for one_span in layer.findall(path):\n",
    "                            span_text = one_span.text            \n",
    "                            hit_lemmata.append(span_text)\n",
    "                            \n",
    "            # Get pos of each hit\n",
    "            if (dataView.get(\"type\")==\"application/x-clarin-fcs-adv+xml\"):\n",
    "                layers_processed = layers_processed + 1             \n",
    "                for layer in dataView.findall(\".//{http://clarin.eu/fcs/dataview/advanced}Layer\"):                    \n",
    "                    if (layer.get(\"id\")==\"http://www.ivdnt.org/annotation-layers/universal_dependency\"):\n",
    "                        hit_pos = []\n",
    "                        path = \".//{http://clarin.eu/fcs/dataview/advanced}Span\"\n",
    "                        if (hits_only is True):\n",
    "                            path = path+\"[@highlight='h1']\" \n",
    "                        for one_span in layer.findall(path):\n",
    "                            span_text = one_span.text            \n",
    "                            hit_pos.append(span_text)\n",
    "                            \n",
    "            if layers_processed == 3:\n",
    "                if hits_only:\n",
    "                    kwic = [left_context] + hit_lemmata + hit_pos + hit_words + [right_context]\n",
    "                else:\n",
    "                    kwic = hit_lemmata + hit_pos + hit_words\n",
    "                records.append(kwic)\n",
    "                layers_processed = 0     \n",
    "                    \n",
    "    if hits_only:\n",
    "        columns = [\"left context\"] + [\"lemma \" + str(n) for n in range(n_words_in_hit)] + [\"pos \" + str(n) for n in range(n_words_in_hit)] + [\"word \" + str(n) for n in range(n_words_in_hit)] + [\"right context\"]\n",
    "    else:\n",
    "        columns = [\"lemma \" + str(n) for n in range(n_words_in_hit)] + [\"pos \" + str(n) for n in range(n_words_in_hit)] + [\"word \" + str(n) for n in range(n_words_in_hit)]\n",
    "    \n",
    "    next_pos = 0\n",
    "    next_record_position = root.find(\"{http://docs.oasis-open.org/ns/search-ws/sruResponse}nextRecordPosition\")\n",
    "    if (next_record_position is not None):\n",
    "        next_pos = int(next_record_position.text)\n",
    "        \n",
    "    return pd.DataFrame(records, columns = columns), next_pos\n",
    "\n",
    "def _show_error_if_any(text):\n",
    "    # get error message out of xml and print it on screen\n",
    "    root = ET.fromstring(text)\n",
    "    msgs = []\n",
    "    for diagnostic in root.iter(\"{http://docs.oasis-open.org/ns/search-ws/diagnostic}diagnostic\"):\n",
    "        for msg in diagnostic.findall(\"{http://docs.oasis-open.org/ns/search-ws/diagnostic}message\"):\n",
    "            msg_text = msg.text if msg.text is not None else ''\n",
    "            msgs.append(msg_text)\n",
    "    if len(msgs) > 0:\n",
    "        print(\"; \".join(msgs))\n",
    "\n",
    "# View methods\n",
    "\n",
    "# results: dict of df's\n",
    "# labels: list of label corresponding to the df's in results\n",
    "def view_multiple_results(results, labels):\n",
    "    assert len(labels)==len(results)\n",
    "    for n,query in enumerate(results):\n",
    "        df = results[query]\n",
    "        if not df.empty:\n",
    "            display(HTML('Resultaten voor <b>' + labels[n] + \"</b>:\"))\n",
    "            display(df)\n",
    "            \n",
    "            \n",
    "            \n",
    "def get_frequency_list(lexicon, pos, corpus):\n",
    "    \n",
    "    # LEXICON: get a lemmata list to work with\n",
    "    df_lexicon = search_lexicon_alllemmata(lexicon, pos)\n",
    "    lexicon_lemmata_set = sorted( set([w.lower() for w in df_lexicon[\"writtenForm\"]]) )\n",
    "    lexicon_lemmata_arr= numpy.array(lexicon_lemmata_set)\n",
    "\n",
    "    # instantiate a dataframe for storing lemmata and frequencies\n",
    "    df_frequency_list = pd.DataFrame(index=lexicon_lemmata_arr, columns=['raw_freq'])\n",
    "    df_frequency_list.index.name = 'lemmata'\n",
    "\n",
    "    # CORPUS: loop through lemmata list, query the corpus with that lemma, and count the results\n",
    "\n",
    "    # It's a good idea to work with more than one lemma at once!\n",
    "    nr_of_lemmata_to_query_atonce = 100\n",
    "    \n",
    "    # loop over lemmata list \n",
    "    for i in range(0, len(lexicon_lemmata_set), nr_of_lemmata_to_query_atonce):\n",
    "        # slice to small sets of lemmata to query at once\n",
    "        small_lemmata_set = set( lexicon_lemmata_arr[i : i+nr_of_lemmata_to_query_atonce] )    \n",
    "\n",
    "        # join set of lemmata to send them in a query all at once\n",
    "        # beware: single quotes need escaping\n",
    "        lemmata_list = \"|\".join(small_lemmata_set).replace(\"'\", \"\\\\\\\\'\")\n",
    "        df_corpus = search_corpus(r'[lemma=\"' + lemmata_list + r'\"]', corpus)\n",
    "\n",
    "        # store frequencies\n",
    "        if (len(df_corpus)>0):\n",
    "            for one_lemma in small_lemmata_set: \n",
    "                raw_freq = len(df_corpus[df_corpus['lemma 0'] == one_lemma])\n",
    "                df_frequency_list.at[one_lemma, 'raw_freq'] = raw_freq \n",
    "                \n",
    "    # final step: compute rank\n",
    "    # this is needed to be able to compare different frequency lists \n",
    "    # with each other (which we could achieve by computing a rank diff)\n",
    "    df_frequency_list['rank'] = df_frequency_list['raw_freq'].rank(ascending = False).astype(int)\n",
    "    \n",
    "    return df_frequency_list;\n",
    "\n",
    "\n",
    "def get_missing_wordforms(lexicon, pos, corpus):\n",
    "    \n",
    "    # LEXICON: get a lemmata list to work with\n",
    "    df_lexicon = search_lexicon_alllemmata(lexicon, pos)\n",
    "    lexicon_lemmata_set = sorted( set([w.lower() for w in df_lexicon[\"writtenForm\"]]) )\n",
    "    lexicon_lemmata_arr= numpy.array(lexicon_lemmata_set)\n",
    "    \n",
    "    # instantiate a dataframe for storing lemmata and wordforms\n",
    "    df_enriched_lexicon = pd.DataFrame(index=lexicon_lemmata_arr, columns=['lemma', 'pos', 'known_wordforms', 'unknown_wordforms'])\n",
    "    df_enriched_lexicon.index.name = 'lemmata'\n",
    "    \n",
    "    # CORPUS: loop through lemmata list, query the corpus with that lemma, \n",
    "    # and compute difference between both\n",
    "\n",
    "    # It's a good idea to work with more than one lemma at once!\n",
    "    nr_of_lemmata_to_query_atonce = 100\n",
    "    \n",
    "    # loop over lemmata list \n",
    "    for i in range(0, len(lexicon_lemmata_set), nr_of_lemmata_to_query_atonce):\n",
    "        # slice to small sets of lemmata to query at once\n",
    "        small_lemmata_set = set( lexicon_lemmata_arr[i : i+nr_of_lemmata_to_query_atonce] )    \n",
    "        \n",
    "        # join set of lemmata to send them in a query all at once\n",
    "        # beware: single quotes need escaping\n",
    "        lemmata_list = \"|\".join(small_lemmata_set).replace(\"'\", \"\\\\\\\\'\")\n",
    "        df_corpus = search_corpus(r'[lemma=\"' + lemmata_list + r'\"]', corpus)\n",
    "        \n",
    "        # process results\n",
    "        if (len(df_corpus)>0):\n",
    "            for one_lemma in small_lemmata_set: \n",
    "                \n",
    "                # look up the known wordforms in the lexicon\n",
    "                query = lexicon_query(one_lemma, pos, lexicon)\n",
    "                df_known_wordforms = search_lexicon(query, lexicon)\n",
    "                \n",
    "                if (len(df_known_wordforms) != 0):\n",
    "                    known_wordforms = set( df_known_wordforms['wordform'].str.lower() )\n",
    "                    # find the wordforms in the corpus\n",
    "                    corpus_wordforms = set( (df_corpus[df_corpus['lemma 0'] == one_lemma])['word 0'].str.lower() )\n",
    "                    # determine which corpus wordforms are not in lexicon wordforms\n",
    "                    unknown_wordforms = corpus_wordforms.difference(known_wordforms)\n",
    "\n",
    "                    if (len(unknown_wordforms) !=0):\n",
    "                        # store the results\n",
    "                        df_enriched_lexicon.at[one_lemma, 'lemma'] = one_lemma\n",
    "                        df_enriched_lexicon.at[one_lemma, 'pos'] = pos\n",
    "                        df_enriched_lexicon.at[one_lemma, 'known_wordforms'] = known_wordforms\n",
    "                        df_enriched_lexicon.at[one_lemma, 'unknown_wordforms'] = unknown_wordforms\n",
    "                \n",
    "    # return non-empty results, t.i. cases in which we found some wordforms\n",
    "    return df_enriched_lexicon[ df_enriched_lexicon['unknown_wordforms'].notnull() ]\n",
    "        \n",
    "    \n",
    "def get_rank_diff(df1, df2):\n",
    "    \n",
    "    # find lemmata shared by both dataframes: computing ranks diffs is only possible\n",
    "    # when dealing with lemmata which are in both frames\n",
    "    lemmata_list1 = set(df1.index.tolist())\n",
    "    lemmata_list2 = set(df2.index.tolist())\n",
    "    common_lemmata_list = list( lemmata_list1.intersection(lemmata_list2) )\n",
    "    \n",
    "    # build dataframes limited to the common lemmata\n",
    "    limited_df1 = df1.loc[ common_lemmata_list , : ]\n",
    "    limited_df2 = df2.loc[ common_lemmata_list , : ]\n",
    "    \n",
    "    # recompute ranks in both dataframes, because in each frame the original ranks were\n",
    "    # computed with a lemmata list which might be larger than the lemmata list common\n",
    "    # to both dataframes\n",
    "    \n",
    "    limited_df1['rank'] = limited_df1['raw_freq'].rank(ascending = False).astype(int)\n",
    "    limited_df2['rank'] = limited_df2['raw_freq'].rank(ascending = False).astype(int)\n",
    "    \n",
    "    # instantiate a dataframe for storing lemmata and rank diffs\n",
    "    df_rankdiffs = pd.DataFrame(index=common_lemmata_list, columns=['rank_1', 'rank_2', 'rank_diff'])\n",
    "    df_rankdiffs.index.name = 'lemmata'\n",
    "    \n",
    "    df_rankdiffs['rank_1'] = limited_df1['rank']\n",
    "    df_rankdiffs['rank_2'] = limited_df2['rank']\n",
    "    df_rankdiffs['rank_diff'] = pd.DataFrame.abs( df_rankdiffs['rank_1'] - df_rankdiffs['rank_2'] )\n",
    "    \n",
    "    return df_rankdiffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library functions: UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T15:54:30.161099Z",
     "start_time": "2019-01-22T15:54:30.147834Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from pathlib import Path\n",
    "from IPython.display import Javascript\n",
    "from IPython.core.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEFAULT_QUERY = r'[lemma=\"boek\" & pos=\"verb\"]' #r'[lemma=\"boeken\" pos=\"verb\"]'\n",
    "DEFAULT_CORPUS = \"chn\"\n",
    "\n",
    "\n",
    "\n",
    "def create_corpus_ui():\n",
    "    # Create UI elements\n",
    "    corpusQueryField = widgets.Text(description=\"<b>CQL query:</b>\", value=DEFAULT_QUERY)\n",
    "    corpusField = widgets.Dropdown(\n",
    "        options=AVAILABLE_CORPORA,\n",
    "        value=DEFAULT_CORPUS,\n",
    "        description='<b>Corpus:</b>',\n",
    "    )\n",
    "    '''corpusSearchButton = widgets.Button(\n",
    "        description='Search',\n",
    "        button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "        tooltip='Search',\n",
    "    )\n",
    "    # Handle events\n",
    "    corpusSearchButton.on_click(corpus_search)'''\n",
    "    \n",
    "    # Stack UI elements in vertical box and display\n",
    "    corpusUiBox = widgets.VBox([corpusQueryField,corpusField])\n",
    "    display(corpusUiBox)\n",
    "    \n",
    "    # Return fields, so their contents are accessible from the global namespace of the Notebook\n",
    "    return corpusQueryField, corpusField\n",
    "\n",
    "def create_lexicon_ui():\n",
    "    DEFAULT_SEARCHWORD = 'boek'\n",
    "    DEFAULT_LEXICON = \"diamant\"\n",
    "\n",
    "    # Create UI elements\n",
    "    searchWordField = widgets.Text(description=\"<b>Word:</b>\", value=DEFAULT_SEARCHWORD)\n",
    "    lexiconField = widgets.Dropdown(\n",
    "        options=['anw', 'celex', 'diamant', 'duelme', 'molex'],\n",
    "        value=DEFAULT_LEXICON,\n",
    "        description='<b>Lexicon:</b>',\n",
    "    )\n",
    "    '''lexSearchButton = widgets.Button(\n",
    "        description='Search',\n",
    "        button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "        tooltip='Search',\n",
    "    )\n",
    "    # Handle events\n",
    "    lexSearchButton.on_click(lexicon_search)'''\n",
    "    # Stack UI elements in vertical box and display\n",
    "    lexUiBox = widgets.VBox([searchWordField,lexiconField])\n",
    "    display(lexUiBox)\n",
    "    return searchWordField, lexiconField\n",
    "\n",
    "\n",
    "def create_save_dataframe_ui(df):\n",
    "    # build ui for saving results\n",
    "    DEFAULT_FILENAME = 'mijn_resultaten.csv'\n",
    "    saveResultsCaption = widgets.Label(value='Sla uw resultaten op:')\n",
    "    fileNameField = widgets.Text(value=DEFAULT_FILENAME)\n",
    "    savebutton = widgets.Button(\n",
    "        description='Bestand opslaan',\n",
    "        disabled=False,\n",
    "        button_style='warning', \n",
    "        tooltip=DEFAULT_FILENAME,  # trick to pass filename to button widget\n",
    "        icon=''\n",
    "    )\n",
    "    # inject dataframe into button object\n",
    "    savebutton.df = df\n",
    "    # when the user types a new filename, it will be passed to the button tooltip property straight away\n",
    "    fileNameLink = widgets.jslink((fileNameField, 'value'), (savebutton, 'tooltip'))\n",
    "    # click event with callback\n",
    "    savebutton.on_click( _save_dataframe )    \n",
    "    saveResultsBox = widgets.HBox([saveResultsCaption, fileNameField, savebutton])\n",
    "    display(saveResultsBox)    \n",
    "    \n",
    "def _save_dataframe(button):\n",
    "    fileName = button.tooltip\n",
    "    # The result files can be saved locally or on the server:\n",
    "    # If result files are to be offered as downloads, set to True; otherwise set to False    \n",
    "    fileDownloadable = False\n",
    "    # specify paths here, if needed:\n",
    "    filePath_onServer = ''  # could be /path/to\n",
    "    filePath_default = ''\n",
    "    # compute full path given chosen mode\n",
    "    fullFileName = (filePath_onServer if fileDownloadable else filePath_default ) + fileName\n",
    "        \n",
    "    try:\n",
    "        button.df.to_csv( fullFileName, index=False)\n",
    "        # confirm it all went well\n",
    "        print(fileName + \" saved\")    \n",
    "        button.button_style = 'success'\n",
    "        button.icon = 'check'\n",
    "        # trick: https://stackoverflow.com/questions/31893930/download-csv-from-an-ipython-notebook\n",
    "        if (fileDownloadable):\n",
    "            downloadableFiles = FileLinks(filePath_onServer)\n",
    "            display(downloadableFiles)\n",
    "    except Exception as e:\n",
    "        button.button_style = 'danger'\n",
    "        raise ValueError(\"An error occured when saving \" + fileName + \": \"+ str(e))    \n",
    "\n",
    "    \n",
    "    \n",
    "def load_dataframe(filepath):\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        print(filepath + \" loaded successfully\")            \n",
    "    except Exception as e:\n",
    "        raise ValueError(\"An error occured when loading \" + filepath + \": \"+ str(e))\n",
    "    finally:\n",
    "        return df\n",
    "\n",
    "def display_df(df, columns=None, title=None):\n",
    "    if title is not None:\n",
    "        display(HTML(\"<b>%s</b>\" % title))\n",
    "    \n",
    "    if columns is not None:\n",
    "        df_display=df[columns]\n",
    "    else:\n",
    "        df_display = df\n",
    "    \n",
    "    display(df)\n",
    "    create_save_dataframe_ui(df_corpus)\n",
    "    \n",
    "def display_df_chart(df, filter, title=None):\n",
    "    plt.figure()\n",
    "    (df[filter]).plot.barh().set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library functions: Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T14:35:34.495485Z",
     "start_time": "2019-01-22T14:35:34.474233Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def containsRegex(word):\n",
    "    return ( word.find('^')>-1 or\n",
    "            word.find('$')>-1 or \n",
    "            re.match(\"\\(.+?\\)\", word) or\n",
    "            re.match(\"\\[.+?\\]\", word) or\n",
    "            re.match(\"[\\+*]\", word) )\n",
    "                     \n",
    "def lexicon_query(word, pos, lexicon):\n",
    "    if (lexicon==\"anw\"):\n",
    "        exactsearch = (not containsRegex(word))\n",
    "        subpart = \"\"\"FILTER ( regex(?lemma, \\\"\"\"\"+word+\"\"\"\\\") || regex(?definition, \\\"\"\"\"+word+\"\"\"\\\") ) . \"\"\"\n",
    "        if (exactsearch == True):\n",
    "              subpart =  \"\"\"\n",
    "                { { ?lemId rdfs:label ?lemma .  \n",
    "                values ?lemma { \\\"\"\"\"+word+\"\"\"\\\"@nl \\\"\"\"\"+word+\"\"\"\\\" } }                 \n",
    "                UNION\n",
    "                { ?definitionId lemon:value ?definition .\n",
    "                values ?definition { \\\"\"\"\"+word+\"\"\"\\\"@nl \\\"\"\"\"+word+\"\"\"\\\" } } } .\n",
    "                \"\"\"               \n",
    "        query = \"\"\"PREFIX ontolex: <http://www.w3.org/ns/lemon/ontolex#>\n",
    "                  PREFIX anw: <http://rdf.ivdnt.org/lexica/anw>\n",
    "                  PREFIX anwsch: <http://rdf.ivdnt.org/schema/anw/>\n",
    "                  PREFIX lemon: <http://lemon-model.net/lemon#>\n",
    "                  \n",
    "                  SELECT ?lemId ?lemma ?writtenForm ?definition concat('', ?definitionComplement) as ?definitionComplement\n",
    "                  FROM <http://rdf.ivdnt.org/lexica/anw>\n",
    "                  WHERE {\n",
    "                      ?lemId rdfs:label ?lemma .\n",
    "                      ?lemId ontolex:sense ?senseId .\n",
    "                      ?senseId lemon:definition ?definitionId .\n",
    "                      ?definitionId lemon:value ?definition .\n",
    "                      OPTIONAL { ?definitionId anwsch:definitionComplement ?definitionComplement .}\n",
    "                      OPTIONAL { ?lemId ontolex:canonicalForm ?lemCFId . \n",
    "                          ?lemCFId ontolex:writtenRepresentation ?writtenForm . }\n",
    "                      \"\"\"+subpart+\"\"\"\n",
    "                      }\"\"\"\n",
    "    elif (lexicon==\"diamant\"):\n",
    "        exactsearch = (not containsRegex(word))\n",
    "        subpart1 = \"\"\"?n_form ontolex:writtenRep ?n_ontolex_writtenRep . \n",
    "            FILTER regex(?n_ontolex_writtenRep, \\\"\"\"\"+word+\"\"\"\\\") . \"\"\"\n",
    "        subpart2 = \"\"\"?n_syndef diamant:definitionText ?n_syndef_definitionText .  \n",
    "            FILTER regex(?n_ontolex_writtenRep, \\\"\"\"\"+word+\"\"\"\\\") . \"\"\"\n",
    "        if (exactsearch == True):\n",
    "            subpart1 =  \"\"\"\n",
    "                { ?n_form ontolex:writtenRep ?n_ontolex_writtenRep . \n",
    "                values ?n_ontolex_writtenRep { \\\"\"\"\"+word+\"\"\"\\\"@nl \\\"\"\"\"+word+\"\"\"\\\" } } \n",
    "                \"\"\"                \n",
    "            subpart2 = \"\"\"\n",
    "                { ?n_syndef diamant:definitionText ?n_syndef_definitionText . \n",
    "                values ?n_syndef_definitionText { \\\"\"\"\"+word+\"\"\"\\\"@nl \\\"\"\"\"+word+\"\"\"\\\" } } \n",
    "                \"\"\"\n",
    "        query = \"\"\"\n",
    "        PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "        prefix prov: <http://www.w3.org/ns/prov#>\n",
    "        prefix diamant: <http://rdf.ivdnt.org/schema/diamant#>\n",
    "        prefix lexinfo: <http://www.lexinfo.net/ontology/2.0/lexinfo#>\n",
    "        prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "        prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "        prefix lemon: <http://lemon-model.net/lemon#>\n",
    "        prefix ontolex: <http://www.w3.org/ns/lemon/ontolex#>\n",
    "        prefix ud: <http://universaldependencies.org/u/pos/>\n",
    "        prefix skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "        prefix dcterms: <http://purl.org/dc/terms/>\n",
    "        prefix dc: <http://purl.org/dc/terms/>\n",
    "\n",
    "        select ?n_entry ?n_form ?n_ontolex_writtenRep ?n_syndef ?n_sensedef ?n_sensedef_definitionText ?n_syndef_definitionText ?n_sense ?inputMode ?wy_f_show ?wy_t_show\n",
    "        where\n",
    "        {\n",
    "        graph ?g\n",
    "        {\n",
    "        {\n",
    "            \"\"\" + subpart1 + \"\"\"\n",
    "            { ?n_entry a ontolex:LexicalEntry} .\n",
    "            { ?n_form a ontolex:Form} .\n",
    "            { ?n_sense a ontolex:LexicalSense} .\n",
    "            { ?n_syndef a diamant:SynonymDefinition} .\n",
    "            { ?n_sensedef a lemon:SenseDefinition} .\n",
    "            { ?n_syndef diamant:definitionText ?n_syndef_definitionText } .\n",
    "            { ?n_sensedef diamant:definitionText ?n_sensedef_definitionText } .\n",
    "            { ?n_entry ontolex:canonicalForm ?n_form } .\n",
    "            { ?n_entry ontolex:sense ?n_sense } .\n",
    "            { ?n_sense lemon:definition ?n_syndef } .\n",
    "            { ?n_sense lemon:definition ?n_sensedef } .\n",
    "              ?n_sense diamant:attestation ?n_attest_show .\n",
    "              ?n_sense diamant:attestation ?n_attest_filter .\n",
    "              ?n_attest_show diamant:text ?n_q_show .\n",
    "              ?n_attest_filter diamant:text ?n_q_filter .\n",
    "              ?n_attest_show a diamant:Attestation .\n",
    "              ?n_attest_filter a diamant:Attestation .\n",
    "              ?n_q_filter a diamant:Quotation .\n",
    "              ?n_q_show a diamant:Quotation .\n",
    "              ?n_q_filter diamant:witnessYearFrom ?wy_f_filter .\n",
    "              ?n_q_filter diamant:witnessYearTo ?wy_t_filter .\n",
    "              ?n_q_show diamant:witnessYearFrom ?wy_f_show .\n",
    "              ?n_q_show diamant:witnessYearTo ?wy_t_show .\n",
    "              FILTER (xsd:integer(?wy_f_show) >= 1200)\n",
    "              FILTER (xsd:integer(?wy_t_show) >= 1200)\n",
    "              FILTER (xsd:integer(?wy_f_show) <= 2018)\n",
    "              FILTER (xsd:integer(?wy_t_show) <= 2018)\n",
    "            { bind(\"lemma\" as ?inputMode) } .\n",
    "            } UNION\n",
    "          {\n",
    "            \"\"\" + subpart2 + \"\"\"\n",
    "            { ?n_sense a ontolex:LexicalSense} .\n",
    "            { ?n_syndef a diamant:SynonymDefinition} .\n",
    "            { ?n_sensedef a lemon:SenseDefinition} .\n",
    "            { ?n_form a ontolex:Form} .\n",
    "            { ?n_form ontolex:writtenRep ?n_ontolex_writtenRep } .  { ?n_entry a ontolex:LexicalEntry} .\n",
    "            { ?n_entry ontolex:sense ?n_sense } .\n",
    "            { ?n_sense lemon:definition ?n_syndef } .\n",
    "            { ?n_sense lemon:definition ?n_sensedef } .\n",
    "            { ?n_sensedef diamant:definitionText ?n_sensedef_definitionText } .\n",
    "            { ?n_entry ontolex:canonicalForm ?n_form } .\n",
    "            ?n_sense diamant:attestation ?n_attest_show .\n",
    "            ?n_sense diamant:attestation ?n_attest_filter .\n",
    "            ?n_attest_filter diamant:text ?n_q_filter .\n",
    "            ?n_attest_show diamant:text ?n_q_show .\n",
    "            ?n_q_filter diamant:witnessYearFrom ?wy_f_filter .\n",
    "            ?n_q_filter diamant:witnessYearTo ?wy_t_filter .\n",
    "            ?n_q_show diamant:witnessYearFrom ?wy_f_show .\n",
    "            ?n_q_show diamant:witnessYearTo ?wy_t_show .\n",
    "            ?n_attest_show a diamant:Attestation .\n",
    "            ?n_attest_filter a diamant:Attestation .\n",
    "            ?n_q_filter a diamant:Quotation .\n",
    "            ?n_q_show a diamant:Quotation .\n",
    "            FILTER (xsd:integer(?wy_f_show) >= 1200)\n",
    "            FILTER (xsd:integer(?wy_t_show) >= 1200)\n",
    "            FILTER (xsd:integer(?wy_f_show) <= 2018)\n",
    "            FILTER (xsd:integer(?wy_t_show) <= 2018)\n",
    "          { bind(\"defText\" as ?inputMode) } .\n",
    "            }\n",
    "        }\n",
    "        }\"\"\"\n",
    "    elif (lexicon==\"molex\"):\n",
    "        exactsearch = (not containsRegex(word))\n",
    "        subpart1 = \"\"\"\"\"\"\n",
    "        subpart2 = \"\"\"\"\"\"\n",
    "        subpartPos = \"\"\"\"\"\"\n",
    "        if (word != ''):\n",
    "            if (exactsearch == True):\n",
    "                subpart1 =  \"\"\"\n",
    "                    { ?lemCFId ontolex:writtenRep ?lemma . \n",
    "                    values ?lemma { \\\"\"\"\"+word+\"\"\"\\\"@nl \\\"\"\"\"+word+\"\"\"\\\" } } \n",
    "                    UNION\n",
    "                    { ?wordformId ontolex:writtenRep ?wordform . \n",
    "                    values ?wordform { \\\"\"\"\"+word+\"\"\"\\\"@nl \\\"\"\"\"+word+\"\"\"\\\" } } .\n",
    "                    \"\"\"        \n",
    "            else:\n",
    "                subpart2 = \"\"\"FILTER ( regex(?lemma, \\\"\"\"\"+word+\"\"\"\\\") || regex(?wordform, \\\"\"\"\"+word+\"\"\"\\\") ) . \"\"\"\n",
    "        if (pos is not None and pos != ''):\n",
    "            subpartPos = \"\"\"FILTER ( regex(?lemPos, \\\"\"\"\"+pos+\"\"\"$\\\") ) .\"\"\"\n",
    "        query = \"\"\"\n",
    "            PREFIX ontolex: <http://www.w3.org/ns/lemon/ontolex#>\n",
    "            PREFIX UD: <http://universaldependencies.org/u/>\n",
    "            PREFIX diamant: <http://rdf.ivdnt.org/schema/diamant#>\n",
    "            \n",
    "            SELECT ?lemEntryId ?lemma ?lemPos ?wordformId ?wordform ?hyphenation ?wordformPos ?Gender ?Number\n",
    "            FROM <http://rdf.ivdnt.org/lexica/molex>\n",
    "            WHERE\n",
    "            {\n",
    "            ?lemEntryId ontolex:canonicalForm ?lemCFId .\n",
    "            ?lemCFId ontolex:writtenRep ?lemma .\n",
    "            \"\"\"+subpart1+\"\"\"\n",
    "            OPTIONAL {?lemEntryId UD:Gender ?Gender .}\n",
    "            OPTIONAL {?lemEntryId UD:VerbForm ?verbform .}\n",
    "            ?lemEntryId UD:pos ?lemPos .\n",
    "            \"\"\"+subpartPos+\"\"\"\n",
    "            ?lemEntryId ontolex:lexicalForm ?wordformId .\n",
    "            ?wordformId UD:pos ?wordformPos .\n",
    "            OPTIONAL {?wordformId UD:Number ?Number .}\n",
    "            OPTIONAL {?wordformId ontolex:writtenRep ?wordform .}\n",
    "            OPTIONAL {?wordformId diamant:hyphenation ?hyphenation .}\n",
    "            \"\"\"+subpart2+\"\"\"\n",
    "            }\n",
    "        \"\"\"\n",
    "    elif (lexicon==\"duelme\"):\n",
    "        exactsearch = (not containsRegex(word))\n",
    "        subpart = \"\"\"FILTER ( regex(?lemma, \\\"\"\"\"+word+\"\"\"\\\") || regex(?wordform, \\\"\"\"\"+word+\"\"\"\\\") ) .\"\"\"\n",
    "        if (exactsearch == True):\n",
    "            subpart =  \"\"\"\n",
    "                { ?y lmf:hasLemma ?dl .  \n",
    "                values ?dl { \\\"\"\"\"+word+\"\"\"\\\"@nl \\\"\"\"\"+word+\"\"\"\\\" } }                 \n",
    "                \"\"\"        \n",
    "        query = \"\"\"\n",
    "            PREFIX duelme: <http://rdf.ivdnt.org/lexica/duelme>\n",
    "            PREFIX intskos: <http://ivdnt.org/schema/lexica#>\n",
    "            PREFIX lmf: <http://www.lexinfo.net/lmf>\n",
    "            PREFIX ontolex: <http://www.w3.org/ns/lemon/ontolex#>\n",
    "            PREFIX UD: <http://rdf.ivdnt.org/vocabs/UniversalDependencies2#>\n",
    "            \n",
    "            SELECT ?exampleSentence ?lemma ?gender ?number\n",
    "            WHERE  {\n",
    "                  ?d intskos:ExampleSentence ?exampleSentence .\n",
    "                  ?d lmf:ListOfComponents [lmf:Component ?y] .\n",
    "                  ?y lmf:hasLemma ?lemma . \n",
    "                  OPTIONAL {?y UD:Gender ?gender}\n",
    "                  OPTIONAL {?y UD:Number ?number}\n",
    "            \"\"\"+subpart+\"\"\"\n",
    "            }\n",
    "        \"\"\"\n",
    "    elif (lexicon==\"celex\"):\n",
    "        exactsearch = (not containsRegex(word))\n",
    "        subpart = \"\"\"FILTER ( regex(?lemma, \\\"\"\"\"+word+\"\"\"\\\") ) . \"\"\"\n",
    "        if (exactsearch == True):\n",
    "            subpart =  \"\"\"\n",
    "                { ?lemmaId ontolex:canonicalForm [ontolex:writtenRep ?lemma] .  \n",
    "                values ?lemma { \\\"\"\"\"+word+\"\"\"\\\"@nl \\\"\"\"\"+word+\"\"\"\\\" } }                 \n",
    "                \"\"\"        \n",
    "        query = \"\"\"\n",
    "            PREFIX ontolex: <http://www.w3.org/ns/lemon/ontolex#>\n",
    "            PREFIX celex: <http://rdf.ivdnt.org/lexica/celex>\n",
    "            PREFIX UD: <http://rdf.ivdnt.org/vocabs/UniversalDependencies2#>\n",
    "            PREFIX decomp: <http://www.w3.org/ns/lemon/decomp#>\n",
    "            PREFIX gold: <http://purl.org/linguistics/gold#>\n",
    "            \n",
    "            SELECT DISTINCT ?lemmaId ?lemma ?wordformId ?wordform ?number ?gender concat('',?subLemmata) AS ?subLemmata\n",
    "            WHERE  {\n",
    "                ?lemmaId ontolex:canonicalForm [ontolex:writtenRep ?lemma] .\n",
    "                \"\"\"+subpart+\"\"\"\n",
    "                BIND( ?lemmaId AS ?lemmaIdIRI ).\n",
    "                ?lemmaId ontolex:lexicalForm ?wordformId .\n",
    "                ?wordformId ontolex:writtenRep ?wordform .\n",
    "                OPTIONAL {?wordformId UD:Number ?number} .\n",
    "                OPTIONAL {\n",
    "                    ?lemmaId UD:Gender ?g . \n",
    "                        bind( \n",
    "                            if(?g = UD:Fem_Gender, \n",
    "                            UD:Com_Gender, \n",
    "                                if(?g = UD:Masc_Gender,\n",
    "                                    UD:Com_Gender,\n",
    "                                    UD:Neut_Gender\n",
    "                                )\n",
    "                            )\n",
    "                            AS ?gender\n",
    "                        )\n",
    "                }\n",
    "                OPTIONAL {\n",
    "                    SELECT ?lemmaIdIRI (group_concat(DISTINCT concat(?partNr,\":\",?subLemma);separator=\" + \") as ?subLemmata)\n",
    "                    WHERE {\n",
    "                        SELECT ?lemmaIdIRI ?celexComp ?aWordformId ?subLemma ?partNr\n",
    "                        WHERE {\n",
    "                                {\n",
    "                                ?lemmaIdIRI ontolex:lexicalForm ?aWordformId . \n",
    "                                ?lemmaIdIRI decomp:constituent ?celexComp .\n",
    "                                OPTIONAL { ?celexComp gold:stem [ontolex:writtenRep ?subLemma] . }\n",
    "                                OPTIONAL { ?celexComp decomp:correspondsTo [ ontolex:canonicalForm [ontolex:writtenRep ?subLemma]] . }\n",
    "                                }\n",
    "                                {\n",
    "                                    {\n",
    "                                        {?lemmaIdIRI <http://www.w3.org/1999/02/22-rdf-syntax-ns#_1> ?celexComp .}\n",
    "                                        UNION\n",
    "                                        {?lemmaIdIRI <http://www.w3.org/1999/02/22-rdf-syntax-ns#_2> ?celexComp .}\n",
    "                                        UNION\n",
    "                                        {?lemmaIdIRI <http://www.w3.org/1999/02/22-rdf-syntax-ns#_3> ?celexComp .}\n",
    "                                        UNION\n",
    "                                        {?lemmaIdIRI <http://www.w3.org/1999/02/22-rdf-syntax-ns#_4> ?celexComp .}\n",
    "                                        UNION\n",
    "                                        {?lemmaIdIRI <http://www.w3.org/1999/02/22-rdf-syntax-ns#_5> ?celexComp .}\n",
    "                                        UNION\n",
    "                                        {?lemmaIdIRI <http://www.w3.org/1999/02/22-rdf-syntax-ns#_6> ?celexComp .}                                        \n",
    "                                    }\n",
    "                                ?lemmaIdIRI ?rdfsynt ?celexComp .\n",
    "                                BIND(IF(STRSTARTS(str(?rdfsynt), \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"), replace(STRAFTER(str(?rdfsynt), \"#\"), \"_\", \"\"), \"999\") AS ?partNr) .\n",
    "                                MINUS {\n",
    "                                    ?lemmaIdIRI <http://www.w3.org/1999/02/22-rdf-syntax-ns#0> ?celexComp .\n",
    "                                    }\n",
    "                                }\n",
    "                            FILTER (?partNr != \"999\") .\n",
    "                            }\n",
    "                            ORDER BY ?partNr\n",
    "                            }\n",
    "                        GROUP BY ?aWordformId ?lemmaIdIRI\n",
    "                    }\n",
    "            }\n",
    "        \"\"\"\n",
    "        \n",
    "    return query\n",
    "\n",
    "def corpus_query_lemma(word):\n",
    "    return r'[lemma=\"'+ word + r'\"]'\n",
    "\n",
    "def lexicon_query_alllemmata(lexicon, pos):\n",
    "    if (lexicon==\"anw\"):\n",
    "        query = \"\"\"PREFIX ontolex: <http://www.w3.org/ns/lemon/ontolex#>\n",
    "                  PREFIX anw: <http://rdf.ivdnt.org/lexica/anw>                  \n",
    "                  SELECT DISTINCT ?writtenForm\n",
    "                  FROM <http://rdf.ivdnt.org/lexica/anw>\n",
    "                  WHERE {\n",
    "                      ?lemId rdfs:label ?lemma .\n",
    "                      ?lemId ontolex:canonicalForm ?lemCFId . \n",
    "                      ?lemCFId ontolex:writtenRepresentation ?writtenForm .\n",
    "                      }\n",
    "                      ORDER BY ?writtenForm\"\"\"\n",
    "    elif (lexicon==\"celex\"):\n",
    "        query = \"\"\"\n",
    "            PREFIX ontolex: <http://www.w3.org/ns/lemon/ontolex#>\n",
    "            \n",
    "            SELECT DISTINCT ?lemma AS ?writtenForm\n",
    "            WHERE  {\n",
    "                ?lemmaId ontolex:canonicalForm [ontolex:writtenRep ?lemma] .                \n",
    "                }\n",
    "            ORDER BY ?lemma\"\"\"\n",
    "    elif (lexicon==\"diamant\"):\n",
    "        query = \"\"\"\n",
    "        PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "        prefix prov: <http://www.w3.org/ns/prov#>\n",
    "        prefix diamant: <http://rdf.ivdnt.org/schema/diamant#>\n",
    "        prefix lexinfo: <http://www.lexinfo.net/ontology/2.0/lexinfo#>\n",
    "        prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "        prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "        prefix lemon: <http://lemon-model.net/lemon#>\n",
    "        prefix ontolex: <http://www.w3.org/ns/lemon/ontolex#>\n",
    "        prefix ud: <http://universaldependencies.org/u/pos/>\n",
    "        prefix skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "        prefix dcterms: <http://purl.org/dc/terms/>\n",
    "        prefix dc: <http://purl.org/dc/terms/>\n",
    "\n",
    "        select DISTINCT ?n_ontolex_writtenRep AS ?writtenForm\n",
    "        where\n",
    "        {\n",
    "        graph ?g\n",
    "        {\n",
    "        {\n",
    "            { ?n_form ontolex:writtenRep ?n_ontolex_writtenRep} .\n",
    "            { ?n_form a ontolex:Form} .\n",
    "        }\n",
    "        }\n",
    "        }\n",
    "        ORDER BY ?n_ontolex_writtenRep\n",
    "        LIMIT 10000\n",
    "        \"\"\"\n",
    "    elif (lexicon==\"duelme\"):\n",
    "        query = \"\"\"\n",
    "            PREFIX lmf: <http://www.lexinfo.net/lmf>            \n",
    "            SELECT DISTINCT ?lemma AS ?writtenForm\n",
    "            WHERE  {\n",
    "                  ?y lmf:hasLemma ?lemma . \n",
    "            }\n",
    "            ORDER BY ?lemma\"\"\"\n",
    "    elif (lexicon==\"molex\"):\n",
    "        pos_condition = \"\"\"\"\"\"\n",
    "        if pos is not None:\n",
    "            pos_condition = \"\"\"\n",
    "            {?lemEntryId UD:pos ?lemPos .\n",
    "            FILTER regex(?lemPos, '\"\"\"+pos+\"\"\"') } .\n",
    "            \"\"\"\n",
    "        query = \"\"\"\n",
    "                PREFIX ontolex: <http://www.w3.org/ns/lemon/ontolex#>\n",
    "                PREFIX UD: <http://universaldependencies.org/u/>\n",
    "                SELECT DISTINCT ?lemma AS ?writtenForm\n",
    "                FROM <http://rdf.ivdnt.org/lexica/molex>\n",
    "                WHERE\n",
    "                {\n",
    "                ?lemEntryId ontolex:canonicalForm ?lemCFId .\n",
    "                ?lemCFId ontolex:writtenRep ?lemma .  \n",
    "                \"\"\"+pos_condition+\"\"\"\n",
    "                }\n",
    "                 ORDER BY ?lemma\"\"\"\n",
    "    else:\n",
    "        raise ValueError(\"Lexicon \" + lexicon + \" not supported for querying all words.\")\n",
    "        \n",
    "    #print(query)\n",
    "    return query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the cell below to show the UI, and fill in your search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T14:35:35.930964Z",
     "start_time": "2019-01-22T14:35:35.909872Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66be2935765495399661cd0ef29ab96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='[lemma=\"boek\" & pos=\"verb\"]', description='<b>CQL query:</b>'), Dropdown(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from chaininglib import ui\n",
    "\n",
    "# Create corpus UI, creates references to field contents\n",
    "corpusQueryField, corpusField = create_corpus_ui()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Click the cell below and press Run to perform the given query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T15:54:51.993481Z",
     "start_time": "2019-01-22T15:54:51.497985Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://portal.clarin.inl.nl/fcscorpora/clariah-fcs-endpoints/sru?operation=searchRetrieve&queryType=fcs&maximumRecords=1000&x-fcs-context=chn&query=%5Blemma%3D%22de%7Chet%22%5D%5Bpos%3D%22ADJ%22%5D%5Bword%3D%22loop%22%5D\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Results:</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left context</th>\n",
       "      <th>lemma 0</th>\n",
       "      <th>lemma 1</th>\n",
       "      <th>lemma 2</th>\n",
       "      <th>pos 0</th>\n",
       "      <th>pos 1</th>\n",
       "      <th>pos 2</th>\n",
       "      <th>word 0</th>\n",
       "      <th>word 1</th>\n",
       "      <th>word 2</th>\n",
       "      <th>right context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAB-bestuur is zaterdag vergaderd over</td>\n",
       "      <td>de</td>\n",
       "      <td>internationaal</td>\n",
       "      <td>loop</td>\n",
       "      <td>None</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>de</td>\n",
       "      <td>internationale</td>\n",
       "      <td>loop</td>\n",
       "      <td>die in 2003 voor het</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>liet zijn of haar tranen</td>\n",
       "      <td>de</td>\n",
       "      <td>vrij</td>\n",
       "      <td>loop</td>\n",
       "      <td>None</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>de</td>\n",
       "      <td>vrije</td>\n",
       "      <td>loop</td>\n",
       "      <td>De dankdienst werd geleid door</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>familie lieten zij hun tranen</td>\n",
       "      <td>de</td>\n",
       "      <td>vrij</td>\n",
       "      <td>loop</td>\n",
       "      <td>None</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>de</td>\n",
       "      <td>vrije</td>\n",
       "      <td>loop</td>\n",
       "      <td>Johan Ferrier wordt vandaag tijdens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>verwacht vandaag 3.000 man tijdens</td>\n",
       "      <td>de</td>\n",
       "      <td>groen</td>\n",
       "      <td>loop</td>\n",
       "      <td>None</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>de</td>\n",
       "      <td>groene</td>\n",
       "      <td>loop</td>\n",
       "      <td>van zijn organisatie De wandel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vijf uur s middags start</td>\n",
       "      <td>de</td>\n",
       "      <td>groen</td>\n",
       "      <td>loop</td>\n",
       "      <td>None</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>de</td>\n",
       "      <td>groene</td>\n",
       "      <td>loop</td>\n",
       "      <td>op het parkeerterrein van het</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dat bewust is gekozen voor</td>\n",
       "      <td>de</td>\n",
       "      <td>groen</td>\n",
       "      <td>loop</td>\n",
       "      <td>None</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>de</td>\n",
       "      <td>groene</td>\n",
       "      <td>loop</td>\n",
       "      <td>als naam Wij lopen in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>en laten vrouwen de emoties</td>\n",
       "      <td>de</td>\n",
       "      <td>vrij</td>\n",
       "      <td>loop</td>\n",
       "      <td>None</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>de</td>\n",
       "      <td>vrije</td>\n",
       "      <td>loop</td>\n",
       "      <td>Als een vrouw ook nog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>zinnen Hij liet zijn tranen</td>\n",
       "      <td>de</td>\n",
       "      <td>vrij</td>\n",
       "      <td>loop</td>\n",
       "      <td>None</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>de</td>\n",
       "      <td>vrije</td>\n",
       "      <td>loop</td>\n",
       "      <td>Gerechtigheid Suriname ander gezicht internationaal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>scholen kunnen zij hun creativiteit</td>\n",
       "      <td>de</td>\n",
       "      <td>vrij</td>\n",
       "      <td>loop</td>\n",
       "      <td>None</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>de</td>\n",
       "      <td>vrije</td>\n",
       "      <td>loop</td>\n",
       "      <td>geven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>zinnen Hij liet zijn tranen</td>\n",
       "      <td>de</td>\n",
       "      <td>vrij</td>\n",
       "      <td>loop</td>\n",
       "      <td>None</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>de</td>\n",
       "      <td>vrije</td>\n",
       "      <td>loop</td>\n",
       "      <td>Gerechtigheid Suriname ander gezicht internationaal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              left context lemma 0         lemma 1 lemma 2  \\\n",
       "0  SAB-bestuur is zaterdag vergaderd over       de  internationaal    loop   \n",
       "1                liet zijn of haar tranen       de            vrij    loop   \n",
       "2           familie lieten zij hun tranen       de            vrij    loop   \n",
       "3      verwacht vandaag 3.000 man tijdens       de           groen    loop   \n",
       "4                vijf uur s middags start       de           groen    loop   \n",
       "5              dat bewust is gekozen voor       de           groen    loop   \n",
       "6             en laten vrouwen de emoties       de            vrij    loop   \n",
       "7             zinnen Hij liet zijn tranen       de            vrij    loop   \n",
       "8     scholen kunnen zij hun creativiteit       de            vrij    loop   \n",
       "9             zinnen Hij liet zijn tranen       de            vrij    loop   \n",
       "\n",
       "  pos 0 pos 1 pos 2 word 0          word 1 word 2  \\\n",
       "0  None   ADJ  NOUN     de  internationale   loop   \n",
       "1  None   ADJ  NOUN     de           vrije   loop   \n",
       "2  None   ADJ  NOUN     de           vrije   loop   \n",
       "3  None   ADJ  NOUN     de          groene   loop   \n",
       "4  None   ADJ  NOUN     de          groene   loop   \n",
       "5  None   ADJ  NOUN     de          groene   loop   \n",
       "6  None   ADJ  NOUN     de           vrije   loop   \n",
       "7  None   ADJ  NOUN     de           vrije   loop   \n",
       "8  None   ADJ  NOUN     de           vrije   loop   \n",
       "9  None   ADJ  NOUN     de           vrije   loop   \n",
       "\n",
       "                                          right context  \n",
       "0                                  die in 2003 voor het  \n",
       "1                        De dankdienst werd geleid door  \n",
       "2                   Johan Ferrier wordt vandaag tijdens  \n",
       "3                        van zijn organisatie De wandel  \n",
       "4                         op het parkeerterrein van het  \n",
       "5                                 als naam Wij lopen in  \n",
       "6                                 Als een vrouw ook nog  \n",
       "7   Gerechtigheid Suriname ander gezicht internationaal  \n",
       "8                                                 geven  \n",
       "9   Gerechtigheid Suriname ander gezicht internationaal  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75216b169ef743b79a97690fdfc6b697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Sla uw resultaten op:'), Text(value='mijn_resultaten.csv'), Button(button_style='w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from chaininglib import search\n",
    "query= corpusQueryField.value\n",
    "corpus = corpusField.value\n",
    "df_corpus = search_corpus(query, corpus)\n",
    "#df_corpus = load_dataframe('mijn_resultaten.csv')\n",
    "display_df(df_corpus, title=\"Results:\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexicon search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the cell below to show the UI, and fill in your search query in the UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T14:35:39.078060Z",
     "start_time": "2019-01-22T14:35:39.061787Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from chaininglib import ui\n",
    "searchWordField, lexiconField = create_lexicon_ui()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Click the cell below and press Run to perform the given query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T14:35:42.147205Z",
     "start_time": "2019-01-22T14:35:41.791699Z"
    }
   },
   "outputs": [],
   "source": [
    "#from chaininglib import queries, search\n",
    "\n",
    "search_word = searchWordField.value\n",
    "lexicon = lexiconField.value\n",
    "# USER: can replace this by own custom query\n",
    "query = lexicon_query(word=search_word, pos= '', lexicon=lexicon)\n",
    "\n",
    "df_lexicon = search_lexicon(query, lexicon)\n",
    "display(df_lexicon)\n",
    "#df_columns_list = list(df_lexicon.columns.values)\n",
    "#df_lexicon_in_columns = df_lexicon[df_columns_list]\n",
    "#display(df_lexicon_in_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study 1 (parallel): Frequency of *puur*+verb and *zuiver*+verb compared\n",
    "* Below cell searches for *puur*+verb and for *zuiver*+verb in the CHN corpus\n",
    "* Compare frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T14:39:47.933723Z",
     "start_time": "2019-01-22T14:39:47.043682Z"
    }
   },
   "outputs": [],
   "source": [
    "#from chaininglib import search\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# Word 1: puur\n",
    "word1= \"puur\"\n",
    "df_corpus1 = search_corpus('[word=\"' + word1 + r'\"][pos=\"verb\"]',corpus=\"chn\")\n",
    "display(HTML('<b>' + word1 + '</b>'))\n",
    "display(df_corpus1)\n",
    "\n",
    "# Word 2: zuiver\n",
    "word2 = \"zuiver\"\n",
    "df_corpus2 = search_corpus(r'[word=\"' + word2 + r'\"][pos=\"verb\"]',\"chn\")\n",
    "display(HTML('<b>' + word2 + '</b>'))\n",
    "display(df_corpus2)\n",
    "\n",
    "# Compute difference\n",
    "diff_left, diff_right, intersec = column_difference(df_corpus1[\"word 1\"], df_corpus2[\"word 1\"])\n",
    "# Elements of 1 that are not in 2\n",
    "display(HTML('Werkwoorden voor <b>' + word1 + '</b> niet in <b>' + word2 + '</b>: ' + \", \".join(diff_left)))\n",
    "# Elements of 2 that are not in 1\n",
    "display(HTML('Werkwoorden voor <b>' + word1 + '</b> niet in <b>' + word2 + '</b>: ' + \", \".join(diff_right)))\n",
    "# Elements both in 1 and 2\n",
    "display(HTML('Werkwoorden zowel voor <b>' + word1 + '</b> als voor <b>' + word2 + '</b>: ' + \", \".join(intersec)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study 2 (sequential): Retrieve synonyms from DiaMaNT, look up in Gysseling\n",
    "* Below cell searches for term \"boek\" in DiaMaNT, and looks up all variants in Gysseling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T14:35:56.234896Z",
     "start_time": "2019-01-22T14:35:45.746206Z"
    }
   },
   "outputs": [],
   "source": [
    "search_word = \"boek\"\n",
    "lexicon = \"diamant\"\n",
    "corpus= \"gysseling\"\n",
    "\n",
    "# First, lookup synonyms in DiaMaNT\n",
    "query = lexicon_query(word=search_word, pos= '', lexicon=lexicon)\n",
    "df_lexicon = search_lexicon(query, lexicon)\n",
    "syns = diamant_get_synonyms(df_lexicon) \n",
    "syns.add(search_word) # Also add search word itself\n",
    "display(HTML('Synoniemen voor <b>' + search_word + '</b>: ' + \", \".join(syns)))\n",
    "\n",
    "# Search for all synonyms in corpus\n",
    "## Create queries: search by lemma\n",
    "syns_queries = [corpus_query_lemma(syn) for syn in syns]\n",
    "## Search for all synonyms in corpus\n",
    "result_dict = search_corpus_multiple(syns_queries, corpus)\n",
    "view_multiple_results(result_dict, labels=list(syns))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T16:24:19.655999Z",
     "start_time": "2019-01-11T16:24:19.645252Z"
    }
   },
   "source": [
    "## Case study (parallel) 3: Find corpus words not in lexicon; list most frequent ones.\n",
    "* Only parallel if you can ask the lexicon a list of all words.\n",
    "* Currently only working: ask DiaMaNT list of words (limited at 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T14:36:56.525588Z",
     "start_time": "2019-01-22T14:35:56.240217Z"
    }
   },
   "outputs": [],
   "source": [
    "# Query lexicon to give list of all words\n",
    "lexicon=\"anw\"\n",
    "df_lexicon = search_lexicon_alllemmata(lexicon)\n",
    "## TODO: Why do double words appear?\n",
    "lexicon_set = sorted( set([w.lower() for w in df_lexicon[\"writtenForm\"]]) )\n",
    "display(lexicon_set)\n",
    "\n",
    "df_corpus = search_corpus_allwords(\"gysseling\", None)\n",
    "display(df_corpus)\n",
    "len(df_corpus)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T15:46:20.519833Z",
     "start_time": "2019-01-16T15:46:20.516208Z"
    }
   },
   "source": [
    "## Case study (sequential) 4: Find occurences of attributive adjectives not ending with -e, even though they are preceeded by a definite article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T14:53:04.668561Z",
     "start_time": "2019-01-22T14:52:54.047161Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus_to_search=\"opensonar\"\n",
    "lexicon_to_search=\"molex\"\n",
    "\n",
    "# CORPUS: get [article + attributive adjective + nouns] combinations in which the adjective does not end with -e\n",
    "print('Stap 1:')\n",
    "df_corpus = search_corpus(r'[lemma=\"de|het\"][word=\"^g(.+)[^e]$\" & pos=\"ADJ\"][pos=\"NOUN\"]', corpus=corpus_to_search)\n",
    "display(df_corpus)\n",
    "\n",
    "# LEXICON: get adjectives the lemma of which does not end with -e\n",
    "query=lexicon_query('^g(.+)[^e]$', 'ADJ', lexicon_to_search)\n",
    "df_lexicon = search_lexicon(query, lexicon_to_search)\n",
    "display(df_lexicon)\n",
    "\n",
    "# LEXICON: get adjectives having a final -e in definite attributive use\n",
    "print('Filtering lexicon results')\n",
    "df_lexicon_form_e = filter_df(df_lexicon,column=\"wordform\",method=\"regex\", regex_or_set = 'e$')\n",
    "#final_e_condition=df_lexicon.wordform.str.contains('e$')\n",
    "#df = df_lexicon[final_e_condition]\n",
    "display(df_lexicon_form_e)\n",
    "\n",
    "# RESULT: get the records out of our first list in which the -e-less-adjectives match the lemma form of our last list\n",
    "print('Wanted list:')\n",
    "e_forms = list(df_lexicon_form_e.lemma)\n",
    "#no_final_e_condition = df_corpus['word 1'].isin(eless_forms)\n",
    "#result_df = df_corpus[no_final_e_condition]\n",
    "result_df = filter_df(df_corpus, column = \"word 1\", method=\"isin\", regex_or_set=e_forms)\n",
    "display( result_df )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study (sequential) 5: (morphosyntactic lexicon and possibly unannotated corpus) Look up inflected forms and spelling variants for a given lemma in a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T14:33:52.653090Z",
     "start_time": "2019-01-22T14:33:40.188Z"
    }
   },
   "outputs": [],
   "source": [
    "lexicon_to_search=\"molex\"\n",
    "corpus_to_search=\"chn\"\n",
    "\n",
    "##############################################\n",
    "# TODO  zelfde met meerdere lemmata en gegroepeerd \n",
    "##############################################\n",
    "\n",
    "lemma_to_look_for=\"denken\"\n",
    "\n",
    "# LEXICON: Search for the inflected forms of a lemma in a morphosyntactic lexicon\n",
    "query=lexicon_query(lemma_to_look_for, None, lexicon_to_search)\n",
    "df_lexicon = search_lexicon(query, lexicon_to_search)\n",
    "display(df_lexicon)\n",
    "\n",
    "# Put all inflected forms into a list\n",
    "inflected_wordforms = list(df_lexicon.wordform)\n",
    "\n",
    "# CORPUS: Look up the inflected forms in a (possibly unannotated) corpus\n",
    "# beware: If the corpus is not annotated, all we can do is searching for the inflected words\n",
    "#         But if the corpus is lemmatized, we have to make sure we're retrieving correct data by specifying the lemma as well\n",
    "annotated_corpus = True\n",
    "query = r'[lemma=\"'+lemma_to_look_for+r'\" & word=\"'+r\"|\".join(inflected_wordforms)+r'\"]' if annotated_corpus else r'[word=\"'+r\"|\".join(inflected_wordforms)+r'\"]'\n",
    "df_corpus = search_corpus(query, corpus=corpus_to_search)\n",
    "display(df_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study : Build frequency table of some corpus, based on lemma list of a given lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T14:33:52.653972Z",
     "start_time": "2019-01-22T14:33:40.190Z"
    }
   },
   "outputs": [],
   "source": [
    "base_lexicon=\"anw\"\n",
    "corpus_to_search1=\"opensonar\"\n",
    "corpus_to_search2=\"chn\"\n",
    "\n",
    "# build frequency tables of two corpora\n",
    "\n",
    "df_frequency_list1 = get_frequency_list(base_lexicon, \"NOUN\", corpus_to_search1)\n",
    "display( df_frequency_list1.sort_values(ascending=False,by=['raw_freq']).head(25) )\n",
    "display_df_chart(df_frequency_list1.sort_values(ascending=True, by=['rank']).head(25), 'raw_freq', title='chart df1' )\n",
    "\n",
    "df_frequency_list2 = get_frequency_list(base_lexicon, \"NOUN\", corpus_to_search2)\n",
    "display(df_frequency_list2.sort_values(ascending=False,by=['raw_freq']).head(25))\n",
    "display_df_chart(df_frequency_list2.sort_values(ascending=True, by=['rank']).head(25), 'raw_freq', title='chart df2' )\n",
    "\n",
    "\n",
    "# TODO: lemmata tonen die in 1 of 2 ontbreken\n",
    "\n",
    "# compute the rank diff of lemmata in frequency tables\n",
    "\n",
    "df_rankdiffs = get_rank_diff(df_frequency_list1, df_frequency_list2)\n",
    "\n",
    "display(df_rankdiffs.sort_values(by=['rank_diff']).head(25))\n",
    "display_df_chart( df_rankdiffs.sort_values(ascending=False, by=['rank_diff']).head(25), 'rank_diff', title='chart large diff' )\n",
    "display_df_chart( df_rankdiffs.sort_values(ascending=True, by=['rank_diff']).head(25), 'rank_diff', title='chart small diff' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study: search in a corpus for wordforms of a lemma, which are not included of this lemma's paramadigm in a lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>known_wordforms</th>\n",
       "      <th>unknown_wordforms</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemmata</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>achterliggen</th>\n",
       "      <td>achterliggen</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{achterlagen, achterlig, achterligt, achterliggen, lagen achter, liggen achter, lag achter, achtergelegen, achterliggend, achterlag, ligt achter, lig achter}</td>\n",
       "      <td>{achterliggende}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>afstraffen</th>\n",
       "      <td>afstraffen</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{afstraffen, afstraf, afgestraft, afstraffend, afstrafte, afstraft, straft af, afstraften, straffen af, strafte af, straften af, straf af}</td>\n",
       "      <td>{afstraffende}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arresteren</th>\n",
       "      <td>arresteren</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{gearresteerd, arresteren, arresteer, arresteerden, arresterend, arresteert, arresteerde}</td>\n",
       "      <td>{gearresteerde}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>automatiseren</th>\n",
       "      <td>automatiseren</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{geautomatiseerd, automatiseert, automatiseer, automatiserend, automatiseerde, automatiseerden, automatiseren}</td>\n",
       "      <td>{geautomatiseerde}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>belangstellen</th>\n",
       "      <td>belangstellen</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{belangstellen, belangstellend, stelt belang, stellen belang, stelden belang, belangstelt, stel belang, stelde belang, belanggesteld, belangstelde, belangstel, belangstelden}</td>\n",
       "      <td>{belangstellenden}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bijkomen</th>\n",
       "      <td>bijkomen</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{komt bij, kom bij, bijkomen, bijkwamen, kwam bij, bijkomt, bijgekomen, bijkwam, kwamen bij, bijkom, bijkomend, komen bij}</td>\n",
       "      <td>{bijkomende}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bijpassen</th>\n",
       "      <td>bijpassen</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{pasten bij, pas bij, passen bij, paste bij, bijgepast, bijpas, bijpast, bijpassen, bijpaste, bijpasten, bijpassend, past bij}</td>\n",
       "      <td>{bijpassende}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boeien</th>\n",
       "      <td>boeien</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{boeit, boeiden, boeide, geboeid, boeiend, boeien, boei}</td>\n",
       "      <td>{boeiende}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buizen</th>\n",
       "      <td>buizen</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{buizen, buisden, buist, buizend, buisde, gebuisd, buis}</td>\n",
       "      <td>{gebuisde}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>controleren</th>\n",
       "      <td>controleren</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{controleert, controleerden, controleer, controleren, controlerend, gecontroleerd, controleerde}</td>\n",
       "      <td>{gecontroleerde}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drukken</th>\n",
       "      <td>drukken</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{drukken, druk, gedrukt, drukt, drukkend, drukten, drukte}</td>\n",
       "      <td>{gedrukte}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expliciteren</th>\n",
       "      <td>expliciteren</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{expliciteert, expliciteerde, expliciterend, expliciteer, expliciteren, geëxpliciteerd, expliciteerden}</td>\n",
       "      <td>{geëxpliciteerde}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interesseren</th>\n",
       "      <td>interesseren</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{interesseren, interesseerde, interesseer, geïnteresseerd, interesseerden, interesserend, interesseert}</td>\n",
       "      <td>{geïnteresseerden}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inzien</th>\n",
       "      <td>inzien</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{inziet, ingezien, zien in, zag in, inzag, inzie, zie in, zagen in, ziet in, inzien, inzagen, inziend}</td>\n",
       "      <td>{inziens}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jongen</th>\n",
       "      <td>jongen</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{jongden, jong, jongen, jongt, jongde, jongend, gejongd}</td>\n",
       "      <td>{jongens}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laken</th>\n",
       "      <td>laken</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{laken, lakend, laakte, gelaakt, laak, laakt, laakten}</td>\n",
       "      <td>{lakentjes}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liggen</th>\n",
       "      <td>liggen</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{lag, ligt, lig, liggen, lagen, gelegen, liggend}</td>\n",
       "      <td>{let, liggende}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maken</th>\n",
       "      <td>maken</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{maak, maakten, gemaakt, maakt, maakte, maken, makend}</td>\n",
       "      <td>{gebruikmaken}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missen</th>\n",
       "      <td>missen</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{missen, miste, mis, missend, misten, mist, gemist}</td>\n",
       "      <td>{gemiste}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noemen</th>\n",
       "      <td>noemen</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{noemt, noemde, noemden, genoemd, noem, noemen, noemend}</td>\n",
       "      <td>{genoemde}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omkeren</th>\n",
       "      <td>omkeren</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{omkeerde, omkeerden, omkeren, keerde om, omkeer, omkeert, omgekeerd, keerden om, omkerend, keert om, keer om, keren om}</td>\n",
       "      <td>{omgekeerde}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omringen</th>\n",
       "      <td>omringen</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{omringen, omringend, omringd, omringden, omringde, omring, omringt}</td>\n",
       "      <td>{omringende}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opleiden</th>\n",
       "      <td>opleiden</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{opleidde, opleidt, opgeleid, leiden op, opleidend, opleid, opleidden, leid op, opleiden, leidt op, leidden op, leidde op}</td>\n",
       "      <td>{opgeleide}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opperen</th>\n",
       "      <td>opperen</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{opperden, geopperd, opper, opperend, opperen, opperde, oppert}</td>\n",
       "      <td>{geopperde}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raken</th>\n",
       "      <td>raken</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{raak, raakte, raakten, geraakt, raken, raakt, rakend}</td>\n",
       "      <td>{geraken}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reden</th>\n",
       "      <td>reden</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{reden, reedden, gereed, redend, reedde, reedt, reed}</td>\n",
       "      <td>{redenen}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rieken</th>\n",
       "      <td>rieken</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{rieken, rook, riekten, geroken, roken, riekte, riekt, riekend, riek}</td>\n",
       "      <td>{riekende}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roken</th>\n",
       "      <td>roken</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{rook, roken, gerookt, rokend, rookt, rookte, rookten}</td>\n",
       "      <td>{gerookte}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roosteren</th>\n",
       "      <td>roosteren</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{rooster, roosterde, geroosterd, roosterden, roosteren, roosterend, roostert}</td>\n",
       "      <td>{geroosterde}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samenstellen</th>\n",
       "      <td>samenstellen</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{samenstelde, samenstelt, samengesteld, samenstelden, stellen samen, samenstellen, samenstel, stelt samen, stelden samen, samenstellend, stel samen, stelde samen}</td>\n",
       "      <td>{samenstellende}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samenvallen</th>\n",
       "      <td>samenvallen</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{valt samen, vielen samen, samenvallen, viel samen, samenvielen, samenvallend, samenviel, samenvalt, samenval, val samen, samengevallen, vallen samen}</td>\n",
       "      <td>{samenvallende}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selecteren</th>\n",
       "      <td>selecteren</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{selecterend, selecteerden, selecteren, selecteerde, geselecteerd, selecteer, selecteert}</td>\n",
       "      <td>{geselecteerde}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>structureren</th>\n",
       "      <td>structureren</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{gestructureerd, structureren, structureer, structureerden, structurerend, structureert, structureerde}</td>\n",
       "      <td>{gestructureerde}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>terugkeren</th>\n",
       "      <td>terugkeren</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{terugkeren, keren terug, terugkeer, keerde terug, terugkeerde, terugkeert, teruggekeerd, terugkeerden, keerden terug, terugkerend, keert terug, keer terug}</td>\n",
       "      <td>{terugkerende}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thuisblijven</th>\n",
       "      <td>thuisblijven</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{blijven thuis, thuisblijven, thuisgebleven, thuisbleven, thuisblijvend, bleef thuis, bleven thuis, thuisblijft, blijft thuis, thuisblijf, thuisbleef, blijf thuis}</td>\n",
       "      <td>{thuisblijvende}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trouwen</th>\n",
       "      <td>trouwen</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{trouwend, trouwen, trouwde, getrouwd, trouw, trouwden, trouwt}</td>\n",
       "      <td>{krijgen}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uitbreiden</th>\n",
       "      <td>uitbreiden</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{breidden uit, breid uit, breidt uit, breidde uit, uitbreidde, breiden uit, uitbreidend, uitbreidden, uitbreiden, uitbreidt, uitgebreid, uitbreid}</td>\n",
       "      <td>{uitgebreide}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uitlachen</th>\n",
       "      <td>uitlachen</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{lachen uit, lacht uit, lachten uit, uitlachen, lach uit, uitlachten, uitgelachen, uitlach, uitlachte, uitlachend, lachte uit, uitlacht}</td>\n",
       "      <td>{lachen}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uitsmeren</th>\n",
       "      <td>uitsmeren</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{smeren uit, uitsmerend, smeert uit, smeerde uit, uitsmeert, smeer uit, uitsmeren, smeerden uit, uitsmeer, uitsmeerden, uitgesmeerd, uitsmeerde}</td>\n",
       "      <td>{uitgesmeerde}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vallen</th>\n",
       "      <td>vallen</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{viel, valt, vallend, val, gevallen, vielen, vallen}</td>\n",
       "      <td>{door}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verplichten</th>\n",
       "      <td>verplichten</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{verplichten, verplichtend, verplichtten, verplichtte, verplicht}</td>\n",
       "      <td>{verplichte}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verwachten</th>\n",
       "      <td>verwachten</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{verwachtend, verwacht, verwachtte, verwachtten, verwachten}</td>\n",
       "      <td>{verwachte}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vorderen</th>\n",
       "      <td>vorderen</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{vorderen, vorderde, gevorderd, vorderden, vorderend, vordert, vorder}</td>\n",
       "      <td>{gevorderden}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wisselen</th>\n",
       "      <td>wisselen</td>\n",
       "      <td>VERB</td>\n",
       "      <td>{wisselen, wissel, wisselt, wisselden, gewisseld, wisselde, wisselend}</td>\n",
       "      <td>{wisselende}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       lemma   pos  \\\n",
       "lemmata                              \n",
       "achterliggen    achterliggen  VERB   \n",
       "afstraffen        afstraffen  VERB   \n",
       "arresteren        arresteren  VERB   \n",
       "automatiseren  automatiseren  VERB   \n",
       "belangstellen  belangstellen  VERB   \n",
       "bijkomen            bijkomen  VERB   \n",
       "bijpassen          bijpassen  VERB   \n",
       "boeien                boeien  VERB   \n",
       "buizen                buizen  VERB   \n",
       "controleren      controleren  VERB   \n",
       "drukken              drukken  VERB   \n",
       "expliciteren    expliciteren  VERB   \n",
       "interesseren    interesseren  VERB   \n",
       "inzien                inzien  VERB   \n",
       "jongen                jongen  VERB   \n",
       "laken                  laken  VERB   \n",
       "liggen                liggen  VERB   \n",
       "maken                  maken  VERB   \n",
       "missen                missen  VERB   \n",
       "noemen                noemen  VERB   \n",
       "omkeren              omkeren  VERB   \n",
       "omringen            omringen  VERB   \n",
       "opleiden            opleiden  VERB   \n",
       "opperen              opperen  VERB   \n",
       "raken                  raken  VERB   \n",
       "reden                  reden  VERB   \n",
       "rieken                rieken  VERB   \n",
       "roken                  roken  VERB   \n",
       "roosteren          roosteren  VERB   \n",
       "samenstellen    samenstellen  VERB   \n",
       "samenvallen      samenvallen  VERB   \n",
       "selecteren        selecteren  VERB   \n",
       "structureren    structureren  VERB   \n",
       "terugkeren        terugkeren  VERB   \n",
       "thuisblijven    thuisblijven  VERB   \n",
       "trouwen              trouwen  VERB   \n",
       "uitbreiden        uitbreiden  VERB   \n",
       "uitlachen          uitlachen  VERB   \n",
       "uitsmeren          uitsmeren  VERB   \n",
       "vallen                vallen  VERB   \n",
       "verplichten      verplichten  VERB   \n",
       "verwachten        verwachten  VERB   \n",
       "vorderen            vorderen  VERB   \n",
       "wisselen            wisselen  VERB   \n",
       "\n",
       "                                                                                                                                                                              known_wordforms  \\\n",
       "lemmata                                                                                                                                                                                         \n",
       "achterliggen                    {achterlagen, achterlig, achterligt, achterliggen, lagen achter, liggen achter, lag achter, achtergelegen, achterliggend, achterlag, ligt achter, lig achter}   \n",
       "afstraffen                                         {afstraffen, afstraf, afgestraft, afstraffend, afstrafte, afstraft, straft af, afstraften, straffen af, strafte af, straften af, straf af}   \n",
       "arresteren                                                                                          {gearresteerd, arresteren, arresteer, arresteerden, arresterend, arresteert, arresteerde}   \n",
       "automatiseren                                                                  {geautomatiseerd, automatiseert, automatiseer, automatiserend, automatiseerde, automatiseerden, automatiseren}   \n",
       "belangstellen  {belangstellen, belangstellend, stelt belang, stellen belang, stelden belang, belangstelt, stel belang, stelde belang, belanggesteld, belangstelde, belangstel, belangstelden}   \n",
       "bijkomen                                                           {komt bij, kom bij, bijkomen, bijkwamen, kwam bij, bijkomt, bijgekomen, bijkwam, kwamen bij, bijkom, bijkomend, komen bij}   \n",
       "bijpassen                                                      {pasten bij, pas bij, passen bij, paste bij, bijgepast, bijpas, bijpast, bijpassen, bijpaste, bijpasten, bijpassend, past bij}   \n",
       "boeien                                                                                                                               {boeit, boeiden, boeide, geboeid, boeiend, boeien, boei}   \n",
       "buizen                                                                                                                               {buizen, buisden, buist, buizend, buisde, gebuisd, buis}   \n",
       "controleren                                                                                  {controleert, controleerden, controleer, controleren, controlerend, gecontroleerd, controleerde}   \n",
       "drukken                                                                                                                            {drukken, druk, gedrukt, drukt, drukkend, drukten, drukte}   \n",
       "expliciteren                                                                          {expliciteert, expliciteerde, expliciterend, expliciteer, expliciteren, geëxpliciteerd, expliciteerden}   \n",
       "interesseren                                                                          {interesseren, interesseerde, interesseer, geïnteresseerd, interesseerden, interesserend, interesseert}   \n",
       "inzien                                                                                 {inziet, ingezien, zien in, zag in, inzag, inzie, zie in, zagen in, ziet in, inzien, inzagen, inziend}   \n",
       "jongen                                                                                                                               {jongden, jong, jongen, jongt, jongde, jongend, gejongd}   \n",
       "laken                                                                                                                                  {laken, lakend, laakte, gelaakt, laak, laakt, laakten}   \n",
       "liggen                                                                                                                                      {lag, ligt, lig, liggen, lagen, gelegen, liggend}   \n",
       "maken                                                                                                                                  {maak, maakten, gemaakt, maakt, maakte, maken, makend}   \n",
       "missen                                                                                                                                    {missen, miste, mis, missend, misten, mist, gemist}   \n",
       "noemen                                                                                                                               {noemt, noemde, noemden, genoemd, noem, noemen, noemend}   \n",
       "omkeren                                                              {omkeerde, omkeerden, omkeren, keerde om, omkeer, omkeert, omgekeerd, keerden om, omkerend, keert om, keer om, keren om}   \n",
       "omringen                                                                                                                 {omringen, omringend, omringd, omringden, omringde, omring, omringt}   \n",
       "opleiden                                                           {opleidde, opleidt, opgeleid, leiden op, opleidend, opleid, opleidden, leid op, opleiden, leidt op, leidden op, leidde op}   \n",
       "opperen                                                                                                                       {opperden, geopperd, opper, opperend, opperen, opperde, oppert}   \n",
       "raken                                                                                                                                  {raak, raakte, raakten, geraakt, raken, raakt, rakend}   \n",
       "reden                                                                                                                                   {reden, reedden, gereed, redend, reedde, reedt, reed}   \n",
       "rieken                                                                                                                  {rieken, rook, riekten, geroken, roken, riekte, riekt, riekend, riek}   \n",
       "roken                                                                                                                                  {rook, roken, gerookt, rokend, rookt, rookte, rookten}   \n",
       "roosteren                                                                                                       {rooster, roosterde, geroosterd, roosterden, roosteren, roosterend, roostert}   \n",
       "samenstellen               {samenstelde, samenstelt, samengesteld, samenstelden, stellen samen, samenstellen, samenstel, stelt samen, stelden samen, samenstellend, stel samen, stelde samen}   \n",
       "samenvallen                            {valt samen, vielen samen, samenvallen, viel samen, samenvielen, samenvallend, samenviel, samenvalt, samenval, val samen, samengevallen, vallen samen}   \n",
       "selecteren                                                                                          {selecterend, selecteerden, selecteren, selecteerde, geselecteerd, selecteer, selecteert}   \n",
       "structureren                                                                          {gestructureerd, structureren, structureer, structureerden, structurerend, structureert, structureerde}   \n",
       "terugkeren                       {terugkeren, keren terug, terugkeer, keerde terug, terugkeerde, terugkeert, teruggekeerd, terugkeerden, keerden terug, terugkerend, keert terug, keer terug}   \n",
       "thuisblijven              {blijven thuis, thuisblijven, thuisgebleven, thuisbleven, thuisblijvend, bleef thuis, bleven thuis, thuisblijft, blijft thuis, thuisblijf, thuisbleef, blijf thuis}   \n",
       "trouwen                                                                                                                       {trouwend, trouwen, trouwde, getrouwd, trouw, trouwden, trouwt}   \n",
       "uitbreiden                                 {breidden uit, breid uit, breidt uit, breidde uit, uitbreidde, breiden uit, uitbreidend, uitbreidden, uitbreiden, uitbreidt, uitgebreid, uitbreid}   \n",
       "uitlachen                                            {lachen uit, lacht uit, lachten uit, uitlachen, lach uit, uitlachten, uitgelachen, uitlach, uitlachte, uitlachend, lachte uit, uitlacht}   \n",
       "uitsmeren                                    {smeren uit, uitsmerend, smeert uit, smeerde uit, uitsmeert, smeer uit, uitsmeren, smeerden uit, uitsmeer, uitsmeerden, uitgesmeerd, uitsmeerde}   \n",
       "vallen                                                                                                                                   {viel, valt, vallend, val, gevallen, vielen, vallen}   \n",
       "verplichten                                                                                                                 {verplichten, verplichtend, verplichtten, verplichtte, verplicht}   \n",
       "verwachten                                                                                                                       {verwachtend, verwacht, verwachtte, verwachtten, verwachten}   \n",
       "vorderen                                                                                                               {vorderen, vorderde, gevorderd, vorderden, vorderend, vordert, vorder}   \n",
       "wisselen                                                                                                               {wisselen, wissel, wisselt, wisselden, gewisseld, wisselde, wisselend}   \n",
       "\n",
       "                unknown_wordforms  \n",
       "lemmata                            \n",
       "achterliggen     {achterliggende}  \n",
       "afstraffen         {afstraffende}  \n",
       "arresteren        {gearresteerde}  \n",
       "automatiseren  {geautomatiseerde}  \n",
       "belangstellen  {belangstellenden}  \n",
       "bijkomen             {bijkomende}  \n",
       "bijpassen           {bijpassende}  \n",
       "boeien                 {boeiende}  \n",
       "buizen                 {gebuisde}  \n",
       "controleren      {gecontroleerde}  \n",
       "drukken                {gedrukte}  \n",
       "expliciteren    {geëxpliciteerde}  \n",
       "interesseren   {geïnteresseerden}  \n",
       "inzien                  {inziens}  \n",
       "jongen                  {jongens}  \n",
       "laken                 {lakentjes}  \n",
       "liggen            {let, liggende}  \n",
       "maken              {gebruikmaken}  \n",
       "missen                  {gemiste}  \n",
       "noemen                 {genoemde}  \n",
       "omkeren              {omgekeerde}  \n",
       "omringen             {omringende}  \n",
       "opleiden              {opgeleide}  \n",
       "opperen               {geopperde}  \n",
       "raken                   {geraken}  \n",
       "reden                   {redenen}  \n",
       "rieken                 {riekende}  \n",
       "roken                  {gerookte}  \n",
       "roosteren           {geroosterde}  \n",
       "samenstellen     {samenstellende}  \n",
       "samenvallen       {samenvallende}  \n",
       "selecteren        {geselecteerde}  \n",
       "structureren    {gestructureerde}  \n",
       "terugkeren         {terugkerende}  \n",
       "thuisblijven     {thuisblijvende}  \n",
       "trouwen                 {krijgen}  \n",
       "uitbreiden          {uitgebreide}  \n",
       "uitlachen                {lachen}  \n",
       "uitsmeren          {uitgesmeerde}  \n",
       "vallen                     {door}  \n",
       "verplichten          {verplichte}  \n",
       "verwachten            {verwachte}  \n",
       "vorderen            {gevorderden}  \n",
       "wisselen             {wisselende}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "base_lexicon=\"molex\"\n",
    "corpus_to_search=\"opensonar\"\n",
    "\n",
    "df = get_missing_wordforms(base_lexicon, \"VERB\", corpus_to_search)\n",
    "\n",
    "df.to_csv( \"missing_wordforms.csv\", index=False)\n",
    "#df = load_dataframe(\"missing_wordforms.csv\")\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study: Train a tagger with data from an annotated corpus, an do something cool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Number</th>\n",
       "      <th>hyphenation</th>\n",
       "      <th>lemEntryId</th>\n",
       "      <th>lemPos</th>\n",
       "      <th>lemma</th>\n",
       "      <th>wordform</th>\n",
       "      <th>wordformId</th>\n",
       "      <th>wordformPos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://universaldependencies.org/u/feat/Gender.html#Masc</td>\n",
       "      <td>http://universaldependencies.org/u/feat/Number.html#Sing</td>\n",
       "      <td>loop</td>\n",
       "      <td>http://rdf.ivdnt.org/lexica/diamant/entry/molex/45573</td>\n",
       "      <td>http://universaldependencies.org/u/pos/NOUN</td>\n",
       "      <td>loop</td>\n",
       "      <td>loop</td>\n",
       "      <td>http://rdf.ivdnt.org/lexica/diamant/wordform/molex/89078</td>\n",
       "      <td>http://universaldependencies.org/u/pos/NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://universaldependencies.org/u/feat/Gender.html#Masc</td>\n",
       "      <td>http://universaldependencies.org/u/feat/Number.html#Plur</td>\n",
       "      <td>lo/pen</td>\n",
       "      <td>http://rdf.ivdnt.org/lexica/diamant/entry/molex/45573</td>\n",
       "      <td>http://universaldependencies.org/u/pos/NOUN</td>\n",
       "      <td>loop</td>\n",
       "      <td>lopen</td>\n",
       "      <td>http://rdf.ivdnt.org/lexica/diamant/wordform/molex/156030</td>\n",
       "      <td>http://universaldependencies.org/u/pos/NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://universaldependencies.org/u/feat/Gender.html#Masc</td>\n",
       "      <td>http://universaldependencies.org/u/feat/Number.html#Sing</td>\n",
       "      <td>loop</td>\n",
       "      <td>http://rdf.ivdnt.org/lexica/diamant/entry/molex/45573</td>\n",
       "      <td>http://universaldependencies.org/u/pos/NOUN</td>\n",
       "      <td>loop</td>\n",
       "      <td>loop</td>\n",
       "      <td>http://rdf.ivdnt.org/lexica/diamant/wordform/molex/89078</td>\n",
       "      <td>http://universaldependencies.org/u/pos/NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>http://universaldependencies.org/u/feat/Number.html#Sing</td>\n",
       "      <td>loop</td>\n",
       "      <td>http://rdf.ivdnt.org/lexica/diamant/entry/molex/106637</td>\n",
       "      <td>http://universaldependencies.org/u/pos/VERB</td>\n",
       "      <td>lopen</td>\n",
       "      <td>loop</td>\n",
       "      <td>http://rdf.ivdnt.org/lexica/diamant/wordform/molex/560193</td>\n",
       "      <td>http://universaldependencies.org/u/pos/VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>http://universaldependencies.org/u/feat/Number.html#Sing</td>\n",
       "      <td>loop</td>\n",
       "      <td>http://rdf.ivdnt.org/lexica/diamant/entry/molex/106637</td>\n",
       "      <td>http://universaldependencies.org/u/pos/VERB</td>\n",
       "      <td>lopen</td>\n",
       "      <td>loop</td>\n",
       "      <td>http://rdf.ivdnt.org/lexica/diamant/wordform/molex/822354</td>\n",
       "      <td>http://universaldependencies.org/u/pos/VERB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Gender  \\\n",
       "0  http://universaldependencies.org/u/feat/Gender.html#Masc   \n",
       "1  http://universaldependencies.org/u/feat/Gender.html#Masc   \n",
       "2  http://universaldependencies.org/u/feat/Gender.html#Masc   \n",
       "3                                                             \n",
       "4                                                             \n",
       "\n",
       "                                                     Number hyphenation  \\\n",
       "0  http://universaldependencies.org/u/feat/Number.html#Sing        loop   \n",
       "1  http://universaldependencies.org/u/feat/Number.html#Plur      lo/pen   \n",
       "2  http://universaldependencies.org/u/feat/Number.html#Sing        loop   \n",
       "3  http://universaldependencies.org/u/feat/Number.html#Sing        loop   \n",
       "4  http://universaldependencies.org/u/feat/Number.html#Sing        loop   \n",
       "\n",
       "                                               lemEntryId  \\\n",
       "0   http://rdf.ivdnt.org/lexica/diamant/entry/molex/45573   \n",
       "1   http://rdf.ivdnt.org/lexica/diamant/entry/molex/45573   \n",
       "2   http://rdf.ivdnt.org/lexica/diamant/entry/molex/45573   \n",
       "3  http://rdf.ivdnt.org/lexica/diamant/entry/molex/106637   \n",
       "4  http://rdf.ivdnt.org/lexica/diamant/entry/molex/106637   \n",
       "\n",
       "                                        lemPos  lemma wordform  \\\n",
       "0  http://universaldependencies.org/u/pos/NOUN   loop     loop   \n",
       "1  http://universaldependencies.org/u/pos/NOUN   loop    lopen   \n",
       "2  http://universaldependencies.org/u/pos/NOUN   loop     loop   \n",
       "3  http://universaldependencies.org/u/pos/VERB  lopen     loop   \n",
       "4  http://universaldependencies.org/u/pos/VERB  lopen     loop   \n",
       "\n",
       "                                                  wordformId  \\\n",
       "0   http://rdf.ivdnt.org/lexica/diamant/wordform/molex/89078   \n",
       "1  http://rdf.ivdnt.org/lexica/diamant/wordform/molex/156030   \n",
       "2   http://rdf.ivdnt.org/lexica/diamant/wordform/molex/89078   \n",
       "3  http://rdf.ivdnt.org/lexica/diamant/wordform/molex/560193   \n",
       "4  http://rdf.ivdnt.org/lexica/diamant/wordform/molex/822354   \n",
       "\n",
       "                                   wordformPos  \n",
       "0  http://universaldependencies.org/u/pos/NOUN  \n",
       "1  http://universaldependencies.org/u/pos/NOUN  \n",
       "2  http://universaldependencies.org/u/pos/NOUN  \n",
       "3  http://universaldependencies.org/u/pos/VERB  \n",
       "4  http://universaldependencies.org/u/pos/VERB  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://portal.clarin.inl.nl/fcscorpora/clariah-fcs-endpoints/sru?operation=searchRetrieve&queryType=fcs&maximumRecords=1000&x-fcs-context=opensonar&query=%5Bword%3D%22loop%22%5D\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma 0</th>\n",
       "      <th>lemma 1</th>\n",
       "      <th>lemma 2</th>\n",
       "      <th>lemma 3</th>\n",
       "      <th>lemma 4</th>\n",
       "      <th>lemma 5</th>\n",
       "      <th>lemma 6</th>\n",
       "      <th>lemma 7</th>\n",
       "      <th>lemma 8</th>\n",
       "      <th>lemma 9</th>\n",
       "      <th>...</th>\n",
       "      <th>word 1</th>\n",
       "      <th>word 2</th>\n",
       "      <th>word 3</th>\n",
       "      <th>word 4</th>\n",
       "      <th>word 5</th>\n",
       "      <th>word 6</th>\n",
       "      <th>word 7</th>\n",
       "      <th>word 8</th>\n",
       "      <th>word 9</th>\n",
       "      <th>word 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intuïtie</td>\n",
       "      <td>kreeft</td>\n",
       "      <td>:</td>\n",
       "      <td>advies</td>\n",
       "      <td>:</td>\n",
       "      <td>lopen</td>\n",
       "      <td>niet</td>\n",
       "      <td>te</td>\n",
       "      <td>hard</td>\n",
       "      <td>van</td>\n",
       "      <td>...</td>\n",
       "      <td>kreeft</td>\n",
       "      <td>:</td>\n",
       "      <td>advies</td>\n",
       "      <td>:</td>\n",
       "      <td>loop</td>\n",
       "      <td>niet</td>\n",
       "      <td>te</td>\n",
       "      <td>hard</td>\n",
       "      <td>van</td>\n",
       "      <td>stapel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bewaken</td>\n",
       "      <td>zodat</td>\n",
       "      <td>ik</td>\n",
       "      <td>geen</td>\n",
       "      <td>risico</td>\n",
       "      <td>loop</td>\n",
       "      <td>ivm</td>\n",
       "      <td>inbraak</td>\n",
       "      <td>enz</td>\n",
       "      <td>enz</td>\n",
       "      <td>...</td>\n",
       "      <td>zodat</td>\n",
       "      <td>ik</td>\n",
       "      <td>geen</td>\n",
       "      <td>risico</td>\n",
       "      <td>loop</td>\n",
       "      <td>ivm</td>\n",
       "      <td>inbraken</td>\n",
       "      <td>enz</td>\n",
       "      <td>enz</td>\n",
       "      <td>Jij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rennen</td>\n",
       "      <td>naar</td>\n",
       "      <td>buiten</td>\n",
       "      <td>..</td>\n",
       "      <td>ik</td>\n",
       "      <td>lopen</td>\n",
       "      <td>naar</td>\n",
       "      <td>een</td>\n",
       "      <td>paar</td>\n",
       "      <td>auto\\</td>\n",
       "      <td>...</td>\n",
       "      <td>naar</td>\n",
       "      <td>buiten</td>\n",
       "      <td>..</td>\n",
       "      <td>Ik</td>\n",
       "      <td>loop</td>\n",
       "      <td>naar</td>\n",
       "      <td>een</td>\n",
       "      <td>paar</td>\n",
       "      <td>auto\\'s</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>denken</td>\n",
       "      <td>zullen</td>\n",
       "      <td>beïnvloeden</td>\n",
       "      <td>in</td>\n",
       "      <td>de</td>\n",
       "      <td>loop</td>\n",
       "      <td>van</td>\n",
       "      <td>de</td>\n",
       "      <td>volgend</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>zal</td>\n",
       "      <td>beïnvloeden</td>\n",
       "      <td>in</td>\n",
       "      <td>de</td>\n",
       "      <td>loop</td>\n",
       "      <td>van</td>\n",
       "      <td>de</td>\n",
       "      <td>volgende</td>\n",
       "      <td>25</td>\n",
       "      <td>jaar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nou</td>\n",
       "      <td>dat</td>\n",
       "      <td>kloppen</td>\n",
       "      <td>,</td>\n",
       "      <td>ik</td>\n",
       "      <td>loop</td>\n",
       "      <td>sinds</td>\n",
       "      <td>gisteren</td>\n",
       "      <td>niet</td>\n",
       "      <td>veel</td>\n",
       "      <td>...</td>\n",
       "      <td>dat</td>\n",
       "      <td>klopt</td>\n",
       "      <td>,</td>\n",
       "      <td>ik</td>\n",
       "      <td>loop</td>\n",
       "      <td>sinds</td>\n",
       "      <td>gisteren</td>\n",
       "      <td>niet</td>\n",
       "      <td>meer</td>\n",
       "      <td>zo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>de</td>\n",
       "      <td>mens</td>\n",
       "      <td>er</td>\n",
       "      <td>in</td>\n",
       "      <td>de</td>\n",
       "      <td>loop</td>\n",
       "      <td>van</td>\n",
       "      <td>de</td>\n",
       "      <td>eeuw</td>\n",
       "      <td>mee</td>\n",
       "      <td>...</td>\n",
       "      <td>mens</td>\n",
       "      <td>er</td>\n",
       "      <td>in</td>\n",
       "      <td>de</td>\n",
       "      <td>loop</td>\n",
       "      <td>van</td>\n",
       "      <td>de</td>\n",
       "      <td>eeuwen</td>\n",
       "      <td>mee</td>\n",
       "      <td>deed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weer</td>\n",
       "      <td>over</td>\n",
       "      <td>gaan</td>\n",
       "      <td>in</td>\n",
       "      <td>de</td>\n",
       "      <td>loop</td>\n",
       "      <td>van</td>\n",
       "      <td>de</td>\n",
       "      <td>tijd</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>over</td>\n",
       "      <td>gaat</td>\n",
       "      <td>in</td>\n",
       "      <td>de</td>\n",
       "      <td>loop</td>\n",
       "      <td>van</td>\n",
       "      <td>de</td>\n",
       "      <td>tijd</td>\n",
       "      <td>.</td>\n",
       "      <td>Mij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>boembaloe</td>\n",
       "      <td>ik</td>\n",
       "      <td>lopen</td>\n",
       "      <td>al</td>\n",
       "      <td>dag</td>\n",
       "      <td>het</td>\n",
       "      <td>lied</td>\n",
       "      <td>van</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PRON</td>\n",
       "      <td>...</td>\n",
       "      <td>van</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>due</td>\n",
       "      <td>to</td>\n",
       "      <td>a</td>\n",
       "      <td>positive</td>\n",
       "      <td>feedback</td>\n",
       "      <td>loop</td>\n",
       "      <td>.</td>\n",
       "      <td>As</td>\n",
       "      <td>sea</td>\n",
       "      <td>ice</td>\n",
       "      <td>...</td>\n",
       "      <td>to</td>\n",
       "      <td>a</td>\n",
       "      <td>positive</td>\n",
       "      <td>feedback</td>\n",
       "      <td>loop</td>\n",
       "      <td>.</td>\n",
       "      <td>As</td>\n",
       "      <td>sea</td>\n",
       "      <td>ice</td>\n",
       "      <td>melts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aan</td>\n",
       "      <td>men</td>\n",
       "      <td>hart</td>\n",
       "      <td>liggen</td>\n",
       "      <td>,</td>\n",
       "      <td>lopen</td>\n",
       "      <td>gewoon</td>\n",
       "      <td>verlore</td>\n",
       "      <td>;</td>\n",
       "      <td>weten</td>\n",
       "      <td>...</td>\n",
       "      <td>men</td>\n",
       "      <td>hart</td>\n",
       "      <td>ligt</td>\n",
       "      <td>,</td>\n",
       "      <td>loop</td>\n",
       "      <td>gewoon</td>\n",
       "      <td>verlore</td>\n",
       "      <td>;</td>\n",
       "      <td>weet</td>\n",
       "      <td>met</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     lemma 0 lemma 1      lemma 2   lemma 3   lemma 4 lemma 5 lemma 6  \\\n",
       "0   intuïtie  kreeft            :    advies         :   lopen    niet   \n",
       "1    bewaken   zodat           ik      geen    risico    loop     ivm   \n",
       "2     rennen    naar       buiten        ..        ik   lopen    naar   \n",
       "3     denken  zullen  beïnvloeden        in        de    loop     van   \n",
       "4        nou     dat      kloppen         ,        ik    loop   sinds   \n",
       "5         de    mens           er        in        de    loop     van   \n",
       "6       weer    over         gaan        in        de    loop     van   \n",
       "7  boembaloe      ik        lopen        al       dag     het    lied   \n",
       "8        due      to            a  positive  feedback    loop       .   \n",
       "9        aan     men         hart    liggen         ,   lopen  gewoon   \n",
       "\n",
       "    lemma 7  lemma 8 lemma 9   ...    word 1       word 2    word 3    word 4  \\\n",
       "0        te     hard     van   ...    kreeft            :    advies         :   \n",
       "1   inbraak      enz     enz   ...     zodat           ik      geen    risico   \n",
       "2       een     paar   auto\\   ...      naar       buiten        ..        Ik   \n",
       "3        de  volgend      25   ...       zal  beïnvloeden        in        de   \n",
       "4  gisteren     niet    veel   ...       dat        klopt         ,        ik   \n",
       "5        de     eeuw     mee   ...      mens           er        in        de   \n",
       "6        de     tijd       .   ...      over         gaat        in        de   \n",
       "7       van     NOUN    PRON   ...       van         None      None      None   \n",
       "8        As      sea     ice   ...        to            a  positive  feedback   \n",
       "9   verlore        ;   weten   ...       men         hart      ligt         ,   \n",
       "\n",
       "  word 5  word 6    word 7    word 8   word 9 word 10  \n",
       "0   loop    niet        te      hard      van  stapel  \n",
       "1   loop     ivm  inbraken       enz      enz     Jij  \n",
       "2   loop    naar       een      paar  auto\\'s     die  \n",
       "3   loop     van        de  volgende       25    jaar  \n",
       "4   loop   sinds  gisteren      niet     meer      zo  \n",
       "5   loop     van        de    eeuwen      mee    deed  \n",
       "6   loop     van        de      tijd        .     Mij  \n",
       "7   None    None      None      None     None    None  \n",
       "8   loop       .        As       sea      ice   melts  \n",
       "9   loop  gewoon   verlore         ;     weet     met  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nr_of_words_per_sentence = 11\n",
      "[[('intuïtie', 'NOUN'), ('kreeft', 'NOUN'), (':', 'PUNCT'), ('advies', 'NOUN'), (':', 'PUNCT'), ('loop', 'VERB'), ('niet', 'ADV'), ('te', 'ADV'), ('hard', 'ADJ'), ('van', 'ADP'), ('stapel', 'NOUN')], [('bewaken', 'VERB'), ('zodat', 'SCONJ'), ('ik', 'PRON'), ('geen', 'DET'), ('risico', 'NOUN'), ('loop', 'NOUN'), ('ivm', 'NOUN'), ('inbraken', 'NOUN'), ('enz', 'SYM OR X'), ('enz', 'SYM OR X'), ('Jij', 'PRON')], [('ren', 'VERB'), ('naar', 'ADP'), ('buiten', 'ADP'), ('..', 'PUNCT'), ('Ik', 'PRON'), ('loop', 'VERB'), ('naar', 'ADP'), ('een', 'DET'), ('paar', 'NOUN'), (\"auto\\\\'s\", 'NOUN'), ('die', 'PRON')], [('denken', 'VERB'), ('zal', 'VERB'), ('beïnvloeden', 'VERB'), ('in', 'ADP'), ('de', 'DET'), ('loop', 'NOUN'), ('van', 'ADP'), ('de', 'DET'), ('volgende', 'VERB'), ('25', 'NUM'), ('jaar', 'NOUN')], [('nou', 'ADV'), ('dat', 'PRON'), ('klopt', 'VERB'), (',', 'PUNCT'), ('ik', 'PRON'), ('loop', 'NOUN'), ('sinds', 'ADP'), ('gisteren', 'ADV'), ('niet', 'ADV'), ('meer', 'PRON'), ('zo', 'ADV')], [('de', 'DET'), ('mens', 'NOUN'), ('er', 'PRON'), ('in', 'ADP'), ('de', 'DET'), ('loop', 'NOUN'), ('van', 'ADP'), ('de', 'DET'), ('eeuwen', 'NOUN'), ('mee', 'ADP'), ('deed', 'VERB')], [('weer', 'ADV'), ('over', 'ADP'), ('gaat', 'VERB'), ('in', 'ADP'), ('de', 'DET'), ('loop', 'NOUN'), ('van', 'ADP'), ('de', 'DET'), ('tijd', 'NOUN'), ('.', 'PUNCT'), ('Mij', 'PRON')], [('due', 'SYM OR X'), ('to', 'SYM OR X'), ('a', 'SYM OR X'), ('positive', 'SYM OR X'), ('feedback', 'NOUN'), ('loop', 'NOUN'), ('.', 'PUNCT'), ('As', 'PROPN'), ('sea', 'SYM OR X'), ('ice', 'SYM OR X'), ('melts', 'SYM OR X')], [('aan', 'ADP'), ('men', 'PRON'), ('hart', 'NOUN'), ('ligt', 'VERB'), (',', 'PUNCT'), ('loop', 'VERB'), ('gewoon', 'ADJ'), ('verlore', 'ADJ'), (';', 'PUNCT'), ('weet', 'VERB'), ('met', 'ADP')]]\n",
      "<class 'list'>\n",
      "training now...\n",
      "tagging now...\n",
      "[('Mijn', 'PUNCT'), ('buurman', 'PRON'), ('kijkt', 'PUNCT'), ('door', 'ADP'), ('de', 'DET'), ('loop', 'NOUN'), ('van', 'ADP'), ('zijn', 'NOUN'), ('geweer', 'ADV')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag.perceptron import PerceptronTagger\n",
    "\n",
    "base_lexicon=\"molex\"\n",
    "corpus_to_search=\"opensonar\"\n",
    "\n",
    "# we have a given word, let's say: \"loop\"\n",
    "some_word = \"loop\"\n",
    "\n",
    "# get the paradigm of the lemma our word is a part of\n",
    "query = lexicon_query(some_word, pos=None, lexicon=base_lexicon)\n",
    "df_paradigm = search_lexicon(query, base_lexicon)\n",
    "display(df_paradigm)\n",
    "\n",
    "# gather some pattern including our word, out of an annotated corpus\n",
    "# here: DET + ADJ + 'loop'\n",
    "df_corpus = search_corpus(query=r'[word=\"' + some_word + r'\"]', corpus=corpus_to_search, hits_only=False)\n",
    "\n",
    "display(df_corpus)\n",
    "\n",
    "# Train a tagger with the corpus annotations\n",
    "# The input must be like: tagger.train([ [('today','NN'),('is','VBZ'),('good','JJ'),('day','NN')], [...] ])\n",
    "\n",
    "collocations = []\n",
    "nr_of_words_per_sentence = int( df_corpus.shape[1] / 3 )  # divided by the number of information layers (lemma, pos, wordform)\n",
    "print(\"nr_of_words_per_sentence = \" + str(nr_of_words_per_sentence))\n",
    "\n",
    "for index, row in df_corpus.iterrows():\n",
    "    one_collocation =  []\n",
    "    wrong = False\n",
    "    for i in range(0, nr_of_words_per_sentence, 1): \n",
    "        tuple = ( row['word '+str(i)], row['pos '+str(i)] )\n",
    "        one_collocation.append( tuple )\n",
    "        if (row['word '+str(i)] is None or row['pos '+str(i)] is None):\n",
    "            wrong = True\n",
    "    if wrong is False:\n",
    "        collocations.append(one_collocation)\n",
    "    \n",
    "print(collocations)\n",
    "\n",
    "print(type(collocations))\n",
    "\n",
    "\n",
    "print('training now...')\n",
    "tagger = PerceptronTagger(load=False)\n",
    "tagger.train(collocations)\n",
    "\n",
    "# Use the trained tagger to tag unknown collocations\n",
    "# The input must be like: tagger.tag(['today','is','a','beautiful','day'])\n",
    "\n",
    "print('tagging now...')\n",
    "sentence = 'Mijn buurman kijkt door de loop van zijn geweer'\n",
    "tagged_sentence = tagger.tag( sentence.split() )\n",
    "\n",
    "print(tagged_sentence)\n",
    "\n",
    "\n",
    "# Know we can lemmatize each occurence of our lemma in the new sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs_env",
   "language": "python",
   "name": "cs_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
