{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chaining search\n",
    "\n",
    "\n",
    "\n",
    "## Sphinx documentatie: https://pythonhosted.org/an_example_pypi_project/sphinx.html\n",
    "## in voorbeelden handige python functies opnemen\n",
    "## zoals ; .sort_values(ascending=False,by=['raw_freq']));  list enz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library functions: Search\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T14:23:23.808462Z",
     "start_time": "2019-02-08T14:23:23.521657Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.tag.perceptron import PerceptronTagger\n",
    "\n",
    "def filter_df(df, column, method, regex_or_set):\n",
    "    '''\n",
    "    Return a Pandas DataFrame filtered according to a set of parameters\n",
    "    Args:\n",
    "        df: Pandas DataFrame to filter on\n",
    "        df: column on which we filter\n",
    "        method: \"regex\" of \"isin\"\n",
    "        regex_or_set: Regular expression (if method==\"regex\") or set (if method==\"isin\")\n",
    "    '''\n",
    "    \n",
    "    if method==\"regex\":\n",
    "        filter_condition = df[column].str.contains(regex_or_set)\n",
    "    elif method==\"isin\":\n",
    "        filter_condition = df[column].isin(regex_or_set)\n",
    "    else:\n",
    "        raise ValueError(\"method should be one of regex or isin\")\n",
    "    return df[filter_condition]\n",
    "    \n",
    "\n",
    "\n",
    "def concat_df(df_arr, keys_arr=None):\n",
    "    '''\n",
    "    This function concatenates two dataframes \n",
    "    Args:\n",
    "        df_arr: array of Pandas DataFrames\n",
    "        keys_arr: array of keys to assign to the records of each DataFrame, so we can still distinguish the original DataFrames\n",
    "    Returns:\n",
    "        a single Pandas DataFrame \n",
    "        \n",
    "    >>> new_df = concat_df( [dataframe1, dataframe2, dataframe3], ['chn corpus', 'nederlab', 'opensonar'] )\n",
    "    >>> display_df(new_df)\n",
    "    '''\n",
    "    # ref: https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html\n",
    "    \n",
    "    if keys_arr is not None:\n",
    "        concat_df = pd.concat( df_arr, keys=keys_arr )\n",
    "    else:\n",
    "        concat_df = pd.concat( df_arr )\n",
    "    \n",
    "    return concat_df\n",
    "\n",
    "\n",
    "\n",
    "def join_df(df_arr, join_type=None):\n",
    "    \n",
    "    '''\n",
    "    This function joins two dataframes (=concat along axis 1) \n",
    "    Args:\n",
    "        df_arr: array of Pandas DataFrames\n",
    "        join_type: {inner, outer (default)}\n",
    "    Returns:\n",
    "        a single Pandas DataFrame \n",
    "        \n",
    "    >>> new_df = join_df( [dataframe1, dataframe2] )\n",
    "    >>> display_df(new_df)\n",
    "    '''\n",
    "    \n",
    "    # ref: https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html\n",
    "    \n",
    "    if join is None:\n",
    "        concat_df = pd.concat( df_arr, axis=1 )\n",
    "    else:\n",
    "        concat_df = pd.concat( df_arr, axis=1, join=join_type )\n",
    "    \n",
    "    return concat_df\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "def get_tagger(df_corpus):\n",
    "    '''\n",
    "    This function instantiates a tagger trained with some corpus annotations \n",
    "    Args:\n",
    "        df_corpus: Pandas DataFrame with annotated corpus data\n",
    "    Returns:\n",
    "        a PerceptronTagger instance \n",
    "    \n",
    "    >>> tagger = get_tagger(df_corpus)  # df_corpus containes a Pandas DataFrame with lots of corpus data\n",
    "    >>> sentence = 'Here is some beautiful sentence'\n",
    "    >>> tagged_sentence = tagger.tag( sentence.split() )\n",
    "    >>> print(tagged_sentence) \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # The corpus DataFrame consists of a number of sentences (rows) with a fixed number of tokens.\n",
    "    # Each token has a fixed number of layers holding info like: lemma, wordform or part-of-speech. \n",
    "    # As a result, the number of columns of each row = [number of tokens] x [number of layers]\n",
    "    \n",
    "    # To be able to feed the tagger correctly, we need to compute the number of layers,\n",
    "    # so we can infer the number of tokens the sentences hold. This is because\n",
    "    # the tagger expects us to feed it with arrays with length = [number of tokens], as elements of\n",
    "    # one single array holding all sentences arrays (see below).\n",
    "    \n",
    "    # So, determine how many layers (lemma, pos, wordform) we have \n",
    "    column_names = list(df_corpus.columns.values)\n",
    "    for n, val in enumerate(column_names):\n",
    "        # remove the numbers at the end of the layers names (lemma 1, lemma 2, ..., pos 1, pos 2, ...)\n",
    "        # so we end up with clean layers name only\n",
    "        column_names[n] = val.split(' ')[0] \n",
    "    number_of_layers = len(set(column_names))\n",
    "\n",
    "    # Now we can determine the standard length of our corpus sentences: that can be computed \n",
    "    # by dividing the number of columns of the corpus DataFrame by the number of layers\n",
    "    # we just computed.\n",
    "    sentences = []\n",
    "    nr_of_words_per_sentence = int( df_corpus.shape[1] / number_of_layers )  \n",
    "\n",
    "    # Build training data for the tagger in the right format\n",
    "    # The input must be like: [ [('today','NN'),('is','VBZ'),('good','JJ'),('day','NN')], [...] ]\n",
    "    for index, row in df_corpus.iterrows():\n",
    "        one_sentence =  []\n",
    "        wrong = False\n",
    "        for i in range(0, nr_of_words_per_sentence, 1): \n",
    "            tuple = ( row['word '+str(i)], row['pos '+str(i)] )\n",
    "            one_sentence.append( tuple )\n",
    "            if (row['word '+str(i)] is None or row['pos '+str(i)] is None):\n",
    "                wrong = True\n",
    "        if wrong is False:\n",
    "            sentences.append(one_sentence)\n",
    "\n",
    "    # Instantiate and train the tagger now\n",
    "    tagger = PerceptronTagger(load=False)\n",
    "    tagger.train(sentences)\n",
    "    \n",
    "    return tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T15:42:14.160612Z",
     "start_time": "2019-02-08T15:42:13.887816Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "import urllib\n",
    "#import wx   # for interaction popups          TODO -> omzetten naar JS of zo\n",
    "import itertools # for frequency list function and from_iterable\n",
    "import numpy     # idem\n",
    "from IPython.display import FileLink, FileLinks\n",
    "AVAILABLE_CORPORA = {'chn':'http://svprmc05.inl.nl/blacklab-server/chn',\n",
    "                     'opensonar':'http://172.16.10.93:8080/blacklab-server/opensonar',\n",
    "                     'zeebrieven':'http://svprmc20.ivdnt.org/blacklab-server/zeebrieven',\n",
    "                     'gysseling':'http://svprmc20.ivdnt.org/blacklab-server/gysseling',\n",
    "                     'nederlab':''}\n",
    "RECORDS_PER_PAGE = 1000\n",
    "\n",
    "# Fields parsed by default from corpus xml by _parse_xml\n",
    "# Extra fields can be given to _parse_xml by users\n",
    "DEFAULT_FIELDS_TOKEN = [\"word\", \"lemma\", \"universal_dependency\"]\n",
    "DEFAULT_FIELDS_DOC = []\n",
    "\n",
    "# Get rid of ellipsis in display (otherwise relevant data might not be shown)\n",
    "pd.set_option('display.max_colwidth',1000)\n",
    "\n",
    "\n",
    "\n",
    "# Search methods\n",
    "\n",
    "def search_corpus_allwords(corpus, pos=None):\n",
    "    '''\n",
    "    This function gets all words of a corpus. If needed, the output can be restricted to words with a given part-of-speech\n",
    "    Args:\n",
    "        corpus: corpus name\n",
    "        pos: part-of-speech (optional)\n",
    "    Returns:\n",
    "        a Pandas DataFrame containing corpus data\n",
    "        \n",
    "    >>> df_corpus = search_corpus_allwords(\"gysseling\")\n",
    "    >>> display_df(df_corpus)\n",
    "    '''\n",
    "    \n",
    "    query = r'[word=\".*\"]'\n",
    "    if pos is not None:\n",
    "        query = r'[word=\".*\" & pos=\"'+pos+r'\"]'\n",
    "    return search_corpus(query, corpus)\n",
    "\n",
    "def search_corpus_alllemmata(corpus, pos):\n",
    "    '''\n",
    "    This function gets all lemmata of a corpus. If needed, the output can be restricted to lemmata with a given part-of-speech\n",
    "    Args:\n",
    "        corpus: corpus name\n",
    "        pos: part-of-speech (optional)\n",
    "    Returns:\n",
    "        a Pandas DataFrame containing corpus data\n",
    "        \n",
    "    >>> df_corpus = search_corpus_alllemmata(\"chn\")\n",
    "    >>> display_df(df_corpus)\n",
    "    '''\n",
    "    \n",
    "    query = r'[lemma=\".*\"]'\n",
    "    if pos is not None:\n",
    "        query = r'[lemma=\".*\" & pos=\"'+pos+r'\"]'\n",
    "    return search_corpus(query, corpus) \n",
    "\n",
    "def search_corpus(query, corpus, start_position=1, detailed_context=False, extra_fields_doc=[], extra_fields_token=[]):\n",
    "    '''\n",
    "    This function searches a corpus given a query and a corpus name\n",
    "    Args:\n",
    "        query: a corpus query, eg. previously generated by corpus_query_lemma() or such\n",
    "        corpus: a corpus name\n",
    "        start_position: (optional) corpus response page (usually used by the function automatically calling itself recursively)\n",
    "        detailed_context: (optional) {True, False (default)} \n",
    "    Returns:\n",
    "        a Pandas DataFrame containing corpus data\n",
    "        \n",
    "    >>> df_corpus = search_corpus(r'[pos=\"ADJ\"][word=\"huis\"]', \"chn\")\n",
    "    >>> display_df(df_corpus)\n",
    "    '''\n",
    "    \n",
    "    # show wait indicator\n",
    "    #app = wx.App()\n",
    "    #msg_to_user = wx.BusyInfo('Searching '+corpus+' corpus')\n",
    "    if corpus not in AVAILABLE_CORPORA:\n",
    "        raise ValueError(\"Unknown corpus: \" + corpus)\n",
    "    try:\n",
    "        # Do request to federated content search corpora, so we get same output format for every corpus\n",
    "        url = \"http://portal.clarin.inl.nl/fcscorpora/clariah-fcs-endpoints/sru?operation=searchRetrieve&queryType=fcs&maximumRecords=1000&x-fcs-context=\" + corpus + \"&query=\" + urllib.parse.quote(query)\n",
    "        #print(url)\n",
    "        response = requests.get(url)\n",
    "        response_text = response.text    \n",
    "        df, next_page = _parse_xml(response_text, detailed_context, extra_fields_doc, extra_fields_token)\n",
    "        # If there are next pages, call search_corpus recursively\n",
    "        #print(next_page)\n",
    "        if next_page > 0:\n",
    "            df_more = search_corpus(query, corpus, next_page, detailed_context, extra_fields_doc, extra_fields_token)\n",
    "            df = df.append(df_more, ignore_index=True)\n",
    "        # show message out of xml, if some error has occured (prevents empty output)\n",
    "        _show_error_if_any(response_text)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise ValueError(\"An error occured when searching corpus \" + corpus + \": \"+ str(e))\n",
    "    #finally:\n",
    "    #    # remove wait indicator, and return dataframe\n",
    "    #    del msg_to_user        \n",
    "\n",
    "    \n",
    "    \n",
    "def search_corpus_multiple(queries, corpus):\n",
    "    '''\n",
    "    This function sends multiples queries at once to the search_corpus function\n",
    "    Args:\n",
    "        queries: array of corpus queries, eg. previously generated by corpus_query_lemma() or such\n",
    "        corpus: a corpus name \n",
    "    Returns:\n",
    "        a dictionary of Pandas DataFrames, associating each query (key) to the resulting corpus data (value)\n",
    "    '''\n",
    "    result_dict = {}\n",
    "    for query in queries:\n",
    "        result_dict[query] = search_corpus(query,corpus)\n",
    "    return result_dict\n",
    "   \n",
    "    \n",
    "\n",
    "def search_lexicon_alllemmata(lexicon, pos=None):\n",
    "    '''\n",
    "    This function gets all lemmata of a lexicon. If needed, the output can be restricted to lemmata with a given part-of-speech\n",
    "    Args:\n",
    "        lexicon: a lexicon name\n",
    "        pos: part-of-speech (optional)\n",
    "    Returns:\n",
    "        a Pandas DataFrame containing lexicon data \n",
    "        \n",
    "    >>> df_corpus = search_corpus_alllemmata(\"chn\")\n",
    "    >>> display_df(df_corpus)\n",
    "    '''\n",
    "    query = lexicon_query_alllemmata(lexicon, pos)\n",
    "    return search_lexicon(query, lexicon)\n",
    "\n",
    "\n",
    "\n",
    "def search_lexicon(query, lexicon):\n",
    "    '''\n",
    "    This function searches a lexicon given a query and a lexicon name\n",
    "    Args:\n",
    "        query: a lexicon query, typically previously generated by lexicon_query() or such \n",
    "        lexicon: a lexicon name\n",
    "    Returns:\n",
    "        a Pandas DataFrame with lexicon data \n",
    "        \n",
    "    '''\n",
    "     # show wait indicator, so the user knows what's happening\n",
    "    #app = wx.App()\n",
    "    #msg_to_user = wx.BusyInfo('Searching '+lexicon+' lexicon')\n",
    "    # default endpoint, except when diamant is invoked\n",
    "    endpoint = \"http://172.16.4.56:8890/sparql\"\n",
    "    if (lexicon==\"diamant\"):\n",
    "        endpoint = \"http://svprre02:8080/fuseki/tdb/sparql\"\n",
    "    \n",
    "    try:\n",
    "        # Accept header is needed for virtuoso, it isn't otherwise!\n",
    "        response = requests.post(endpoint, data={\"query\":query}, headers = {\"Accept\":\"application/sparql-results+json\"})\n",
    "        \n",
    "        response_json = json.loads(response.text)\n",
    "        records_json = response_json[\"results\"][\"bindings\"]\n",
    "        records_string = json.dumps(records_json)    \n",
    "        df = pd.read_json(records_string, orient=\"records\")\n",
    "    \n",
    "        # make sure cells containing NULL are added too, otherwise we'll end up with ill-formed data\n",
    "        # TODO: maybe this can be replaced by:\n",
    "        # df = df.fillna('')\n",
    "        df = df.applymap(lambda x: '' if pd.isnull(x) else x[\"value\"])         \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise ValueError(\"An error occured when searching lexicon \" + lexicon + \": \"+ str(e))\n",
    "    #finally:\n",
    "    #    # remove wait indicator, \n",
    "    #    del msg_to_user\n",
    "        \n",
    "\n",
    "# Processing methods\n",
    "\n",
    "def column_difference(df_column1, df_column2):\n",
    "    '''\n",
    "    This function computes differences and similarities between two Pandas DataFrames\n",
    "    Args:\n",
    "        df_column1: a Pandas DataFrame, filtered by one column\n",
    "        df_column2: a Pandas DataFrame, filtered by one column\n",
    "    Returns:\n",
    "        diff_left: array of words only in df_column1\n",
    "        diff_right: array of words only in df_column2\n",
    "        intersec: array of words both in df_column1 and df_column2\n",
    "        \n",
    "    >>> diff_left, diff_right, intersec = column_difference(df_corpus1[\"word 1\"], df_corpus2[\"word 1\"])\n",
    "    >>> display( 'These words are only in DataFrame #1 : ' + \", \".join(diff_left) )\n",
    "    >>> display( 'These words are only in DataFrame #2 : ' + \", \".join(diff_right) )\n",
    "    >>> display( 'These words are common to both DataFrame : ' + \", \".join(intersec) )\n",
    "    '''\n",
    "    \n",
    "    set_df1 = set(df_column1)\n",
    "    set_df2 = set(df_column2)\n",
    "    diff_left = set_df1.difference(set_df2)\n",
    "    diff_right = set_df2.difference(set_df1)\n",
    "    intersec = set_df1.intersection(set_df2)\n",
    "    return diff_left, diff_right, intersec\n",
    "\n",
    "def diamant_get_synonyms(df):\n",
    "    '''\n",
    "    This function gets lemmata or definitions out of a Pandas DataFrame with Diamant data. \n",
    "    The output set content depends on the result type.\n",
    "    \n",
    "    Args:\n",
    "        df: a Pandas DataFrame containing Diamant data\n",
    "    Returns:\n",
    "        a set of lemmata OR a set of synonym definitions\n",
    "        \n",
    "    >>> query = lexicon_query(word=search_word, pos= '', lexicon=lexicon)\n",
    "    >>> df_lexicon = search_lexicon(query, lexicon)\n",
    "    >>> syns = diamant_get_synonyms(df_lexicon) \n",
    "    >>> display( 'Synoniemen voor ' + search_word + ': ' + \", \".join(syns)))\n",
    "    '''\n",
    "    \n",
    "    # Depending on the result type, we return the lemma or the definition text\n",
    "    lemmas = set(df[df[\"inputMode\"]==\"defText\"][\"n_ontolex_writtenRep\"])\n",
    "    defTexts = set(df[df[\"inputMode\"]==\"lemma\"][\"n_syndef_definitionText\"])\n",
    "    return lemmas|defTexts\n",
    "\n",
    "\n",
    "def _parse_xml(text, detailed_context=False, extra_fields_doc=[], extra_fields_token=[]):\n",
    "    '''\n",
    "    This function converts the XML output of a lexicon or corpus search into a Pandas DataFrame for further processing\n",
    "    \n",
    "    Args:\n",
    "        text: the XML response of a lexicon/corpus search, as a string\n",
    "        detailed_context: (optional) True to parse the layers of all tokens, False to limit detailed parsing to hits\n",
    "    Returns:\n",
    "        df: a Pandas DataFrame representing the parse results\n",
    "        next_pos: the next result page to be parsed (since the results might be spread among several XML response pages), \n",
    "        or 0 if there is no page left to be parsed\n",
    "    '''\n",
    "    \n",
    "    # TODO: should we secure against untrusted XML?\n",
    "    root = ET.fromstring(text)\n",
    "    records = []\n",
    "    n_tokens = 0\n",
    "    computed_nt = False\n",
    "    \n",
    "    fields_token = DEFAULT_FIELDS_TOKEN + extra_fields_token\n",
    "    fields_doc = DEFAULT_FIELDS_DOC + extra_fields_doc\n",
    "    for entry in root.iter(\"{http://clarin.eu/fcs/resource}ResourceFragment\"):\n",
    "        doc_metadata = {}\n",
    "        for dataView in entry.findall(\"{http://clarin.eu/fcs/resource}DataView\"):\n",
    "            # Parse document metadata\n",
    "            if(dataView.get(\"type\")==\"application/x-clariah-fcs-simple-metadata+xml\"):\n",
    "                for keyval in dataView.findall(\"keyval\"):\n",
    "                    key = keyval.get(\"key\")\n",
    "                    if key in fields_doc:\n",
    "                        value = keyval.get(\"value\")\n",
    "                        doc_metadata[key] = value\n",
    "            \n",
    "            # ----- [part 1] ----- \n",
    "            # in 'hits only' mode, we'll gather the hits, otherwise we'll gather all the words of the sentences\n",
    "            \n",
    "            # We only take hits into account, ignore metadata and segmenting dataViews\n",
    "            if (detailed_context is False and dataView.get(\"type\")==\"application/x-clarin-fcs-hits+xml\"):\n",
    "                result = dataView.find(\"{http://clarin.eu/fcs/dataview/hits}Result\")\n",
    "                left_context = result.text if result.text is not None else ''\n",
    "                hits = list(result)\n",
    "                if len(hits)==0:\n",
    "                    print([w for w in result.itertext()])\n",
    "                    print(\"no hit in kwic, skip\")\n",
    "                    continue\n",
    "                last_hit = hits[-1]\n",
    "                right_context = last_hit.tail if last_hit.tail is not None else ''\n",
    "                #hit_words = [hit.text for hit in hits]\n",
    "            \n",
    "            # ----- [part 2] ----- \n",
    "            # gather info about each hit (=hits only mode) or about each word (=NOT hits only mode)\n",
    "            \n",
    "            # Get lemma of each hit\n",
    "            if (dataView.get(\"type\")==\"application/x-clarin-fcs-adv+xml\"):\n",
    "                hit_layer = defaultdict(list) \n",
    "                for layer in dataView.findall(\".//{http://clarin.eu/fcs/dataview/advanced}Layer\"):\n",
    "                    layer_id = layer.get(\"id\").split(\"/\")[-1]\n",
    "                    # Only capture this layer, if it is in the list of designated fields (default+extra by user)\n",
    "                    if layer_id in fields_token:\n",
    "                        path = \".//{http://clarin.eu/fcs/dataview/advanced}Span\"\n",
    "                        if (detailed_context is False):\n",
    "                            path = path+\"[@highlight='h1']\" \n",
    "                        for one_span in layer.findall(path):\n",
    "                            span_text = one_span.text            \n",
    "                            hit_layer[layer_id].append(span_text)\n",
    "                        # Compute number of columns and create columns only once\n",
    "                        if not computed_nt:\n",
    "                            n_tokens = len(hit_layer[layer_id])\n",
    "                            computed_nt=True\n",
    "                data, cols = _combine_layers(hit_layer, n_tokens, doc_metadata_req=fields_doc, doc_metadata_recv=doc_metadata)\n",
    "                if detailed_context is False:\n",
    "                    kwic = [left_context] + data + [right_context]\n",
    "                else:\n",
    "                    kwic = data\n",
    "                records.append(kwic)  \n",
    "    if detailed_context is False:\n",
    "        columns = [\"left context\"] + cols + [\"right context\"]\n",
    "    else:\n",
    "        columns = cols\n",
    "    \n",
    "    next_pos = 0\n",
    "    next_record_position = root.find(\"{http://docs.oasis-open.org/ns/search-ws/sruResponse}nextRecordPosition\")\n",
    "    if (next_record_position is not None):\n",
    "        next_pos = int(next_record_position.text)\n",
    "    return pd.DataFrame(records, columns = columns), next_pos\n",
    "\n",
    "def _combine_layers(hit_layer, n_tokens, doc_metadata_req, doc_metadata_recv):\n",
    "    '''\n",
    "    Combine the layers, in alphabetical order of the layer names, to a flat list, with separate column per layer per word in hit, and document metadata added as last columns\n",
    "    \n",
    "    Args:\n",
    "        hit_layer: dictionary with list of items per layer\n",
    "        n_tokens: number of tokens for which token-level annotations exist.\n",
    "                    Is equal to total number of tokens in sentence if _parse_xml is called with detailed_context=True.\n",
    "                    Is equal to number of tokens in hit if _parse_xml is called with detailed_context=False.\n",
    "        doc_metadata_req: list of document metadata fields which have been requested\n",
    "        doc_metadata_recv: dictionary with document metadata that is actually present in hits:\n",
    "                        can contain less fields than doc_fields_requested\n",
    "    Returns:\n",
    "        data: flat list with combined token layers, sorted alphabetically, and document metadata\n",
    "    '''\n",
    "    # Sort layer keys to ensure same order of data in every row and column titles\n",
    "    layers_keys = sorted(hit_layer.keys())\n",
    "    # Original structure is list of tokens per layer id\n",
    "    # Arrange items first on token, then on layer_id\n",
    "    layers_token_flat = [hit_layer[layer_id][n] for n in range(n_tokens) for layer_id in layers_keys]\n",
    "    # Flatten list of document metadata fields\n",
    "    # Use all requested fields, some of which may not be available in this hit\n",
    "    doc_flat = [doc_metadata_recv[field] if field in doc_metadata_recv else \"\" for field in doc_metadata_req]\n",
    "    # Combine token and document data\n",
    "    data = layers_token_flat + doc_flat\n",
    "    \n",
    "    ### Columns\n",
    "    # Create list of columns, in same order\n",
    "    tokens_columns = [layer_id+ \" \"+str(n) for n in range(n_tokens) for layer_id in layers_keys]\n",
    "    # Add all requested document metadata fields as columns\n",
    "    columns = tokens_columns + doc_metadata_req\n",
    "    return data, columns\n",
    "\n",
    "def _show_error_if_any(text):\n",
    "    '''\n",
    "    This function reads error messages in the XML output of a lexicon or corpus search \n",
    "    and it finds any, it is printed on screen\n",
    "    \n",
    "    Args:\n",
    "        text: the XML response of a lexicon/corpus search, as a string\n",
    "    Returns:\n",
    "        N/A\n",
    "    '''\n",
    "    root = ET.fromstring(text)\n",
    "    msgs = []\n",
    "    for diagnostic in root.iter(\"{http://docs.oasis-open.org/ns/search-ws/diagnostic}diagnostic\"):\n",
    "        for msg in diagnostic.findall(\"{http://docs.oasis-open.org/ns/search-ws/diagnostic}message\"):\n",
    "            msg_text = msg.text if msg.text is not None else ''\n",
    "            msgs.append(msg_text)\n",
    "    if len(msgs) > 0:\n",
    "        print(\"; \".join(msgs))\n",
    "\n",
    "# View methods\n",
    "\n",
    "\n",
    "def view_multiple_results(results, labels):\n",
    "    '''\n",
    "    This function shows the content of multiple Pandas DataFrames out of a dictionary associating\n",
    "    labels (eg. corpus or lexicon names) to dataframes (values). It is typically called\n",
    "    after search_corpus_multiple(), since this function returns such a dictionary.\n",
    "    \n",
    "    Args:\n",
    "        results: a dictionary of Pandas DataFrames\n",
    "        labels: list of labels corresponding to the Pandas DataFrames in results\n",
    "    Returns:\n",
    "        N/A\n",
    "        \n",
    "    >>> result_dict = search_corpus_multiple(queries, corpus)\n",
    "    >>> view_multiple_results(result_dict, labels=list(syns))\n",
    "    '''\n",
    "    assert len(labels)==len(results)\n",
    "    for n,query in enumerate(results):\n",
    "        df = results[query]\n",
    "        if not df.empty:\n",
    "            display(HTML('Resultaten voor <b>' + labels[n] + \"</b>:\"))\n",
    "            display(df)\n",
    "            \n",
    "            \n",
    "            \n",
    "def get_frequency_list(lexicon, pos, corpus):\n",
    "    '''\n",
    "    This function builds a lemmata frequency list of a corpus, \n",
    "    given a lexicon (for obvious reasons limited to some part-of-speech).\n",
    "    \n",
    "    Args:\n",
    "        lexicon: a lexicon name\n",
    "        pos: a part-of-speech to limit the search to\n",
    "        corpus: the corpus to be searched\n",
    "    Returns:\n",
    "        a Pandas DataFrame with raw frequencies ('raw_freq' column) and rankings ('rank' column)\n",
    "        \n",
    "    >>> df_frequency_list = get_frequency_list(some_lexicon, \"NOUN\", corpus_to_search)\n",
    "    >>> display(df_frequency_list)\n",
    "    '''\n",
    "    \n",
    "    # LEXICON: get a lemmata list to work with\n",
    "    df_lexicon = search_lexicon_alllemmata(lexicon, pos)\n",
    "    lexicon_lemmata_set = sorted( set([w.lower() for w in df_lexicon[\"writtenForm\"]]) )\n",
    "    lexicon_lemmata_arr= numpy.array(lexicon_lemmata_set)\n",
    "\n",
    "    # instantiate a dataframe for storing lemmata and frequencies\n",
    "    df_frequency_list = pd.DataFrame(index=lexicon_lemmata_arr, columns=['raw_freq'])\n",
    "    df_frequency_list.index.name = 'lemmata'\n",
    "\n",
    "    # CORPUS: loop through lemmata list, query the corpus with that lemma, and count the results\n",
    "\n",
    "    # It's a good idea to work with more than one lemma at once!\n",
    "    nr_of_lemmata_to_query_atonce = 100\n",
    "    \n",
    "    # loop over lemmata list \n",
    "    for i in range(0, len(lexicon_lemmata_set), nr_of_lemmata_to_query_atonce):\n",
    "        # slice to small sets of lemmata to query at once\n",
    "        small_lemmata_set = set( lexicon_lemmata_arr[i : i+nr_of_lemmata_to_query_atonce] )    \n",
    "\n",
    "        # join set of lemmata to send them in a query all at once\n",
    "        # beware: single quotes need escaping\n",
    "        lemmata_list = \"|\".join(small_lemmata_set).replace(\"'\", \"\\\\\\\\'\")\n",
    "        df_corpus = search_corpus(r'[lemma=\"' + lemmata_list + r'\"]', corpus)\n",
    "\n",
    "        # store frequencies\n",
    "        if (len(df_corpus)>0):\n",
    "            for one_lemma in small_lemmata_set: \n",
    "                raw_freq = len(df_corpus[df_corpus['lemma 0'] == one_lemma])\n",
    "                df_frequency_list.at[one_lemma, 'raw_freq'] = raw_freq \n",
    "                \n",
    "    # final step: compute rank\n",
    "    # this is needed to be able to compare different frequency lists \n",
    "    # with each other (which we could achieve by computing a rank diff)\n",
    "    df_frequency_list['rank'] = df_frequency_list['raw_freq'].rank(ascending = False).astype(int)\n",
    "    \n",
    "    return df_frequency_list;\n",
    "\n",
    "\n",
    "def get_missing_wordforms(lexicon, pos, corpus):    \n",
    "    '''\n",
    "    This function gathers all paradigms of a lexicon with a given part-of-speech\n",
    "    and searches an annotated corpus for words missing in those paradigms\n",
    "    \n",
    "    Args:\n",
    "        lexicon: a lexicon name\n",
    "        pos: a part-of-speech to limit the search to\n",
    "        corpus: the corpus to be searched\n",
    "    Returns:\n",
    "        a Pandas DataFrame associating lemmata to their paradigms ('known_wordforms' column) and\n",
    "        missing wordforms found in the corpus ('unknown_wordforms' column).\n",
    "        \n",
    "    >>> df = get_missing_wordforms(\"molex\", \"VERB\", \"opensonar\")\n",
    "    >>> df.to_csv( \"missing_wordforms.csv\", index=False)\n",
    "    '''\n",
    "    \n",
    "    # LEXICON: get a lemmata list to work with\n",
    "    df_lexicon = search_lexicon_alllemmata(lexicon, pos)\n",
    "    lexicon_lemmata_set = sorted( set([w.lower() for w in df_lexicon[\"writtenForm\"]]) )\n",
    "    lexicon_lemmata_arr= numpy.array(lexicon_lemmata_set)\n",
    "    \n",
    "    # instantiate a dataframe for storing lemmata and wordforms\n",
    "    df_enriched_lexicon = pd.DataFrame(index=lexicon_lemmata_arr, columns=['lemma', 'pos', 'known_wordforms', 'unknown_wordforms'])\n",
    "    df_enriched_lexicon.index.name = 'lemmata'\n",
    "    \n",
    "    # CORPUS: loop through lemmata list, query the corpus with that lemma, \n",
    "    # and compute difference between both\n",
    "\n",
    "    # It's a good idea to work with more than one lemma at once!\n",
    "    nr_of_lemmata_to_query_atonce = 100\n",
    "    \n",
    "    # loop over lemmata list \n",
    "    for i in range(0, len(lexicon_lemmata_set), nr_of_lemmata_to_query_atonce):\n",
    "        # slice to small sets of lemmata to query at once\n",
    "        small_lemmata_set = set( lexicon_lemmata_arr[i : i+nr_of_lemmata_to_query_atonce] )    \n",
    "        \n",
    "        # join set of lemmata to send them in a query all at once\n",
    "        # beware: single quotes need escaping\n",
    "        lemmata_list = \"|\".join(small_lemmata_set).replace(\"'\", \"\\\\\\\\'\")\n",
    "        df_corpus = search_corpus(r'[lemma=\"' + lemmata_list + r'\"]', corpus)\n",
    "        \n",
    "        # process results\n",
    "        if (len(df_corpus)>0):\n",
    "            for one_lemma in small_lemmata_set: \n",
    "                \n",
    "                # look up the known wordforms in the lexicon\n",
    "                query = lexicon_query(one_lemma, pos, lexicon)\n",
    "                df_known_wordforms = search_lexicon(query, lexicon)\n",
    "                \n",
    "                if (len(df_known_wordforms) != 0):\n",
    "                    known_wordforms = set( df_known_wordforms['wordform'].str.lower() )\n",
    "                    # find the wordforms in the corpus\n",
    "                    corpus_wordforms = set( (df_corpus[df_corpus['lemma 0'] == one_lemma])['word 0'].str.lower() )\n",
    "                    # determine which corpus wordforms are not in lexicon wordforms\n",
    "                    unknown_wordforms = corpus_wordforms.difference(known_wordforms)\n",
    "\n",
    "                    if (len(unknown_wordforms) !=0):\n",
    "                        # store the results\n",
    "                        df_enriched_lexicon.at[one_lemma, 'lemma'] = one_lemma\n",
    "                        df_enriched_lexicon.at[one_lemma, 'pos'] = pos\n",
    "                        df_enriched_lexicon.at[one_lemma, 'known_wordforms'] = known_wordforms\n",
    "                        df_enriched_lexicon.at[one_lemma, 'unknown_wordforms'] = unknown_wordforms\n",
    "                \n",
    "    # return non-empty results, t.i. cases in which we found some wordforms\n",
    "    return df_enriched_lexicon[ df_enriched_lexicon['unknown_wordforms'].notnull() ]\n",
    "        \n",
    "    \n",
    "def get_rank_diff(df1, df2):\n",
    "    '''\n",
    "    This function compares the rankings of words common to two dataframes, and compute a rank_diff, in such\n",
    "    a way that one can see which words are very frequent in one set and rare in the other.\n",
    "    \n",
    "    Args:\n",
    "        df1: a Pandas DataFrame\n",
    "        df2: a Pandas DataFrame\n",
    "    Returns:\n",
    "        a Pandas DataFrame with lemmata (index), ranks of both input dataframes ('rank_1' and 'rank_2' columns) \n",
    "        and the rank_diff ('rank_diff' column).\n",
    "        \n",
    "    >>> df_frequency_list1 = get_frequency_list(base_lexicon, \"NOUN\", corpus_to_search1)\n",
    "    >>> df_frequency_list2 = get_frequency_list(base_lexicon, \"NOUN\", corpus_to_search2)\n",
    "    >>> df_rankdiffs = get_rank_diff(df_frequency_list1, df_frequency_list2)\n",
    "    '''\n",
    "    \n",
    "    # Find lemmata shared by both dataframes: computing ranks diffs is only possible\n",
    "    # when dealing with lemmata which are in both frames\n",
    "    lemmata_list1 = set(df1.index.tolist())\n",
    "    lemmata_list2 = set(df2.index.tolist())\n",
    "    common_lemmata_list = list( lemmata_list1.intersection(lemmata_list2) )\n",
    "    \n",
    "    # Build dataframes limited to the common lemmata\n",
    "    limited_df1 = df1.loc[ common_lemmata_list , : ]\n",
    "    limited_df2 = df2.loc[ common_lemmata_list , : ]\n",
    "    \n",
    "    # Recompute ranks in both dataframes, because in each frame the original ranks were\n",
    "    # computed with a lemmata list which might be larger than the lemmata list common\n",
    "    # to both dataframes\n",
    "    \n",
    "    limited_df1['rank'] = limited_df1['raw_freq'].rank(ascending = False).astype(int)\n",
    "    limited_df2['rank'] = limited_df2['raw_freq'].rank(ascending = False).astype(int)\n",
    "    \n",
    "    # Instantiate a dataframe for storing lemmata and rank diffs\n",
    "    df_rankdiffs = pd.DataFrame(index=common_lemmata_list, columns=['rank_1', 'rank_2', 'rank_diff'])\n",
    "    df_rankdiffs.index.name = 'lemmata'\n",
    "    \n",
    "    df_rankdiffs['rank_1'] = limited_df1['rank']\n",
    "    df_rankdiffs['rank_2'] = limited_df2['rank']\n",
    "    df_rankdiffs['rank_diff'] = pd.DataFrame.abs( df_rankdiffs['rank_1'] - df_rankdiffs['rank_2'] )\n",
    "    \n",
    "    return df_rankdiffs\n",
    "\n",
    "\n",
    "# TODO: Method misses token fields which are extracted from POS tag by FCS (eg. inflection)\n",
    "def _parse_blacklab_metadata(text):\n",
    "    '''\n",
    "    This method parses metadata fields from a Blacklab metadata response\n",
    "    Args:\n",
    "        text: the XML response of a lexicon/corpus search, as a string\n",
    "    Returns:\n",
    "        A dictionary of with lists of document and token metadata\n",
    "    '''\n",
    "    \n",
    "    # TODO: should we secure against untrusted XML?\n",
    "    root = ET.fromstring(text)\n",
    "    doc_fields = [md.get(\"name\") for md in root.iter(\"metadataField\")]\n",
    "    token_fields = [prop.get(\"name\") for prop in root.iter(\"property\")]\n",
    "    return {\"document\": doc_fields, \"token\": token_fields}\n",
    "    \n",
    "\n",
    "def _corpus_metadata_blacklab(corpus_name):\n",
    "    '''\n",
    "    Return all possible metadata fields for a BlackLab-based corpus, by sending a request to the corpus\n",
    "    \n",
    "    Args:\n",
    "        corpus_name: Name of the corpus\n",
    "    Returns:\n",
    "        A dictionary of with lists of document and token metadata\n",
    "    '''\n",
    "    corpus_url = AVAILABLE_CORPORA[corpus_name]\n",
    "    response = requests.get(corpus_url)\n",
    "    response_text = response.text  \n",
    "    return _parse_blacklab_metadata(response_text)\n",
    "\n",
    "def get_available_metadata(resource_type, resource_name):\n",
    "    '''\n",
    "    Return all possible metadata fields for a lexicon or corpus\n",
    "    \n",
    "    Args:\n",
    "        resource_type: One of 'lexicon' or 'corpus'\n",
    "        resource_name: Name of the lexicon or corpus\n",
    "    Returns:\n",
    "        A list of metadata fields\n",
    "    '''\n",
    "    if resource_type==\"lexicon\":\n",
    "        # Create sample query for this lexicon\n",
    "        q = lexicon_query(word=\"\", pos=\"\", lexicon=resource_name)\n",
    "        return _etadata_from_lexicon_query(q)\n",
    "    elif resource_type==\"corpus\":\n",
    "        if resource_name in AVAILABLE_CORPORA and resource_name != \"nederlab\":\n",
    "            return _corpus_metadata_blacklab(resource_name)\n",
    "        elif corpus_name==\"nederlab\":\n",
    "            print(\"Corpus metadata not yet available for Nederlab\")\n",
    "            return []\n",
    "        else:\n",
    "            ValueError(\"Unknown corpus: \" + corpus_name + \". Should be one of \" + AVAILABLE_CORPORA.keys())\n",
    "    else:\n",
    "        raise ValueError(\"resource_type should be 'corpus' or 'lexicon'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library functions: UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T15:42:17.743540Z",
     "start_time": "2019-02-08T15:42:17.518243Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "#import tkinter as tk\n",
    "#from tkinter import filedialog\n",
    "from pathlib import Path\n",
    "from IPython.display import Javascript\n",
    "from IPython.core.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEFAULT_QUERY = r'[lemma=\"boek\" & pos=\"verb\"]' #r'[lemma=\"boeken\" pos=\"verb\"]'\n",
    "DEFAULT_CORPUS = \"chn\"\n",
    "\n",
    "\n",
    "\n",
    "def create_corpus_ui():\n",
    "    '''\n",
    "    This function builds a GUI for corpus search\n",
    "    \n",
    "    Args:\n",
    "        N/A\n",
    "    Returns:\n",
    "        N/A\n",
    "    '''\n",
    "    \n",
    "    # Create UI elements\n",
    "    corpusQueryField = widgets.Text(description=\"<b>CQL query:</b>\", value=DEFAULT_QUERY)\n",
    "    corpusField = widgets.Dropdown(\n",
    "        options=AVAILABLE_CORPORA.keys(),\n",
    "        value=DEFAULT_CORPUS,\n",
    "        description='<b>Corpus:</b>',\n",
    "    )\n",
    "    '''corpusSearchButton = widgets.Button(\n",
    "        description='Search',\n",
    "        button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "        tooltip='Search',\n",
    "    )\n",
    "    # Handle events\n",
    "    corpusSearchButton.on_click(corpus_search)'''\n",
    "    \n",
    "    # Stack UI elements in vertical box and display\n",
    "    corpusUiBox = widgets.VBox([corpusQueryField,corpusField])\n",
    "    display(corpusUiBox)\n",
    "    \n",
    "    # Return fields, so their contents are accessible from the global namespace of the Notebook\n",
    "    return corpusQueryField, corpusField\n",
    "\n",
    "def create_lexicon_ui():\n",
    "    '''\n",
    "    This function builds a GUI for lexicon search.\n",
    "    \n",
    "    Args:\n",
    "        N/A\n",
    "    Returns:\n",
    "        N/A\n",
    "    '''\n",
    "    \n",
    "    DEFAULT_SEARCHWORD = 'boek'\n",
    "    DEFAULT_LEXICON = \"diamant\"\n",
    "\n",
    "    # Create UI elements\n",
    "    searchWordField = widgets.Text(description=\"<b>Word:</b>\", value=DEFAULT_SEARCHWORD)\n",
    "    lexiconField = widgets.Dropdown(\n",
    "        options=['anw', 'celex', 'diamant', 'duelme', 'molex'],\n",
    "        value=DEFAULT_LEXICON,\n",
    "        description='<b>Lexicon:</b>',\n",
    "    )\n",
    "    '''lexSearchButton = widgets.Button(\n",
    "        description='Search',\n",
    "        button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "        tooltip='Search',\n",
    "    )\n",
    "    # Handle events\n",
    "    lexSearchButton.on_click(lexicon_search)'''\n",
    "    # Stack UI elements in vertical box and display\n",
    "    lexUiBox = widgets.VBox([searchWordField,lexiconField])\n",
    "    display(lexUiBox)\n",
    "    return searchWordField, lexiconField\n",
    "\n",
    "\n",
    "def create_save_dataframe_ui(df):\n",
    "    '''\n",
    "    This function builds a GUI for saving the results of some lexicon or corpus query to a .csv file.\n",
    "    One can use load_dataframe(filepath) to reload the results later on.\n",
    "    \n",
    "    Args:\n",
    "        df: a Pandas DataFrame\n",
    "    Returns:\n",
    "        N/A\n",
    "    '''\n",
    "    \n",
    "    # build ui for saving results\n",
    "    DEFAULT_FILENAME = 'mijn_resultaten.csv'\n",
    "    saveResultsCaption = widgets.Label(value='Sla uw resultaten op:')\n",
    "    fileNameField = widgets.Text(value=DEFAULT_FILENAME)\n",
    "    savebutton = widgets.Button(\n",
    "        description='Bestand opslaan',\n",
    "        disabled=False,\n",
    "        button_style='warning', \n",
    "        tooltip=DEFAULT_FILENAME,  # trick to pass filename to button widget\n",
    "        icon=''\n",
    "    )\n",
    "    # inject dataframe into button object\n",
    "    savebutton.df = df\n",
    "    # when the user types a new filename, it will be passed to the button tooltip property straight away\n",
    "    fileNameLink = widgets.jslink((fileNameField, 'value'), (savebutton, 'tooltip'))\n",
    "    # click event with callback\n",
    "    savebutton.on_click( _save_dataframe )    \n",
    "    saveResultsBox = widgets.HBox([saveResultsCaption, fileNameField, savebutton])\n",
    "    display(saveResultsBox)\n",
    "    \n",
    "def _save_dataframe(button):\n",
    "    fileName = button.tooltip\n",
    "    # The result files can be saved locally or on the server:\n",
    "    # If result files are to be offered as downloads, set to True; otherwise set to False    \n",
    "    fileDownloadable = False\n",
    "    # specify paths here, if needed:\n",
    "    filePath_onServer = ''  # could be /path/to\n",
    "    filePath_default = ''\n",
    "    # compute full path given chosen mode\n",
    "    fullFileName = (filePath_onServer if fileDownloadable else filePath_default ) + fileName\n",
    "        \n",
    "    try:\n",
    "        button.df.to_csv( fullFileName, index=False)\n",
    "        # confirm it all went well\n",
    "        print(fileName + \" saved\")    \n",
    "        button.button_style = 'success'\n",
    "        button.icon = 'check'\n",
    "        # trick: https://stackoverflow.com/questions/31893930/download-csv-from-an-ipython-notebook\n",
    "        if (fileDownloadable):\n",
    "            downloadableFiles = FileLinks(filePath_onServer)\n",
    "            display(downloadableFiles)\n",
    "    except Exception as e:\n",
    "        button.button_style = 'danger'\n",
    "        raise ValueError(\"An error occured when saving \" + fileName + \": \"+ str(e))    \n",
    "\n",
    "    \n",
    "    \n",
    "def load_dataframe(filepath):\n",
    "    '''\n",
    "    This functions (re)loads some previously saved Pandas DataFrame\n",
    "    \n",
    "    Args:\n",
    "        filepath: path to the saved Pandas DataFrame (.csv)\n",
    "    Returns: \n",
    "        a Pandas DataFrame representing the content of the file\n",
    "    \n",
    "    >>> df_corpus = load_dataframe('mijn_resultaten.csv')\n",
    "    >>> display_df(df_corpus, title=\"Results:\")\n",
    "    '''\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        print(filepath + \" loaded successfully\")            \n",
    "    except Exception as e:\n",
    "        raise ValueError(\"An error occured when loading \" + filepath + \": \"+ str(e))\n",
    "    finally:\n",
    "        return df\n",
    "\n",
    "\n",
    "def display_df(df, columns=None, title=None, mode='table'):\n",
    "    '''\n",
    "    This function displays a Pandas DataFrame as a table of as a chart.\n",
    "    \n",
    "    If the 'chart' mode is chosen, the function draws a horizontal chart representing a dataframe.\n",
    "    One axis is the index of the dataframe, and the other axis is the given column, which holds the \n",
    "    values to plot in the chart.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame to be displayed\n",
    "        columns: columns to display, or None to display all columns\n",
    "        title: Title displayed\n",
    "        mode: Way of displaying, one of 'table' (default) or 'chart'\n",
    "    Returns:\n",
    "        N/A\n",
    "    '''\n",
    "    if columns is not None:\n",
    "        df_display=df[columns]\n",
    "    else:\n",
    "        df_display = df\n",
    "    \n",
    "    # chart mode\n",
    "    if mode == 'chart':\n",
    "        plt.figure()\n",
    "        df_display.plot.barh().set_title(title)\n",
    "    \n",
    "    # table mode (default)\n",
    "    else:    \n",
    "        if title is not None:\n",
    "            display(HTML(\"<b>%s</b>\" % title))        \n",
    "\n",
    "        display(df_display)\n",
    "    \n",
    "    # eventually, give UI to save data\n",
    "    create_save_dataframe_ui(df_display)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library functions: Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T15:42:18.320576Z",
     "start_time": "2019-02-08T15:42:18.274160Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def containsRegex(word):\n",
    "    '''\n",
    "    This function checks whether some string contains a regular expression or not\n",
    "    \n",
    "    Args:\n",
    "        word: a string to check for regular expressions\n",
    "    Returns:\n",
    "        A boolean\n",
    "    '''\n",
    "    return ( word.find('^')>-1 or\n",
    "            word.find('$')>-1 or \n",
    "            re.match(\"\\(.+?\\)\", word) or\n",
    "            re.match(\"\\[.+?\\]\", word) or\n",
    "            re.match(\"[\\+*]\", word) )\n",
    "                     \n",
    "def lexicon_query(word, pos, lexicon):\n",
    "    '''\n",
    "    This function builds a query for getting the paradigm etc. of a given lemma out of a given lexicon.\n",
    "    The resulting query string is to be used as a parameter of search_lexicon() \n",
    "    \n",
    "    Args:\n",
    "        word: a lemma/wordform to build the query with\n",
    "        pos: a part-of-speech to build the query with\n",
    "        lexicon: a lexicon to build the query for\n",
    "    Returns:\n",
    "        a query string to be used as a parameter of search_lexicon() \n",
    "    '''\n",
    "    \n",
    "    if (lexicon==\"anw\"):\n",
    "        # part-of-speech filter not supported for this lexicon\n",
    "        if (pos is not None and pos != ''):\n",
    "            print('Filtering by part-of-speech is not (yet) supported in the \\''+lexicon+'\\' lexicon')\n",
    "        # exact or fuzzy search\n",
    "        exactsearch = (not containsRegex(word))\n",
    "        subpart = \"\"\"FILTER ( regex(?lemma, \\\"\"\"\"+word+\"\"\"\\\") || regex(?definition, \\\"\"\"\"+word+\"\"\"\\\") ) . \"\"\"\n",
    "        if (exactsearch == True):\n",
    "              subpart =  \"\"\"\n",
    "                { { ?lemId rdfs:label ?lemma .  \n",
    "                values ?lemma { \\\"\"\"\"+word+\"\"\"\\\"@nl \\\"\"\"\"+word+\"\"\"\\\" } }                 \n",
    "                UNION\n",
    "                { ?definitionId lemon:value ?definition .\n",
    "                values ?definition { \\\"\"\"\"+word+\"\"\"\\\"@nl \\\"\"\"\"+word+\"\"\"\\\" } } } .\n",
    "                \"\"\"               \n",
    "        query = \"\"\"PREFIX ontolex: <http://www.w3.org/ns/lemon/ontolex#>\n",
    "                  PREFIX anw: <http://rdf.ivdnt.org/lexica/anw>\n",
    "                  PREFIX anwsch: <http://rdf.ivdnt.org/schema/anw/>\n",
    "                  PREFIX lemon: <http://lemon-model.net/lemon#>\n",
    "                  \n",
    "                  SELECT ?lemId ?lemma ?writtenForm ?definition concat('', ?definitionComplement) as ?definitionComplement\n",
    "                  FROM <http://rdf.ivdnt.org/lexica/anw>\n",
    "                  WHERE {\n",
    "                      ?lemId rdfs:label ?lemma .\n",
    "                      ?lemId ontolex:sense ?senseId .\n",
    "                      ?senseId lemon:definition ?definitionId .\n",
    "                      ?definitionId lemon:value ?definition .\n",
    "                      OPTIONAL { ?definitionId anwsch:definitionComplement ?definitionComplement .}\n",
    "                      OPTIONAL { ?lemId ontolex:canonicalForm ?lemCFId . \n",
    "                          ?lemCFId ontolex:writtenRepresentation ?writtenForm . }\n",
    "                      \"\"\"+subpart+\"\"\"\n",
    "                      }\"\"\"\n",
    "    elif (lexicon==\"diamant\"):\n",
    "        # part-of-speech filter not supported for this lexicon\n",
    "        if (pos is not None and pos != ''):\n",
    "            print('Filtering by part-of-speech is not (yet) supported in the \\''+lexicon+'\\' lexicon')\n",
    "        # exact or fuzzy search\n",
    "        exactsearch = (not containsRegex(word))\n",
    "        subpart1 = \"\"\"?n_form ontolex:writtenRep ?n_ontolex_writtenRep . \n",
    "            FILTER regex(?n_ontolex_writtenRep, \\\"\"\"\"+word+\"\"\"\\\") . \"\"\"\n",
    "        subpart2 = \"\"\"?n_syndef diamant:definitionText ?n_syndef_definitionText .  \n",
    "            FILTER regex(?n_ontolex_writtenRep, \\\"\"\"\"+word+\"\"\"\\\") . \"\"\"\n",
    "        if (exactsearch == True):\n",
    "            subpart1 =  \"\"\"\n",
    "                { ?n_form ontolex:writtenRep ?n_ontolex_writtenRep . \n",
    "                values ?n_ontolex_writtenRep { \\\"\"\"\"+word+\"\"\"\\\"@nl \\\"\"\"\"+word+\"\"\"\\\" } } \n",
    "                \"\"\"                \n",
    "            subpart2 = \"\"\"\n",
    "                { ?n_syndef diamant:definitionText ?n_syndef_definitionText . \n",
    "                values ?n_syndef_definitionText { \\\"\"\"\"+word+\"\"\"\\\"@nl \\\"\"\"\"+word+\"\"\"\\\" } } \n",
    "                \"\"\"\n",
    "        query = \"\"\"\n",
    "        PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "        prefix prov: <http://www.w3.org/ns/prov#>\n",
    "        prefix diamant: <http://rdf.ivdnt.org/schema/diamant#>\n",
    "        prefix lexinfo: <http://www.lexinfo.net/ontology/2.0/lexinfo#>\n",
    "        prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "        prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "        prefix lemon: <http://lemon-model.net/lemon#>\n",
    "        prefix ontolex: <http://www.w3.org/ns/lemon/ontolex#>\n",
    "        prefix ud: <http://universaldependencies.org/u/pos/>\n",
    "        prefix skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "        prefix dcterms: <http://purl.org/dc/terms/>\n",
    "        prefix dc: <http://purl.org/dc/terms/>\n",
    "\n",
    "        select ?n_entry ?n_form ?n_ontolex_writtenRep ?n_syndef ?n_sensedef ?n_sensedef_definitionText ?n_syndef_definitionText ?n_sense ?inputMode ?wy_f_show ?wy_t_show\n",
    "        where\n",
    "        {\n",
    "        graph ?g\n",
    "        {\n",
    "        {\n",
    "            \"\"\" + subpart1 + \"\"\"\n",
    "            { ?n_entry a ontolex:LexicalEntry} .\n",
    "            { ?n_form a ontolex:Form} .\n",
    "            { ?n_sense a ontolex:LexicalSense} .\n",
    "            { ?n_syndef a diamant:SynonymDefinition} .\n",
    "            { ?n_sensedef a lemon:SenseDefinition} .\n",
    "            { ?n_syndef diamant:definitionText ?n_syndef_definitionText } .\n",
    "            { ?n_sensedef diamant:definitionText ?n_sensedef_definitionText } .\n",
    "            { ?n_entry ontolex:canonicalForm ?n_form } .\n",
    "            { ?n_entry ontolex:sense ?n_sense } .\n",
    "            { ?n_sense lemon:definition ?n_syndef } .\n",
    "            { ?n_sense lemon:definition ?n_sensedef } .\n",
    "              ?n_sense diamant:attestation ?n_attest_show .\n",
    "              ?n_sense diamant:attestation ?n_attest_filter .\n",
    "              ?n_attest_show diamant:text ?n_q_show .\n",
    "              ?n_attest_filter diamant:text ?n_q_filter .\n",
    "              ?n_attest_show a diamant:Attestation .\n",
    "              ?n_attest_filter a diamant:Attestation .\n",
    "              ?n_q_filter a diamant:Quotation .\n",
    "              ?n_q_show a diamant:Quotation .\n",
    "              ?n_q_filter diamant:witnessYearFrom ?wy_f_filter .\n",
    "              ?n_q_filter diamant:witnessYearTo ?wy_t_filter .\n",
    "              ?n_q_show diamant:witnessYearFrom ?wy_f_show .\n",
    "              ?n_q_show diamant:witnessYearTo ?wy_t_show .\n",
    "              FILTER (xsd:integer(?wy_f_show) >= 1200)\n",
    "              FILTER (xsd:integer(?wy_t_show) >= 1200)\n",
    "              FILTER (xsd:integer(?wy_f_show) <= 2018)\n",
    "              FILTER (xsd:integer(?wy_t_show) <= 2018)\n",
    "            { bind(\"lemma\" as ?inputMode) } .\n",
    "            } UNION\n",
    "          {\n",
    "            \"\"\" + subpart2 + \"\"\"\n",
    "            { ?n_sense a ontolex:LexicalSense} .\n",
    "            { ?n_syndef a diamant:SynonymDefinition} .\n",
    "            { ?n_sensedef a lemon:SenseDefinition} .\n",
    "            { ?n_form a ontolex:Form} .\n",
    "            { ?n_form ontolex:writtenRep ?n_ontolex_writtenRep } .  { ?n_entry a ontolex:LexicalEntry} .\n",
    "            { ?n_entry ontolex:sense ?n_sense } .\n",
    "            { ?n_sense lemon:definition ?n_syndef } .\n",
    "            { ?n_sense lemon:definition ?n_sensedef } .\n",
    "            { ?n_sensedef diamant:definitionText ?n_sensedef_definitionText } .\n",
    "            { ?n_entry ontolex:canonicalForm ?n_form } .\n",
    "            ?n_sense diamant:attestation ?n_attest_show .\n",
    "            ?n_sense diamant:attestation ?n_attest_filter .\n",
    "            ?n_attest_filter diamant:text ?n_q_filter .\n",
    "            ?n_attest_show diamant:text ?n_q_show .\n",
    "            ?n_q_filter diamant:witnessYearFrom ?wy_f_filter .\n",
    "            ?n_q_filter diamant:witnessYearTo ?wy_t_filter .\n",
    "            ?n_q_show diamant:witnessYearFrom ?wy_f_show .\n",
    "            ?n_q_show diamant:witnessYearTo ?wy_t_show .\n",
    "            ?n_attest_show a diamant:Attestation .\n",
    "            ?n_attest_filter a diamant:Attestation .\n",
    "            ?n_q_filter a diamant:Quotation .\n",
    "            ?n_q_show a diamant:Quotation .\n",
    "            FILTER (xsd:integer(?wy_f_show) >= 1200)\n",
    "            FILTER (xsd:integer(?wy_t_show) >= 1200)\n",
    "            FILTER (xsd:integer(?wy_f_show) <= 2018)\n",
    "            FILTER (xsd:integer(?wy_t_show) <= 2018)\n",
    "          { bind(\"defText\" as ?inputMode) } .\n",
    "            }\n",
    "        }\n",
    "        }\"\"\"\n",
    "    elif (lexicon==\"molex\"):\n",
    "        # exact or fuzzy search\n",
    "        exactsearch = (not containsRegex(word))\n",
    "        subpart1 = \"\"\"\"\"\"\n",
    "        subpart2 = \"\"\"\"\"\"\n",
    "        subpartPos = \"\"\"\"\"\"\n",
    "        if (word != ''):\n",
    "            if (exactsearch == True):\n",
    "                subpart1 =  \"\"\"\n",
    "                    { ?lemCFId ontolex:writtenRep ?lemma . \n",
    "                    values ?lemma { \\\"\"\"\"+word+\"\"\"\\\"@nl \\\"\"\"\"+word+\"\"\"\\\" } } \n",
    "                    UNION\n",
    "                    { ?wordformId ontolex:writtenRep ?wordform . \n",
    "                    values ?wordform { \\\"\"\"\"+word+\"\"\"\\\"@nl \\\"\"\"\"+word+\"\"\"\\\" } } .\n",
    "                    \"\"\"        \n",
    "            else:\n",
    "                subpart2 = \"\"\"FILTER ( regex(?lemma, \\\"\"\"\"+word+\"\"\"\\\") || regex(?wordform, \\\"\"\"\"+word+\"\"\"\\\") ) . \"\"\"\n",
    "        if (pos is not None and pos != ''):\n",
    "            subpartPos = \"\"\"FILTER ( regex(?lemPos, \\\"\"\"\"+pos+\"\"\"$\\\") ) .\"\"\"\n",
    "        query = \"\"\"\n",
    "            PREFIX ontolex: <http://www.w3.org/ns/lemon/ontolex#>\n",
    "            PREFIX UD: <http://universaldependencies.org/u/>\n",
    "            PREFIX diamant: <http://rdf.ivdnt.org/schema/diamant#>\n",
    "            \n",
    "            SELECT ?lemEntryId ?lemma ?lemPos ?wordformId ?wordform ?hyphenation ?wordformPos ?Gender ?Number\n",
    "            FROM <http://rdf.ivdnt.org/lexica/molex>\n",
    "            WHERE\n",
    "            {\n",
    "            ?lemEntryId ontolex:canonicalForm ?lemCFId .\n",
    "            ?lemCFId ontolex:writtenRep ?lemma .\n",
    "            \"\"\"+subpart1+\"\"\"\n",
    "            OPTIONAL {?lemEntryId UD:Gender ?Gender .}\n",
    "            OPTIONAL {?lemEntryId UD:VerbForm ?verbform .}\n",
    "            ?lemEntryId UD:pos ?lemPos .\n",
    "            \"\"\"+subpartPos+\"\"\"\n",
    "            ?lemEntryId ontolex:lexicalForm ?wordformId .\n",
    "            ?wordformId UD:pos ?wordformPos .\n",
    "            OPTIONAL {?wordformId UD:Number ?Number .}\n",
    "            OPTIONAL {?wordformId ontolex:writtenRep ?wordform .}\n",
    "            OPTIONAL {?wordformId diamant:hyphenation ?hyphenation .}\n",
    "            \"\"\"+subpart2+\"\"\"\n",
    "            }\n",
    "        \"\"\"\n",
    "    elif (lexicon==\"duelme\"):\n",
    "        # part-of-speech filter not supported for this lexicon\n",
    "        if (pos is not None and pos != ''):\n",
    "            print('Filtering by part-of-speech is not (yet) supported in the \\''+lexicon+'\\' lexicon')\n",
    "        # exact or fuzzy search\n",
    "        exactsearch = (not containsRegex(word))\n",
    "        subpart = \"\"\"FILTER ( regex(?lemma, \\\"\"\"\"+word+\"\"\"\\\") || regex(?wordform, \\\"\"\"\"+word+\"\"\"\\\") ) .\"\"\"\n",
    "        if (exactsearch == True):\n",
    "            subpart =  \"\"\"\n",
    "                { ?y lmf:hasLemma ?dl .  \n",
    "                values ?dl { \\\"\"\"\"+word+\"\"\"\\\"@nl \\\"\"\"\"+word+\"\"\"\\\" } }                 \n",
    "                \"\"\"        \n",
    "        query = \"\"\"\n",
    "            PREFIX duelme: <http://rdf.ivdnt.org/lexica/duelme>\n",
    "            PREFIX intskos: <http://ivdnt.org/schema/lexica#>\n",
    "            PREFIX lmf: <http://www.lexinfo.net/lmf>\n",
    "            PREFIX ontolex: <http://www.w3.org/ns/lemon/ontolex#>\n",
    "            PREFIX UD: <http://rdf.ivdnt.org/vocabs/UniversalDependencies2#>\n",
    "            \n",
    "            SELECT ?exampleSentence ?lemma ?gender ?number\n",
    "            WHERE  {\n",
    "                  ?d intskos:ExampleSentence ?exampleSentence .\n",
    "                  ?d lmf:ListOfComponents [lmf:Component ?y] .\n",
    "                  ?y lmf:hasLemma ?lemma . \n",
    "                  OPTIONAL {?y UD:Gender ?gender}\n",
    "                  OPTIONAL {?y UD:Number ?number}\n",
    "            \"\"\"+subpart+\"\"\"\n",
    "            }\n",
    "        \"\"\"\n",
    "    elif (lexicon==\"celex\"):\n",
    "        # part-of-speech filter not supported for this lexicon\n",
    "        if (pos is not None and pos != ''):\n",
    "            print('Filtering by part-of-speech is not (yet) supported in the \\''+lexicon+'\\' lexicon')\n",
    "        # exact or fuzzy search\n",
    "        exactsearch = (not containsRegex(word))\n",
    "        subpart = \"\"\"FILTER ( regex(?lemma, \\\"\"\"\"+word+\"\"\"\\\") ) . \"\"\"\n",
    "        if (exactsearch == True):\n",
    "            subpart =  \"\"\"\n",
    "                { ?lemmaId ontolex:canonicalForm [ontolex:writtenRep ?lemma] .  \n",
    "                values ?lemma { \\\"\"\"\"+word+\"\"\"\\\"@nl \\\"\"\"\"+word+\"\"\"\\\" } }                 \n",
    "                \"\"\"        \n",
    "        query = \"\"\"\n",
    "            PREFIX ontolex: <http://www.w3.org/ns/lemon/ontolex#>\n",
    "            PREFIX celex: <http://rdf.ivdnt.org/lexica/celex>\n",
    "            PREFIX UD: <http://rdf.ivdnt.org/vocabs/UniversalDependencies2#>\n",
    "            PREFIX decomp: <http://www.w3.org/ns/lemon/decomp#>\n",
    "            PREFIX gold: <http://purl.org/linguistics/gold#>\n",
    "            \n",
    "            SELECT DISTINCT ?lemmaId ?lemma ?wordformId ?wordform ?number ?gender concat('', ?subLemmata) AS ?subLemmata\n",
    "            WHERE  {\n",
    "                ?lemmaId ontolex:canonicalForm [ontolex:writtenRep ?lemma] .\n",
    "                \"\"\"+subpart+\"\"\"\n",
    "                BIND( ?lemmaId AS ?lemmaIdIRI ).\n",
    "                ?lemmaId ontolex:lexicalForm ?wordformId .\n",
    "                ?wordformId ontolex:writtenRep ?wordform .\n",
    "                OPTIONAL {?wordformId UD:Number ?number} .\n",
    "                OPTIONAL {\n",
    "                    ?lemmaId UD:Gender ?g . \n",
    "                        bind( \n",
    "                            if(?g = UD:Fem_Gender, \n",
    "                            UD:Com_Gender, \n",
    "                                if(?g = UD:Masc_Gender,\n",
    "                                    UD:Com_Gender,\n",
    "                                    UD:Neut_Gender\n",
    "                                )\n",
    "                            )\n",
    "                            AS ?gender\n",
    "                        )\n",
    "                }\n",
    "                OPTIONAL {\n",
    "                    SELECT ?lemmaIdIRI (group_concat(DISTINCT concat(?partNr,\":\",?subLemma);separator=\" + \") as ?subLemmata)\n",
    "                    WHERE {\n",
    "                        SELECT ?lemmaIdIRI ?celexComp ?aWordformId ?subLemma ?partNr\n",
    "                        WHERE {\n",
    "                                {\n",
    "                                ?lemmaIdIRI ontolex:lexicalForm ?aWordformId . \n",
    "                                ?lemmaIdIRI decomp:constituent ?celexComp .\n",
    "                                OPTIONAL { ?celexComp gold:stem [ontolex:writtenRep ?subLemma] . }\n",
    "                                OPTIONAL { ?celexComp decomp:correspondsTo [ ontolex:canonicalForm [ontolex:writtenRep ?subLemma]] . }\n",
    "                                }\n",
    "                                {\n",
    "                                    {\n",
    "                                        {?lemmaIdIRI <http://www.w3.org/1999/02/22-rdf-syntax-ns#_1> ?celexComp .}\n",
    "                                        UNION\n",
    "                                        {?lemmaIdIRI <http://www.w3.org/1999/02/22-rdf-syntax-ns#_2> ?celexComp .}\n",
    "                                        UNION\n",
    "                                        {?lemmaIdIRI <http://www.w3.org/1999/02/22-rdf-syntax-ns#_3> ?celexComp .}\n",
    "                                        UNION\n",
    "                                        {?lemmaIdIRI <http://www.w3.org/1999/02/22-rdf-syntax-ns#_4> ?celexComp .}\n",
    "                                        UNION\n",
    "                                        {?lemmaIdIRI <http://www.w3.org/1999/02/22-rdf-syntax-ns#_5> ?celexComp .}\n",
    "                                        UNION\n",
    "                                        {?lemmaIdIRI <http://www.w3.org/1999/02/22-rdf-syntax-ns#_6> ?celexComp .}                                        \n",
    "                                    }\n",
    "                                ?lemmaIdIRI ?rdfsynt ?celexComp .\n",
    "                                BIND(IF(STRSTARTS(str(?rdfsynt), \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"), replace(STRAFTER(str(?rdfsynt), \"#\"), \"_\", \"\"), \"999\") AS ?partNr) .\n",
    "                                MINUS {\n",
    "                                    ?lemmaIdIRI <http://www.w3.org/1999/02/22-rdf-syntax-ns#0> ?celexComp .\n",
    "                                    }\n",
    "                                }\n",
    "                            FILTER (?partNr != \"999\") .\n",
    "                            }\n",
    "                            ORDER BY ?partNr\n",
    "                            }\n",
    "                        GROUP BY ?aWordformId ?lemmaIdIRI\n",
    "                    }\n",
    "            }\n",
    "        \"\"\"\n",
    "        \n",
    "    return query\n",
    "\n",
    "\n",
    "\n",
    "def corpus_query_lemma(lemma):\n",
    "    '''\n",
    "    This function builds a query for getting occurances of a given lemma within a given corpus\n",
    "    Args:\n",
    "        lemma: a lemma to look for \n",
    "    Returns:\n",
    "        a corpus query string\n",
    "        \n",
    "    >>> lemma_query = corpus_query_lemma(\"lopen\")\n",
    "    >>> df_corpus = search_corpus(lemma_query, \"chn\")\n",
    "    >>> display(df_corpus)\n",
    "    '''\n",
    "    return r'[lemma=\"'+ lemma + r'\"]'\n",
    "\n",
    "\n",
    "def corpus_query_wordform(word):\n",
    "    '''\n",
    "    This function builds a query for getting occurances of a given wordform within a given corpus\n",
    "    Args:\n",
    "        word: a wordform to look for \n",
    "    Returns:\n",
    "        a corpus query string\n",
    "        \n",
    "    >>> wordform_query = corpus_query_wordform(\"liep\")\n",
    "    >>> df_corpus = search_corpus(wordform_query, \"chn\")\n",
    "    >>> display(df_corpus)\n",
    "    '''\n",
    "    return r'[word=\"'+ word + r'\"]'\n",
    "\n",
    "def lexicon_query_alllemmata(lexicon, pos):\n",
    "    '''\n",
    "    This function builds a query for getting all lemmata of a lexicon, if needed restricted to a given part-of-speech.\n",
    "    The resulting query string is to be used as a parameter of search_lexicon().\n",
    "    \n",
    "    Args:\n",
    "        lexicon: a lexicon name \n",
    "        pos: (optional) a part-of-speech\n",
    "    Returns:\n",
    "        a lexicon query string\n",
    "    '''\n",
    "    \n",
    "    if (lexicon==\"anw\"):\n",
    "        # part-of-speech filter not supported for this lexicon\n",
    "        if (pos is not None and pos != ''):\n",
    "            print('Filtering by part-of-speech is not (yet) supported in the \\''+lexicon+'\\' lexicon')\n",
    "        query = \"\"\"PREFIX ontolex: <http://www.w3.org/ns/lemon/ontolex#>\n",
    "                  PREFIX anw: <http://rdf.ivdnt.org/lexica/anw>                  \n",
    "                  SELECT DISTINCT ?writtenForm\n",
    "                  FROM <http://rdf.ivdnt.org/lexica/anw>\n",
    "                  WHERE {\n",
    "                      ?lemId rdfs:label ?lemma .\n",
    "                      ?lemId ontolex:canonicalForm ?lemCFId . \n",
    "                      ?lemCFId ontolex:writtenRepresentation ?writtenForm .\n",
    "                      }\n",
    "                      ORDER BY ?writtenForm\"\"\"\n",
    "    elif (lexicon==\"celex\"):\n",
    "        # part-of-speech filter not supported for this lexicon\n",
    "        if (pos is not None and pos != ''):\n",
    "            print('Filtering by part-of-speech is not (yet) supported in the \\''+lexicon+'\\' lexicon')\n",
    "        query = \"\"\"\n",
    "            PREFIX ontolex: <http://www.w3.org/ns/lemon/ontolex#>\n",
    "            \n",
    "            SELECT DISTINCT ?lemma AS ?writtenForm\n",
    "            WHERE  {\n",
    "                ?lemmaId ontolex:canonicalForm [ontolex:writtenRep ?lemma] .                \n",
    "                }\n",
    "            ORDER BY ?lemma\"\"\"\n",
    "    elif (lexicon==\"diamant\"):\n",
    "        # part-of-speech filter not supported for this lexicon\n",
    "        if (pos is not None and pos != ''):\n",
    "            print('Filtering by part-of-speech is not (yet) supported in the \\''+lexicon+'\\' lexicon')\n",
    "        query = \"\"\"\n",
    "        PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "        prefix prov: <http://www.w3.org/ns/prov#>\n",
    "        prefix diamant: <http://rdf.ivdnt.org/schema/diamant#>\n",
    "        prefix lexinfo: <http://www.lexinfo.net/ontology/2.0/lexinfo#>\n",
    "        prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "        prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "        prefix lemon: <http://lemon-model.net/lemon#>\n",
    "        prefix ontolex: <http://www.w3.org/ns/lemon/ontolex#>\n",
    "        prefix ud: <http://universaldependencies.org/u/pos/>\n",
    "        prefix skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "        prefix dcterms: <http://purl.org/dc/terms/>\n",
    "        prefix dc: <http://purl.org/dc/terms/>\n",
    "\n",
    "        select DISTINCT ?n_ontolex_writtenRep AS ?writtenForm\n",
    "        where\n",
    "        {\n",
    "        graph ?g\n",
    "        {\n",
    "        {\n",
    "            { ?n_form ontolex:writtenRep ?n_ontolex_writtenRep} .\n",
    "            { ?n_form a ontolex:Form} .\n",
    "        }\n",
    "        }\n",
    "        }\n",
    "        ORDER BY ?n_ontolex_writtenRep\n",
    "        LIMIT 10000\n",
    "        \"\"\"\n",
    "    elif (lexicon==\"duelme\"):\n",
    "        # part-of-speech filter not supported for this lexicon\n",
    "        if (pos is not None and pos != ''):\n",
    "            print('Filtering by part-of-speech is not (yet) supported in the \\''+lexicon+'\\' lexicon')\n",
    "        query = \"\"\"\n",
    "            PREFIX lmf: <http://www.lexinfo.net/lmf>            \n",
    "            SELECT DISTINCT ?lemma AS ?writtenForm\n",
    "            WHERE  {\n",
    "                  ?y lmf:hasLemma ?lemma . \n",
    "            }\n",
    "            ORDER BY ?lemma\"\"\"\n",
    "    elif (lexicon==\"molex\"):\n",
    "        # part-of-speech filter\n",
    "        pos_condition = \"\"\"\"\"\"\n",
    "        if pos is not None and pos != '':\n",
    "            pos_condition = \"\"\"\n",
    "            {?lemEntryId UD:pos ?lemPos .\n",
    "            FILTER regex(?lemPos, '\"\"\"+pos+\"\"\"') } .\n",
    "            \"\"\"\n",
    "        query = \"\"\"\n",
    "                PREFIX ontolex: <http://www.w3.org/ns/lemon/ontolex#>\n",
    "                PREFIX UD: <http://universaldependencies.org/u/>\n",
    "                SELECT DISTINCT ?lemma AS ?writtenForm\n",
    "                FROM <http://rdf.ivdnt.org/lexica/molex>\n",
    "                WHERE\n",
    "                {\n",
    "                ?lemEntryId ontolex:canonicalForm ?lemCFId .\n",
    "                ?lemCFId ontolex:writtenRep ?lemma .  \n",
    "                \"\"\"+pos_condition+\"\"\"\n",
    "                }\n",
    "                 ORDER BY ?lemma\"\"\"\n",
    "    else:\n",
    "        raise ValueError(\"Lexicon \" + lexicon + \" not supported for querying all words.\")\n",
    "        \n",
    "    #print(query)\n",
    "    return query\n",
    "\n",
    "def _metadata_from_lexicon_query(lex_query):\n",
    "    '''\n",
    "    Extract metadata fields from a lexicon query string\n",
    "    \n",
    "    Args:\n",
    "        lex_query: A query string issued to a lexicon, can be constructed using lexicon_query()\n",
    "    Returns:\n",
    "        A list of metadata fields\n",
    "    '''\n",
    "    # Get part after select, eg: \"?x ?y ?concat('',z) as ?a\"\n",
    "    select_match = re.search(r'select\\s+(?:distinct)*\\s*(.*)\\s*(?:where|from)', lex_query, flags=re.IGNORECASE)\n",
    "    if select_match:\n",
    "        select_string = select_match.group(1)\n",
    "        #Delete concat() part and following AS, because it can contain a space we do not want to split on\n",
    "        string_wh_concat = re.sub(r'concat\\(.*\\) AS', '', select_string, flags=re.IGNORECASE)\n",
    "        split_string = string_wh_concat.split()\n",
    "        for i,elem in enumerate(split_string):\n",
    "            if elem.lower()==\"AS\":\n",
    "                # Remove AS and element before AS\n",
    "                split_string.pop(i)\n",
    "                split_string.pop(i-1)\n",
    "                # Assume only one AS, so we escape loop\n",
    "                break\n",
    "        columns = [c.lstrip(\"?\") for c in split_string]\n",
    "    else:\n",
    "        raise ValueError(\"No columns find in lexicon query.\")\n",
    "    return columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the cell below to show the UI, and fill in your search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T15:51:29.957256Z",
     "start_time": "2019-02-07T15:51:29.939067Z"
    }
   },
   "outputs": [],
   "source": [
    "#from chaininglib import ui\n",
    "\n",
    "# Create corpus UI, creates references to field contents\n",
    "corpusQueryField, corpusField = create_corpus_ui()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Click the cell below and press Run to perform the given query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-07T15:51:31.580633Z",
     "start_time": "2019-02-07T15:51:31.400999Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#from chaininglib import search\n",
    "query= corpusQueryField.value\n",
    "corpus = corpusField.value\n",
    "df_corpus = search_corpus(query, corpus)\n",
    "#df_corpus = load_dataframe('mijn_resultaten.csv')\n",
    "display_df(df_corpus, title=\"Results:\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexicon search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the cell below to show the UI, and fill in your search query in the UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T17:27:48.739501Z",
     "start_time": "2019-02-04T17:27:48.079Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from chaininglib import ui\n",
    "searchWordField, lexiconField = create_lexicon_ui()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Click the cell below and press Run to perform the given query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T17:27:48.740295Z",
     "start_time": "2019-02-04T17:27:48.082Z"
    }
   },
   "outputs": [],
   "source": [
    "#from chaininglib import queries, search\n",
    "\n",
    "search_word = searchWordField.value\n",
    "lexicon = lexiconField.value\n",
    "# USER: can replace this by own custom query\n",
    "query = lexicon_query(word=search_word, pos= '', lexicon=lexicon)\n",
    "\n",
    "df_lexicon = search_lexicon(query, lexicon)\n",
    "display(df_lexicon)\n",
    "#df_columns_list = list(df_lexicon.columns.values)\n",
    "#df_lexicon_in_columns = df_lexicon[df_columns_list]\n",
    "#display(df_lexicon_in_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study 1 (parallel): Frequency of *puur*+verb and *zuiver*+verb compared\n",
    "* Below cell searches for *puur*+verb and for *zuiver*+verb in the CHN corpus\n",
    "* Compare frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T17:27:48.741069Z",
     "start_time": "2019-02-04T17:27:48.086Z"
    }
   },
   "outputs": [],
   "source": [
    "#from chaininglib import search\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# Word 1: puur\n",
    "word1= \"puur\"\n",
    "df_corpus1 = search_corpus('[word=\"' + word1 + r'\"][pos=\"verb\"]',corpus=\"chn\")\n",
    "display(HTML('<b>' + word1 + '</b>'))\n",
    "display(df_corpus1)\n",
    "\n",
    "# Word 2: zuiver\n",
    "word2 = \"zuiver\"\n",
    "df_corpus2 = search_corpus(r'[word=\"' + word2 + r'\"][pos=\"verb\"]',\"chn\")\n",
    "display(HTML('<b>' + word2 + '</b>'))\n",
    "display(df_corpus2)\n",
    "\n",
    "# Compute difference\n",
    "diff_left, diff_right, intersec = column_difference(df_corpus1[\"word 1\"], df_corpus2[\"word 1\"])\n",
    "# Elements of 1 that are not in 2\n",
    "display(HTML('Werkwoorden voor <b>' + word1 + '</b> niet in <b>' + word2 + '</b>: ' + \", \".join(diff_left)))\n",
    "# Elements of 2 that are not in 1\n",
    "display(HTML('Werkwoorden voor <b>' + word1 + '</b> niet in <b>' + word2 + '</b>: ' + \", \".join(diff_right)))\n",
    "# Elements both in 1 and 2\n",
    "display(HTML('Werkwoorden zowel voor <b>' + word1 + '</b> als voor <b>' + word2 + '</b>: ' + \", \".join(intersec)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study 2 (sequential): Retrieve synonyms from DiaMaNT, look up in Gysseling\n",
    "* Below cell searches for term \"boek\" in DiaMaNT, and looks up all variants in Gysseling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T17:27:48.741938Z",
     "start_time": "2019-02-04T17:27:48.090Z"
    }
   },
   "outputs": [],
   "source": [
    "search_word = \"boek\"\n",
    "lexicon = \"diamant\"\n",
    "corpus= \"gysseling\"\n",
    "\n",
    "# First, lookup synonyms in DiaMaNT\n",
    "query = lexicon_query(word=search_word, pos= '', lexicon=lexicon)\n",
    "df_lexicon = search_lexicon(query, lexicon)\n",
    "syns = diamant_get_synonyms(df_lexicon) \n",
    "syns.add(search_word) # Also add search word itself\n",
    "display(HTML('Synoniemen voor <b>' + search_word + '</b>: ' + \", \".join(syns)))\n",
    "\n",
    "# Search for all synonyms in corpus\n",
    "## Create queries: search by lemma\n",
    "syns_queries = [corpus_query_lemma(syn) for syn in syns]\n",
    "## Search for all synonyms in corpus\n",
    "result_dict = search_corpus_multiple(syns_queries, corpus)\n",
    "view_multiple_results(result_dict, labels=list(syns))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T16:24:19.655999Z",
     "start_time": "2019-01-11T16:24:19.645252Z"
    }
   },
   "source": [
    "## Case study (parallel) 3: Find corpus words not in lexicon; list most frequent ones.\n",
    "* Only parallel if you can ask the lexicon a list of all words.\n",
    "* Currently only working: ask DiaMaNT list of words (limited at 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T17:27:48.742799Z",
     "start_time": "2019-02-04T17:27:48.094Z"
    }
   },
   "outputs": [],
   "source": [
    "# Query lexicon to give list of all words\n",
    "lexicon=\"anw\"\n",
    "df_lexicon = search_lexicon_alllemmata(lexicon)\n",
    "## TODO: Why do double words appear?\n",
    "lexicon_set = sorted( set([w.lower() for w in df_lexicon[\"writtenForm\"]]) )\n",
    "display(lexicon_set)\n",
    "\n",
    "df_corpus = search_corpus_allwords(\"gysseling\", None)\n",
    "display(df_corpus)\n",
    "len(df_corpus)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T15:46:20.519833Z",
     "start_time": "2019-01-16T15:46:20.516208Z"
    }
   },
   "source": [
    "## Case study (sequential) 4: Find occurences of attributive adjectives not ending with -e, even though they are preceeded by a definite article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T17:27:48.743596Z",
     "start_time": "2019-02-04T17:27:48.098Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus_to_search=\"opensonar\"\n",
    "lexicon_to_search=\"molex\"\n",
    "\n",
    "# CORPUS: get [article + attributive adjective + nouns] combinations in which the adjective does not end with -e\n",
    "print('Stap 1:')\n",
    "df_corpus = search_corpus(r'[lemma=\"de|het\"][word=\"^g(.+)[^e]$\" & pos=\"ADJ\"][pos=\"NOUN\"]', corpus=corpus_to_search)\n",
    "display(df_corpus)\n",
    "\n",
    "# LEXICON: get adjectives the lemma of which does not end with -e\n",
    "query=lexicon_query('^g(.+)[^e]$', 'ADJ', lexicon_to_search)\n",
    "df_lexicon = search_lexicon(query, lexicon_to_search)\n",
    "display(df_lexicon)\n",
    "\n",
    "# LEXICON: get adjectives having a final -e in definite attributive use\n",
    "print('Filtering lexicon results')\n",
    "df_lexicon_form_e = filter_df(df_lexicon,column=\"wordform\",method=\"regex\", regex_or_set = 'e$')\n",
    "#final_e_condition=df_lexicon.wordform.str.contains('e$')\n",
    "#df = df_lexicon[final_e_condition]\n",
    "display(df_lexicon_form_e)\n",
    "\n",
    "# RESULT: get the records out of our first list in which the -e-less-adjectives match the lemma form of our last list\n",
    "print('Wanted list:')\n",
    "e_forms = list(df_lexicon_form_e.lemma)\n",
    "#no_final_e_condition = df_corpus['word 1'].isin(eless_forms)\n",
    "#result_df = df_corpus[no_final_e_condition]\n",
    "result_df = filter_df(df_corpus, column = \"word 1\", method=\"isin\", regex_or_set=e_forms)\n",
    "display( result_df )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study (sequential) 5: (morphosyntactic lexicon and possibly unannotated corpus) Look up inflected forms and spelling variants for a given lemma in a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T17:27:48.744390Z",
     "start_time": "2019-02-04T17:27:48.101Z"
    }
   },
   "outputs": [],
   "source": [
    "lexicon_to_search=\"molex\"\n",
    "corpus_to_search=\"chn\"\n",
    "\n",
    "##############################################\n",
    "# TODO  zelfde met meerdere lemmata en gegroepeerd \n",
    "##############################################\n",
    "\n",
    "lemma_to_look_for=\"denken\"\n",
    "\n",
    "# LEXICON: Search for the inflected forms of a lemma in a morphosyntactic lexicon\n",
    "query=lexicon_query(lemma_to_look_for, None, lexicon_to_search)\n",
    "df_lexicon = search_lexicon(query, lexicon_to_search)\n",
    "display(df_lexicon)\n",
    "\n",
    "# Put all inflected forms into a list\n",
    "inflected_wordforms = list(df_lexicon.wordform)\n",
    "\n",
    "# CORPUS: Look up the inflected forms in a (possibly unannotated) corpus\n",
    "# beware: If the corpus is not annotated, all we can do is searching for the inflected words\n",
    "#         But if the corpus is lemmatized, we have to make sure we're retrieving correct data by specifying the lemma as well\n",
    "annotated_corpus = True\n",
    "query = r'[lemma=\"'+lemma_to_look_for+r'\" & word=\"'+r\"|\".join(inflected_wordforms)+r'\"]' if annotated_corpus else r'[word=\"'+r\"|\".join(inflected_wordforms)+r'\"]'\n",
    "df_corpus = search_corpus(query, corpus=corpus_to_search)\n",
    "display(df_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study 6: Build frequency table of some corpus, based on lemma list of a given lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T17:27:48.745116Z",
     "start_time": "2019-02-04T17:27:48.107Z"
    }
   },
   "outputs": [],
   "source": [
    "base_lexicon=\"anw\"\n",
    "corpus_to_search1=\"opensonar\"\n",
    "corpus_to_search2=\"chn\"\n",
    "\n",
    "# build frequency tables of two corpora\n",
    "\n",
    "df_frequency_list1 = get_frequency_list(base_lexicon, \"NOUN\", corpus_to_search1)\n",
    "display( df_frequency_list1.sort_values(ascending=False,by=['raw_freq']).head(25) )\n",
    "display_df(df_frequency_list1.sort_values(ascending=True, by=['rank']).head(25), columns='raw_freq', title='chart df1', mode='chart' )\n",
    "\n",
    "df_frequency_list2 = get_frequency_list(base_lexicon, \"NOUN\", corpus_to_search2)\n",
    "display(df_frequency_list2.sort_values(ascending=False,by=['raw_freq']).head(25))\n",
    "display_df(df_frequency_list2.sort_values(ascending=True, by=['rank']).head(25), columns='raw_freq', title='chart df2', mode='chart' )\n",
    "\n",
    "\n",
    "# TODO: lemmata tonen die in 1 of 2 ontbreken\n",
    "\n",
    "# compute the rank diff of lemmata in frequency tables\n",
    "\n",
    "df_rankdiffs = get_rank_diff(df_frequency_list1, df_frequency_list2)\n",
    "\n",
    "display(df_rankdiffs.sort_values(by=['rank_diff']).head(25))\n",
    "display_df( df_rankdiffs.sort_values(ascending=False, by=['rank_diff']).head(25), columns='rank_diff', title='chart large diff', mode='chart' )\n",
    "display_df( df_rankdiffs.sort_values(ascending=True, by=['rank_diff']).head(25), columns='rank_diff', title='chart small diff', mode='chart' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study 7: search in a corpus for wordforms of a lemma, which are not included in this lemma's paramadigm in a lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T17:27:48.745942Z",
     "start_time": "2019-02-04T17:27:48.110Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "base_lexicon=\"molex\"\n",
    "corpus_to_search=\"opensonar\"\n",
    "\n",
    "df = get_missing_wordforms(base_lexicon, \"VERB\", corpus_to_search)\n",
    "\n",
    "df.to_csv( \"missing_wordforms.csv\", index=False)\n",
    "#df = load_dataframe(\"missing_wordforms.csv\")\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study 8: Train a tagger with data from an annotated corpus, and do something cool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T17:27:48.746715Z",
     "start_time": "2019-02-04T17:27:48.113Z"
    }
   },
   "outputs": [],
   "source": [
    "base_lexicon=\"molex\"\n",
    "corpus_to_search1=\"opensonar\"\n",
    "corpus_to_search2=\"chn\"\n",
    "\n",
    "# we have a given word, let's say: \"loop\"\n",
    "some_word = \"loop\"\n",
    "\n",
    "# get the paradigm of the lemma our word is a part of\n",
    "query = lexicon_query(some_word, pos=None, lexicon=base_lexicon)\n",
    "df_paradigm = search_lexicon(query, base_lexicon)\n",
    "display(df_paradigm)\n",
    "\n",
    "# gather some pattern including our word, out of an annotated corpus\n",
    "# here: DET + ADJ + 'loop'\n",
    "corpus_query = corpus_query_wordform(some_word)\n",
    "df_corpus1 = search_corpus(corpus_query, corpus=corpus_to_search1, detailed_context=True)\n",
    "display(df_corpus1)\n",
    "df_corpus2 = search_corpus(corpus_query, corpus=corpus_to_search2, detailed_context=True)\n",
    "display(df_corpus2)\n",
    "\n",
    "\n",
    "df_all = concat_df([df_corpus1, df_corpus2], [corpus_to_search1, corpus_to_search2])\n",
    "display(df_all)\n",
    "\n",
    "# get a tagger trained with our corpus data\n",
    "tagger = get_tagger(df_all)\n",
    "\n",
    "# Use the trained tagger to tag unknown sentences\n",
    "# The input must be like: tagger.tag(['today','is','a','beautiful','day'])\n",
    "\n",
    "sentence = 'Mijn buurman kijkt door de loop van zijn geweer'\n",
    "tagged_sentence = tagger.tag( sentence.split() )\n",
    "\n",
    "print(tagged_sentence)\n",
    "\n",
    "\n",
    "# Know we can lemmatize each occurence of our lemma in the new sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study 9: Search in corpus and filter on metadata\n",
    "First, we request all available metadata fields of the corpus. Then, we issue a search query, and request all metadata fields for the result. Finally, we filter on metadata values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-08T16:29:06.839642Z",
     "start_time": "2019-02-08T16:29:06.410879Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>All results:</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left context</th>\n",
       "      <th>lemma 0</th>\n",
       "      <th>universal_dependency 0</th>\n",
       "      <th>word 0</th>\n",
       "      <th>aantal_paginas</th>\n",
       "      <th>aantal_woorden</th>\n",
       "      <th>adr_beroep</th>\n",
       "      <th>adr_bijzonderheden</th>\n",
       "      <th>adr_geb_decennium</th>\n",
       "      <th>adr_geb_jaar</th>\n",
       "      <th>...</th>\n",
       "      <th>signatuur</th>\n",
       "      <th>status</th>\n",
       "      <th>subcorpus</th>\n",
       "      <th>title</th>\n",
       "      <th>trans_bestand</th>\n",
       "      <th>trans_datum</th>\n",
       "      <th>type_brief</th>\n",
       "      <th>witnessYear_from</th>\n",
       "      <th>witnessYear_to</th>\n",
       "      <th>right context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heeft 4 gl 0 Aen</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken</td>\n",
       "      <td>2</td>\n",
       "      <td>496</td>\n",
       "      <td>schipper</td>\n",
       "      <td></td>\n",
       "      <td>1620</td>\n",
       "      <td>1623</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 32-1845-2</td>\n",
       "      <td>6</td>\n",
       "      <td>17B</td>\n",
       "      <td>To Lukas Pruijs, 13 januari 1661</td>\n",
       "      <td>06-01-2009 243-245-TR</td>\n",
       "      <td>2009-05-11 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1661</td>\n",
       "      <td>1661</td>\n",
       "      <td>en pampier en pennen en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lijeue man stelt alles te</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeck</td>\n",
       "      <td>1</td>\n",
       "      <td>900</td>\n",
       "      <td>schipper</td>\n",
       "      <td></td>\n",
       "      <td>1620</td>\n",
       "      <td>1623</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 32-1845-2</td>\n",
       "      <td>6</td>\n",
       "      <td>17A, 17B</td>\n",
       "      <td>To Lukas Pruijs, 6 juni 1664</td>\n",
       "      <td>06-01-2009 249-252-TR-def</td>\n",
       "      <td>2009-04-09 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1664</td>\n",
       "      <td>1664</td>\n",
       "      <td>waet ghij uijt geft dat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alzoo hij niet op de</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>bouck</td>\n",
       "      <td>1</td>\n",
       "      <td>302</td>\n",
       "      <td>koopman</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-644</td>\n",
       "      <td>6</td>\n",
       "      <td>17B</td>\n",
       "      <td>To Simon Been, 9 december 1664</td>\n",
       "      <td>06-01-2010 174-175-TR-def</td>\n",
       "      <td>unknown</td>\n",
       "      <td>private</td>\n",
       "      <td>1664</td>\n",
       "      <td>1664</td>\n",
       "      <td>en stondt en hij heeft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Schrijfpampier a 6 Sr t</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boek.</td>\n",
       "      <td>2</td>\n",
       "      <td>440</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-322</td>\n",
       "      <td>6</td>\n",
       "      <td>18V, 18Dbc</td>\n",
       "      <td>To J.H. Martens, 11 november 1780</td>\n",
       "      <td>07-01-2009 032-034-TR-def</td>\n",
       "      <td>2009-04-15 00:00:00</td>\n",
       "      <td>business</td>\n",
       "      <td>1780</td>\n",
       "      <td>1780</td>\n",
       "      <td>50 ditto ongsneeden ditto a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>voorne missive, dat UEDs mijn</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken</td>\n",
       "      <td>2</td>\n",
       "      <td>291</td>\n",
       "      <td>secretaris</td>\n",
       "      <td></td>\n",
       "      <td>1750</td>\n",
       "      <td>1751</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-323</td>\n",
       "      <td>6</td>\n",
       "      <td>18D</td>\n",
       "      <td>To Gabriel Lixraaven, 10 januari 1781</td>\n",
       "      <td>08-01-2009 109-110-TR-def</td>\n",
       "      <td>2009-11-21 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1781</td>\n",
       "      <td>1781</td>\n",
       "      <td>bij berntrop laat verkoopen, als</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>verbeeld hebbe, dat wat geleerde</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken</td>\n",
       "      <td>2</td>\n",
       "      <td>291</td>\n",
       "      <td>secretaris</td>\n",
       "      <td></td>\n",
       "      <td>1750</td>\n",
       "      <td>1751</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-323</td>\n",
       "      <td>6</td>\n",
       "      <td>18D</td>\n",
       "      <td>To Gabriel Lixraaven, 10 januari 1781</td>\n",
       "      <td>08-01-2009 109-110-TR-def</td>\n",
       "      <td>2009-11-21 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1781</td>\n",
       "      <td>1781</td>\n",
       "      <td>aan gaat, schouten altoos geprafereert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>beijde, accuratesse goede order der</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boecken,</td>\n",
       "      <td>2</td>\n",
       "      <td>559</td>\n",
       "      <td>reder</td>\n",
       "      <td></td>\n",
       "      <td>1750</td>\n",
       "      <td>1757</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-323</td>\n",
       "      <td>6</td>\n",
       "      <td>18D</td>\n",
       "      <td>To David Wendorp, 16 december 1780</td>\n",
       "      <td>08-01-2009 133-135-TR-def</td>\n",
       "      <td>2009-09-09 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1780</td>\n",
       "      <td>1780</td>\n",
       "      <td>&amp; Voorsigtigheijd, die prijse ik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rollen matten MR &amp; Eenige</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken</td>\n",
       "      <td>3</td>\n",
       "      <td>844</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1730</td>\n",
       "      <td>1736</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-323</td>\n",
       "      <td>6</td>\n",
       "      <td>18D</td>\n",
       "      <td>To Magdalena Wendorp-Bagge, 16 december 1780</td>\n",
       "      <td>08-01-2009 149-151-TR-def</td>\n",
       "      <td>2009-06-10 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1780</td>\n",
       "      <td>1780</td>\n",
       "      <td>Maar also die twee Scheepen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>te Senden, &amp; wat de</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken</td>\n",
       "      <td>3</td>\n",
       "      <td>844</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1730</td>\n",
       "      <td>1736</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-323</td>\n",
       "      <td>6</td>\n",
       "      <td>18D</td>\n",
       "      <td>To Magdalena Wendorp-Bagge, 16 december 1780</td>\n",
       "      <td>08-01-2009 149-151-TR-def</td>\n",
       "      <td>2009-06-10 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1780</td>\n",
       "      <td>1780</td>\n",
       "      <td>aan betreft Zo Gelieft maar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>laaten wagten tot ik mijn</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken</td>\n",
       "      <td>2</td>\n",
       "      <td>630</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-319</td>\n",
       "      <td>6</td>\n",
       "      <td>18S, 18A, 18Da</td>\n",
       "      <td>To Christiaan Frederik Coller, december 1780</td>\n",
       "      <td>1108-1110-TR-def</td>\n",
       "      <td>2009-01-22 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1780</td>\n",
       "      <td>1780</td>\n",
       "      <td>heeft, want weet anders niet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&amp; houw nu alle de</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken</td>\n",
       "      <td>2</td>\n",
       "      <td>630</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-319</td>\n",
       "      <td>6</td>\n",
       "      <td>18S, 18A, 18Da</td>\n",
       "      <td>To Christiaan Frederik Coller, december 1780</td>\n",
       "      <td>1108-1110-TR-def</td>\n",
       "      <td>2009-01-22 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1780</td>\n",
       "      <td>1780</td>\n",
       "      <td>&amp; bonte &amp; die sijn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gantsche regel die in myn</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Boek</td>\n",
       "      <td>3</td>\n",
       "      <td>1448</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-368</td>\n",
       "      <td>6</td>\n",
       "      <td>18S, 18Da</td>\n",
       "      <td>To Christina Bakker-Smits, 26 september 1780</td>\n",
       "      <td>1156-1159-TR-def</td>\n",
       "      <td>2008-09-11 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1780</td>\n",
       "      <td>1780</td>\n",
       "      <td>niet te vinden is, en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>al frij hoch bij hente</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>bock</td>\n",
       "      <td>1</td>\n",
       "      <td>409</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1630</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-647</td>\n",
       "      <td>6</td>\n",
       "      <td>17B</td>\n",
       "      <td>To Maartje Nannings, 12 februari 1665</td>\n",
       "      <td>16-06-2009 153-154-TR-def</td>\n",
       "      <td>2009-10-25 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1665</td>\n",
       "      <td>1665</td>\n",
       "      <td>soo het scijnt en men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>reeck. van hem wt v</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken</td>\n",
       "      <td>1</td>\n",
       "      <td>453</td>\n",
       "      <td>koopman</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-223</td>\n",
       "      <td>6</td>\n",
       "      <td>17B</td>\n",
       "      <td>To Michiel Heusch jr., 19 oktober 1664</td>\n",
       "      <td>17-06-2009 011-012-TR-def</td>\n",
       "      <td>2010-01-04 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1664</td>\n",
       "      <td>1664</td>\n",
       "      <td>Is heden versuijmt wij sijn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>maer ick behoefde wel een</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeck</td>\n",
       "      <td>2</td>\n",
       "      <td>517</td>\n",
       "      <td>timmerman</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-223</td>\n",
       "      <td>6</td>\n",
       "      <td>17B</td>\n",
       "      <td>To Eldert Jansz., 6 november 1672</td>\n",
       "      <td>17-06-2009 220-222-TR-def</td>\n",
       "      <td>2009-10-14 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1672</td>\n",
       "      <td>1672</td>\n",
       "      <td>pampier te hebben daerom sal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dan ick behoefde wel een</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeck</td>\n",
       "      <td>2</td>\n",
       "      <td>562</td>\n",
       "      <td>kwartiermeester</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-223</td>\n",
       "      <td>6</td>\n",
       "      <td>17B</td>\n",
       "      <td>To Willem Lukasz., november 1672</td>\n",
       "      <td>17-06-2009 275-277-TR-def</td>\n",
       "      <td>2009-11-09 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1672</td>\n",
       "      <td>1672</td>\n",
       "      <td>Pampier daerom sal ick opbreecken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>van concept en wilde syn</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken</td>\n",
       "      <td>2</td>\n",
       "      <td>669</td>\n",
       "      <td>koopman</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-353</td>\n",
       "      <td>6</td>\n",
       "      <td>18Dbc</td>\n",
       "      <td>To Johan Godfried Meeler, 5 januari 1781</td>\n",
       "      <td>17-06-2009 324-326-TR-def</td>\n",
       "      <td>2009-10-22 00:00:00</td>\n",
       "      <td>business</td>\n",
       "      <td>1781</td>\n",
       "      <td>1781</td>\n",
       "      <td>absolut ter secretarij versorgen Eyndelyk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>’t Eijschen, van onvertueren van</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken</td>\n",
       "      <td>2</td>\n",
       "      <td>669</td>\n",
       "      <td>koopman</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-353</td>\n",
       "      <td>6</td>\n",
       "      <td>18Dbc</td>\n",
       "      <td>To Johan Godfried Meeler, 5 januari 1781</td>\n",
       "      <td>17-06-2009 324-326-TR-def</td>\n",
       "      <td>2009-10-22 00:00:00</td>\n",
       "      <td>business</td>\n",
       "      <td>1781</td>\n",
       "      <td>1781</td>\n",
       "      <td>ligten van copien Extracten of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>post ryders of eenige andere</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken,</td>\n",
       "      <td>4</td>\n",
       "      <td>677</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-348</td>\n",
       "      <td>6</td>\n",
       "      <td>18Da</td>\n",
       "      <td>To Margaretha Berewout-Huurdeman, 30 januari 1781</td>\n",
       "      <td>17-06-2009 428-432-TR-def2</td>\n",
       "      <td>2009-10-22 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1781</td>\n",
       "      <td>1781</td>\n",
       "      <td>ook eenige ingelyd groente of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ik u bij dese, 2</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Boecken,</td>\n",
       "      <td>1</td>\n",
       "      <td>351</td>\n",
       "      <td>onderschrijver</td>\n",
       "      <td></td>\n",
       "      <td>1650</td>\n",
       "      <td>1652</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-228</td>\n",
       "      <td>6</td>\n",
       "      <td>17B</td>\n",
       "      <td>To Martinus Bruno, 7 november 1672</td>\n",
       "      <td>3-1-2008 185-TR-def</td>\n",
       "      <td>2010-02-19 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1672</td>\n",
       "      <td>1672</td>\n",
       "      <td>die bij mij gedrukt en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>seggen dat in ander mans</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>bocken</td>\n",
       "      <td>2</td>\n",
       "      <td>367</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-642-1</td>\n",
       "      <td>6</td>\n",
       "      <td>17B</td>\n",
       "      <td>To Elsje Schoonhoven, 9 december 1664</td>\n",
       "      <td>3b-1-2008 161-162-TR-def</td>\n",
       "      <td>2009-06-02 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1664</td>\n",
       "      <td>1664</td>\n",
       "      <td>quadt studeren is voor waert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>niets van myne agter gelatene</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken</td>\n",
       "      <td>3</td>\n",
       "      <td>868</td>\n",
       "      <td>koopman</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-339</td>\n",
       "      <td>6</td>\n",
       "      <td>18S, 18Da</td>\n",
       "      <td>To Jacob Neuhoff, 1 februari 1781</td>\n",
       "      <td>4-1-2008 185-188-TR-def</td>\n",
       "      <td>2008-07-08 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1781</td>\n",
       "      <td>1781</td>\n",
       "      <td>vernomen nog hoe de suyker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Bedanke UEd voor de toegezondene</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Boeken,</td>\n",
       "      <td>4</td>\n",
       "      <td>319</td>\n",
       "      <td>boekverkoper</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-341</td>\n",
       "      <td>6</td>\n",
       "      <td>18Da</td>\n",
       "      <td>To J.M. van Vloten, 26 september 1780</td>\n",
       "      <td>5-1-2008 115-119-TR-def</td>\n",
       "      <td>2008-04-24 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1780</td>\n",
       "      <td>1780</td>\n",
       "      <td>houde my daarontrent Verder gerécommandeert,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>26 september 1780 Nota Van</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Boeken</td>\n",
       "      <td>4</td>\n",
       "      <td>319</td>\n",
       "      <td>boekverkoper</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-341</td>\n",
       "      <td>6</td>\n",
       "      <td>18Da</td>\n",
       "      <td>To J.M. van Vloten, 26 september 1780</td>\n",
       "      <td>5-1-2008 115-119-TR-def</td>\n",
       "      <td>2008-04-24 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1780</td>\n",
       "      <td>1780</td>\n",
       "      <td>&amp; voor d’Heer J.M.Van Vloten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Hr van Tiel die uE</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken</td>\n",
       "      <td>3</td>\n",
       "      <td>1545</td>\n",
       "      <td>eigenaar plantage</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-341</td>\n",
       "      <td>6</td>\n",
       "      <td>18Da</td>\n",
       "      <td>To Jan Jacob de Wind, 21 januari 1781</td>\n",
       "      <td>5-1-2008 212-215-TR-def</td>\n",
       "      <td>2009-02-18 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1781</td>\n",
       "      <td>1781</td>\n",
       "      <td>houdt, heeft niet kunnen klaar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>om uE Copij van die</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken</td>\n",
       "      <td>3</td>\n",
       "      <td>1545</td>\n",
       "      <td>eigenaar plantage</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-341</td>\n",
       "      <td>6</td>\n",
       "      <td>18Da</td>\n",
       "      <td>To Jan Jacob de Wind, 21 januari 1781</td>\n",
       "      <td>5-1-2008 212-215-TR-def</td>\n",
       "      <td>2009-02-18 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1781</td>\n",
       "      <td>1781</td>\n",
       "      <td>te senden, het welk pr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>de Datums als in Zyn</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boek</td>\n",
       "      <td>3</td>\n",
       "      <td>1545</td>\n",
       "      <td>eigenaar plantage</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-341</td>\n",
       "      <td>6</td>\n",
       "      <td>18Da</td>\n",
       "      <td>To Jan Jacob de Wind, 21 januari 1781</td>\n",
       "      <td>5-1-2008 212-215-TR-def</td>\n",
       "      <td>2009-02-18 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1781</td>\n",
       "      <td>1781</td>\n",
       "      <td>genoteert staat, de reeden is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>leezen van diverse, voornaemlijk Historische,</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Boeken</td>\n",
       "      <td>2</td>\n",
       "      <td>359</td>\n",
       "      <td>stuurman</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-750</td>\n",
       "      <td>6</td>\n",
       "      <td>18D</td>\n",
       "      <td>To Jan Lukas Doeve, 15 januari 1781</td>\n",
       "      <td>650-652-TR-def</td>\n",
       "      <td>unknown</td>\n",
       "      <td>private</td>\n",
       "      <td>1781</td>\n",
       "      <td>1781</td>\n",
       "      <td>zodaenig zult bevlijtigd hebben dat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>heeft UE schryf om een</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boek</td>\n",
       "      <td>4</td>\n",
       "      <td>518</td>\n",
       "      <td>assistent</td>\n",
       "      <td></td>\n",
       "      <td>1750</td>\n",
       "      <td>1750</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-317</td>\n",
       "      <td>6</td>\n",
       "      <td>18A, 18Da</td>\n",
       "      <td>To Abraham Entink, 28 oktober 1780</td>\n",
       "      <td>722-726-TR-def</td>\n",
       "      <td>2007-10-21 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1780</td>\n",
       "      <td>1780</td>\n",
       "      <td>ik weet niet hoe veel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>die moet nu ook gedurig</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken</td>\n",
       "      <td>4</td>\n",
       "      <td>518</td>\n",
       "      <td>assistent</td>\n",
       "      <td></td>\n",
       "      <td>1750</td>\n",
       "      <td>1750</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-317</td>\n",
       "      <td>6</td>\n",
       "      <td>18A, 18Da</td>\n",
       "      <td>To Abraham Entink, 28 oktober 1780</td>\n",
       "      <td>722-726-TR-def</td>\n",
       "      <td>2007-10-21 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1780</td>\n",
       "      <td>1780</td>\n",
       "      <td>hebbe, ik ben alle jare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ik het wissiltie wegens die</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken</td>\n",
       "      <td>1</td>\n",
       "      <td>229</td>\n",
       "      <td>kapitein</td>\n",
       "      <td></td>\n",
       "      <td>1710</td>\n",
       "      <td>1718</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-336</td>\n",
       "      <td>6</td>\n",
       "      <td>18A, 18Da</td>\n",
       "      <td>To Gerrit Harmeijer, 7 oktober 1780</td>\n",
       "      <td>KB 336-018-TR-def</td>\n",
       "      <td>2008-11-21 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1780</td>\n",
       "      <td>1780</td>\n",
       "      <td>die onse Zoon Gerrit heeft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ik myn liede man wat</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>bokken</td>\n",
       "      <td>1</td>\n",
       "      <td>176</td>\n",
       "      <td>derde waak</td>\n",
       "      <td></td>\n",
       "      <td>1740</td>\n",
       "      <td>1748</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-750</td>\n",
       "      <td>6</td>\n",
       "      <td>18Da</td>\n",
       "      <td>To Christiaan de Cerff, december 1779</td>\n",
       "      <td>KB c14-1-c14-2-TR-def</td>\n",
       "      <td>2010-12-06 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1779</td>\n",
       "      <td>1779</td>\n",
       "      <td>wat kastengen wat nuyten wat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      left context lemma 0  \\\n",
       "0                                heeft 4 gl 0 Aen     boek   \n",
       "1                       lijeue man stelt alles te     boek   \n",
       "2                            alzoo hij niet op de     boek   \n",
       "3                         Schrijfpampier a 6 Sr t     boek   \n",
       "4                   voorne missive, dat UEDs mijn     boek   \n",
       "5                verbeeld hebbe, dat wat geleerde     boek   \n",
       "6             beijde, accuratesse goede order der     boek   \n",
       "7                       rollen matten MR & Eenige     boek   \n",
       "8                             te Senden, & wat de     boek   \n",
       "9                       laaten wagten tot ik mijn     boek   \n",
       "10                              & houw nu alle de     boek   \n",
       "11                      gantsche regel die in myn     boek   \n",
       "12                         al frij hoch bij hente     boek   \n",
       "13                            reeck. van hem wt v     boek   \n",
       "14                      maer ick behoefde wel een     boek   \n",
       "15                       dan ick behoefde wel een     boek   \n",
       "16                       van concept en wilde syn     boek   \n",
       "17               ’t Eijschen, van onvertueren van     boek   \n",
       "18                   post ryders of eenige andere     boek   \n",
       "19                               ik u bij dese, 2     boek   \n",
       "20                       seggen dat in ander mans     boek   \n",
       "21                  niets van myne agter gelatene     boek   \n",
       "22               Bedanke UEd voor de toegezondene     boek   \n",
       "23                     26 september 1780 Nota Van     boek   \n",
       "24                             Hr van Tiel die uE     boek   \n",
       "25                            om uE Copij van die     boek   \n",
       "26                           de Datums als in Zyn     boek   \n",
       "27  leezen van diverse, voornaemlijk Historische,     boek   \n",
       "28                         heeft UE schryf om een     boek   \n",
       "29                        die moet nu ook gedurig     boek   \n",
       "30                    ik het wissiltie wegens die     boek   \n",
       "31                           ik myn liede man wat     boek   \n",
       "\n",
       "   universal_dependency 0    word 0 aantal_paginas aantal_woorden  \\\n",
       "0                    NOUN    boeken              2            496   \n",
       "1                    NOUN     boeck              1            900   \n",
       "2                    NOUN     bouck              1            302   \n",
       "3                    NOUN     boek.              2            440   \n",
       "4                    NOUN    boeken              2            291   \n",
       "5                    NOUN    boeken              2            291   \n",
       "6                    NOUN  boecken,              2            559   \n",
       "7                    NOUN    boeken              3            844   \n",
       "8                    NOUN    boeken              3            844   \n",
       "9                    NOUN    boeken              2            630   \n",
       "10                   NOUN    boeken              2            630   \n",
       "11                   NOUN      Boek              3           1448   \n",
       "12                   NOUN      bock              1            409   \n",
       "13                   NOUN    boeken              1            453   \n",
       "14                   NOUN     boeck              2            517   \n",
       "15                   NOUN     boeck              2            562   \n",
       "16                   NOUN    boeken              2            669   \n",
       "17                   NOUN    boeken              2            669   \n",
       "18                   NOUN   boeken,              4            677   \n",
       "19                   NOUN  Boecken,              1            351   \n",
       "20                   NOUN    bocken              2            367   \n",
       "21                   NOUN    boeken              3            868   \n",
       "22                   NOUN   Boeken,              4            319   \n",
       "23                   NOUN    Boeken              4            319   \n",
       "24                   NOUN    boeken              3           1545   \n",
       "25                   NOUN    boeken              3           1545   \n",
       "26                   NOUN      boek              3           1545   \n",
       "27                   NOUN    Boeken              2            359   \n",
       "28                   NOUN      boek              4            518   \n",
       "29                   NOUN    boeken              4            518   \n",
       "30                   NOUN    boeken              1            229   \n",
       "31                   NOUN    bokken              1            176   \n",
       "\n",
       "           adr_beroep adr_bijzonderheden adr_geb_decennium adr_geb_jaar  \\\n",
       "0            schipper                                 1620         1623   \n",
       "1            schipper                                 1620         1623   \n",
       "2             koopman                              unknown      unknown   \n",
       "3                                                  unknown      unknown   \n",
       "4          secretaris                                 1750         1751   \n",
       "5          secretaris                                 1750         1751   \n",
       "6               reder                                 1750         1757   \n",
       "7                                                     1730         1736   \n",
       "8                                                     1730         1736   \n",
       "9                                                  unknown      unknown   \n",
       "10                                                 unknown      unknown   \n",
       "11                                                 unknown      unknown   \n",
       "12                                                    1630      unknown   \n",
       "13            koopman                              unknown      unknown   \n",
       "14          timmerman                              unknown      unknown   \n",
       "15    kwartiermeester                              unknown      unknown   \n",
       "16            koopman                              unknown      unknown   \n",
       "17            koopman                              unknown      unknown   \n",
       "18                                                 unknown      unknown   \n",
       "19     onderschrijver                                 1650         1652   \n",
       "20                                                 unknown      unknown   \n",
       "21            koopman                              unknown      unknown   \n",
       "22       boekverkoper                              unknown      unknown   \n",
       "23       boekverkoper                              unknown      unknown   \n",
       "24  eigenaar plantage                              unknown      unknown   \n",
       "25  eigenaar plantage                              unknown      unknown   \n",
       "26  eigenaar plantage                              unknown      unknown   \n",
       "27           stuurman                              unknown      unknown   \n",
       "28          assistent                                 1750         1750   \n",
       "29          assistent                                 1750         1750   \n",
       "30           kapitein                                 1710         1718   \n",
       "31         derde waak                                 1740         1748   \n",
       "\n",
       "                        ...                            signatuur status  \\\n",
       "0                       ...                        HCA 32-1845-2      6   \n",
       "1                       ...                        HCA 32-1845-2      6   \n",
       "2                       ...                           HCA 30-644      6   \n",
       "3                       ...                           HCA 30-322      6   \n",
       "4                       ...                           HCA 30-323      6   \n",
       "5                       ...                           HCA 30-323      6   \n",
       "6                       ...                           HCA 30-323      6   \n",
       "7                       ...                           HCA 30-323      6   \n",
       "8                       ...                           HCA 30-323      6   \n",
       "9                       ...                           HCA 30-319      6   \n",
       "10                      ...                           HCA 30-319      6   \n",
       "11                      ...                           HCA 30-368      6   \n",
       "12                      ...                           HCA 30-647      6   \n",
       "13                      ...                           HCA 30-223      6   \n",
       "14                      ...                           HCA 30-223      6   \n",
       "15                      ...                           HCA 30-223      6   \n",
       "16                      ...                           HCA 30-353      6   \n",
       "17                      ...                           HCA 30-353      6   \n",
       "18                      ...                           HCA 30-348      6   \n",
       "19                      ...                           HCA 30-228      6   \n",
       "20                      ...                         HCA 30-642-1      6   \n",
       "21                      ...                           HCA 30-339      6   \n",
       "22                      ...                           HCA 30-341      6   \n",
       "23                      ...                           HCA 30-341      6   \n",
       "24                      ...                           HCA 30-341      6   \n",
       "25                      ...                           HCA 30-341      6   \n",
       "26                      ...                           HCA 30-341      6   \n",
       "27                      ...                           HCA 30-750      6   \n",
       "28                      ...                           HCA 30-317      6   \n",
       "29                      ...                           HCA 30-317      6   \n",
       "30                      ...                           HCA 30-336      6   \n",
       "31                      ...                           HCA 30-750      6   \n",
       "\n",
       "         subcorpus                                              title  \\\n",
       "0              17B                   To Lukas Pruijs, 13 januari 1661   \n",
       "1         17A, 17B                       To Lukas Pruijs, 6 juni 1664   \n",
       "2              17B                     To Simon Been, 9 december 1664   \n",
       "3       18V, 18Dbc                  To J.H. Martens, 11 november 1780   \n",
       "4              18D              To Gabriel Lixraaven, 10 januari 1781   \n",
       "5              18D              To Gabriel Lixraaven, 10 januari 1781   \n",
       "6              18D                 To David Wendorp, 16 december 1780   \n",
       "7              18D       To Magdalena Wendorp-Bagge, 16 december 1780   \n",
       "8              18D       To Magdalena Wendorp-Bagge, 16 december 1780   \n",
       "9   18S, 18A, 18Da       To Christiaan Frederik Coller, december 1780   \n",
       "10  18S, 18A, 18Da       To Christiaan Frederik Coller, december 1780   \n",
       "11       18S, 18Da       To Christina Bakker-Smits, 26 september 1780   \n",
       "12             17B              To Maartje Nannings, 12 februari 1665   \n",
       "13             17B             To Michiel Heusch jr., 19 oktober 1664   \n",
       "14             17B                  To Eldert Jansz., 6 november 1672   \n",
       "15             17B                   To Willem Lukasz., november 1672   \n",
       "16           18Dbc           To Johan Godfried Meeler, 5 januari 1781   \n",
       "17           18Dbc           To Johan Godfried Meeler, 5 januari 1781   \n",
       "18            18Da  To Margaretha Berewout-Huurdeman, 30 januari 1781   \n",
       "19             17B                 To Martinus Bruno, 7 november 1672   \n",
       "20             17B              To Elsje Schoonhoven, 9 december 1664   \n",
       "21       18S, 18Da                  To Jacob Neuhoff, 1 februari 1781   \n",
       "22            18Da              To J.M. van Vloten, 26 september 1780   \n",
       "23            18Da              To J.M. van Vloten, 26 september 1780   \n",
       "24            18Da              To Jan Jacob de Wind, 21 januari 1781   \n",
       "25            18Da              To Jan Jacob de Wind, 21 januari 1781   \n",
       "26            18Da              To Jan Jacob de Wind, 21 januari 1781   \n",
       "27             18D                To Jan Lukas Doeve, 15 januari 1781   \n",
       "28       18A, 18Da                 To Abraham Entink, 28 oktober 1780   \n",
       "29       18A, 18Da                 To Abraham Entink, 28 oktober 1780   \n",
       "30       18A, 18Da                To Gerrit Harmeijer, 7 oktober 1780   \n",
       "31            18Da              To Christiaan de Cerff, december 1779   \n",
       "\n",
       "                 trans_bestand          trans_datum type_brief  \\\n",
       "0        06-01-2009 243-245-TR  2009-05-11 00:00:00    private   \n",
       "1    06-01-2009 249-252-TR-def  2009-04-09 00:00:00    private   \n",
       "2    06-01-2010 174-175-TR-def              unknown    private   \n",
       "3    07-01-2009 032-034-TR-def  2009-04-15 00:00:00   business   \n",
       "4    08-01-2009 109-110-TR-def  2009-11-21 00:00:00    private   \n",
       "5    08-01-2009 109-110-TR-def  2009-11-21 00:00:00    private   \n",
       "6    08-01-2009 133-135-TR-def  2009-09-09 00:00:00    private   \n",
       "7    08-01-2009 149-151-TR-def  2009-06-10 00:00:00    private   \n",
       "8    08-01-2009 149-151-TR-def  2009-06-10 00:00:00    private   \n",
       "9             1108-1110-TR-def  2009-01-22 00:00:00    private   \n",
       "10            1108-1110-TR-def  2009-01-22 00:00:00    private   \n",
       "11            1156-1159-TR-def  2008-09-11 00:00:00    private   \n",
       "12   16-06-2009 153-154-TR-def  2009-10-25 00:00:00    private   \n",
       "13   17-06-2009 011-012-TR-def  2010-01-04 00:00:00    private   \n",
       "14   17-06-2009 220-222-TR-def  2009-10-14 00:00:00    private   \n",
       "15   17-06-2009 275-277-TR-def  2009-11-09 00:00:00    private   \n",
       "16   17-06-2009 324-326-TR-def  2009-10-22 00:00:00   business   \n",
       "17   17-06-2009 324-326-TR-def  2009-10-22 00:00:00   business   \n",
       "18  17-06-2009 428-432-TR-def2  2009-10-22 00:00:00    private   \n",
       "19         3-1-2008 185-TR-def  2010-02-19 00:00:00    private   \n",
       "20    3b-1-2008 161-162-TR-def  2009-06-02 00:00:00    private   \n",
       "21     4-1-2008 185-188-TR-def  2008-07-08 00:00:00    private   \n",
       "22     5-1-2008 115-119-TR-def  2008-04-24 00:00:00    private   \n",
       "23     5-1-2008 115-119-TR-def  2008-04-24 00:00:00    private   \n",
       "24     5-1-2008 212-215-TR-def  2009-02-18 00:00:00    private   \n",
       "25     5-1-2008 212-215-TR-def  2009-02-18 00:00:00    private   \n",
       "26     5-1-2008 212-215-TR-def  2009-02-18 00:00:00    private   \n",
       "27              650-652-TR-def              unknown    private   \n",
       "28              722-726-TR-def  2007-10-21 00:00:00    private   \n",
       "29              722-726-TR-def  2007-10-21 00:00:00    private   \n",
       "30           KB 336-018-TR-def  2008-11-21 00:00:00    private   \n",
       "31       KB c14-1-c14-2-TR-def  2010-12-06 00:00:00    private   \n",
       "\n",
       "   witnessYear_from witnessYear_to  \\\n",
       "0              1661           1661   \n",
       "1              1664           1664   \n",
       "2              1664           1664   \n",
       "3              1780           1780   \n",
       "4              1781           1781   \n",
       "5              1781           1781   \n",
       "6              1780           1780   \n",
       "7              1780           1780   \n",
       "8              1780           1780   \n",
       "9              1780           1780   \n",
       "10             1780           1780   \n",
       "11             1780           1780   \n",
       "12             1665           1665   \n",
       "13             1664           1664   \n",
       "14             1672           1672   \n",
       "15             1672           1672   \n",
       "16             1781           1781   \n",
       "17             1781           1781   \n",
       "18             1781           1781   \n",
       "19             1672           1672   \n",
       "20             1664           1664   \n",
       "21             1781           1781   \n",
       "22             1780           1780   \n",
       "23             1780           1780   \n",
       "24             1781           1781   \n",
       "25             1781           1781   \n",
       "26             1781           1781   \n",
       "27             1781           1781   \n",
       "28             1780           1780   \n",
       "29             1780           1780   \n",
       "30             1780           1780   \n",
       "31             1779           1779   \n",
       "\n",
       "                                    right context  \n",
       "0                         en pampier en pennen en  \n",
       "1                         waet ghij uijt geft dat  \n",
       "2                          en stondt en hij heeft  \n",
       "3                     50 ditto ongsneeden ditto a  \n",
       "4                bij berntrop laat verkoopen, als  \n",
       "5          aan gaat, schouten altoos geprafereert  \n",
       "6                & Voorsigtigheijd, die prijse ik  \n",
       "7                     Maar also die twee Scheepen  \n",
       "8                     aan betreft Zo Gelieft maar  \n",
       "9                    heeft, want weet anders niet  \n",
       "10                             & bonte & die sijn  \n",
       "11                          niet te vinden is, en  \n",
       "12                          soo het scijnt en men  \n",
       "13                    Is heden versuijmt wij sijn  \n",
       "14                   pampier te hebben daerom sal  \n",
       "15              Pampier daerom sal ick opbreecken  \n",
       "16      absolut ter secretarij versorgen Eyndelyk  \n",
       "17                 ligten van copien Extracten of  \n",
       "18                  ook eenige ingelyd groente of  \n",
       "19                         die bij mij gedrukt en  \n",
       "20                   quadt studeren is voor waert  \n",
       "21                     vernomen nog hoe de suyker  \n",
       "22   houde my daarontrent Verder gerécommandeert,  \n",
       "23                   & voor d’Heer J.M.Van Vloten  \n",
       "24                 houdt, heeft niet kunnen klaar  \n",
       "25                         te senden, het welk pr  \n",
       "26                  genoteert staat, de reeden is  \n",
       "27            zodaenig zult bevlijtigd hebben dat  \n",
       "28                          ik weet niet hoe veel  \n",
       "29                        hebbe, ik ben alle jare  \n",
       "30                     die onse Zoon Gerrit heeft  \n",
       "31                   wat kastengen wat nuyten wat  \n",
       "\n",
       "[32 rows x 102 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe31bbdae42a4e60ac4192e52f941ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Sla uw resultaten op:'), Text(value='mijn_resultaten.csv'), Button(button_style='w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>After 1700:</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left context</th>\n",
       "      <th>lemma 0</th>\n",
       "      <th>universal_dependency 0</th>\n",
       "      <th>word 0</th>\n",
       "      <th>aantal_paginas</th>\n",
       "      <th>aantal_woorden</th>\n",
       "      <th>adr_beroep</th>\n",
       "      <th>adr_bijzonderheden</th>\n",
       "      <th>adr_geb_decennium</th>\n",
       "      <th>adr_geb_jaar</th>\n",
       "      <th>...</th>\n",
       "      <th>signatuur</th>\n",
       "      <th>status</th>\n",
       "      <th>subcorpus</th>\n",
       "      <th>title</th>\n",
       "      <th>trans_bestand</th>\n",
       "      <th>trans_datum</th>\n",
       "      <th>type_brief</th>\n",
       "      <th>witnessYear_from</th>\n",
       "      <th>witnessYear_to</th>\n",
       "      <th>right context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Schrijfpampier a 6 Sr t</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boek.</td>\n",
       "      <td>2</td>\n",
       "      <td>440</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-322</td>\n",
       "      <td>6</td>\n",
       "      <td>18V, 18Dbc</td>\n",
       "      <td>To J.H. Martens, 11 november 1780</td>\n",
       "      <td>07-01-2009 032-034-TR-def</td>\n",
       "      <td>2009-04-15 00:00:00</td>\n",
       "      <td>business</td>\n",
       "      <td>1780</td>\n",
       "      <td>1780</td>\n",
       "      <td>50 ditto ongsneeden ditto a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>voorne missive, dat UEDs mijn</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken</td>\n",
       "      <td>2</td>\n",
       "      <td>291</td>\n",
       "      <td>secretaris</td>\n",
       "      <td></td>\n",
       "      <td>1750</td>\n",
       "      <td>1751</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-323</td>\n",
       "      <td>6</td>\n",
       "      <td>18D</td>\n",
       "      <td>To Gabriel Lixraaven, 10 januari 1781</td>\n",
       "      <td>08-01-2009 109-110-TR-def</td>\n",
       "      <td>2009-11-21 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1781</td>\n",
       "      <td>1781</td>\n",
       "      <td>bij berntrop laat verkoopen, als</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>verbeeld hebbe, dat wat geleerde</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken</td>\n",
       "      <td>2</td>\n",
       "      <td>291</td>\n",
       "      <td>secretaris</td>\n",
       "      <td></td>\n",
       "      <td>1750</td>\n",
       "      <td>1751</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-323</td>\n",
       "      <td>6</td>\n",
       "      <td>18D</td>\n",
       "      <td>To Gabriel Lixraaven, 10 januari 1781</td>\n",
       "      <td>08-01-2009 109-110-TR-def</td>\n",
       "      <td>2009-11-21 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1781</td>\n",
       "      <td>1781</td>\n",
       "      <td>aan gaat, schouten altoos geprafereert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>beijde, accuratesse goede order der</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boecken,</td>\n",
       "      <td>2</td>\n",
       "      <td>559</td>\n",
       "      <td>reder</td>\n",
       "      <td></td>\n",
       "      <td>1750</td>\n",
       "      <td>1757</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-323</td>\n",
       "      <td>6</td>\n",
       "      <td>18D</td>\n",
       "      <td>To David Wendorp, 16 december 1780</td>\n",
       "      <td>08-01-2009 133-135-TR-def</td>\n",
       "      <td>2009-09-09 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1780</td>\n",
       "      <td>1780</td>\n",
       "      <td>&amp; Voorsigtigheijd, die prijse ik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rollen matten MR &amp; Eenige</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken</td>\n",
       "      <td>3</td>\n",
       "      <td>844</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1730</td>\n",
       "      <td>1736</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-323</td>\n",
       "      <td>6</td>\n",
       "      <td>18D</td>\n",
       "      <td>To Magdalena Wendorp-Bagge, 16 december 1780</td>\n",
       "      <td>08-01-2009 149-151-TR-def</td>\n",
       "      <td>2009-06-10 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1780</td>\n",
       "      <td>1780</td>\n",
       "      <td>Maar also die twee Scheepen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>te Senden, &amp; wat de</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken</td>\n",
       "      <td>3</td>\n",
       "      <td>844</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1730</td>\n",
       "      <td>1736</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-323</td>\n",
       "      <td>6</td>\n",
       "      <td>18D</td>\n",
       "      <td>To Magdalena Wendorp-Bagge, 16 december 1780</td>\n",
       "      <td>08-01-2009 149-151-TR-def</td>\n",
       "      <td>2009-06-10 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1780</td>\n",
       "      <td>1780</td>\n",
       "      <td>aan betreft Zo Gelieft maar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>laaten wagten tot ik mijn</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken</td>\n",
       "      <td>2</td>\n",
       "      <td>630</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-319</td>\n",
       "      <td>6</td>\n",
       "      <td>18S, 18A, 18Da</td>\n",
       "      <td>To Christiaan Frederik Coller, december 1780</td>\n",
       "      <td>1108-1110-TR-def</td>\n",
       "      <td>2009-01-22 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1780</td>\n",
       "      <td>1780</td>\n",
       "      <td>heeft, want weet anders niet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&amp; houw nu alle de</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken</td>\n",
       "      <td>2</td>\n",
       "      <td>630</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-319</td>\n",
       "      <td>6</td>\n",
       "      <td>18S, 18A, 18Da</td>\n",
       "      <td>To Christiaan Frederik Coller, december 1780</td>\n",
       "      <td>1108-1110-TR-def</td>\n",
       "      <td>2009-01-22 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1780</td>\n",
       "      <td>1780</td>\n",
       "      <td>&amp; bonte &amp; die sijn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gantsche regel die in myn</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Boek</td>\n",
       "      <td>3</td>\n",
       "      <td>1448</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-368</td>\n",
       "      <td>6</td>\n",
       "      <td>18S, 18Da</td>\n",
       "      <td>To Christina Bakker-Smits, 26 september 1780</td>\n",
       "      <td>1156-1159-TR-def</td>\n",
       "      <td>2008-09-11 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1780</td>\n",
       "      <td>1780</td>\n",
       "      <td>niet te vinden is, en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>van concept en wilde syn</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken</td>\n",
       "      <td>2</td>\n",
       "      <td>669</td>\n",
       "      <td>koopman</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-353</td>\n",
       "      <td>6</td>\n",
       "      <td>18Dbc</td>\n",
       "      <td>To Johan Godfried Meeler, 5 januari 1781</td>\n",
       "      <td>17-06-2009 324-326-TR-def</td>\n",
       "      <td>2009-10-22 00:00:00</td>\n",
       "      <td>business</td>\n",
       "      <td>1781</td>\n",
       "      <td>1781</td>\n",
       "      <td>absolut ter secretarij versorgen Eyndelyk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>’t Eijschen, van onvertueren van</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken</td>\n",
       "      <td>2</td>\n",
       "      <td>669</td>\n",
       "      <td>koopman</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-353</td>\n",
       "      <td>6</td>\n",
       "      <td>18Dbc</td>\n",
       "      <td>To Johan Godfried Meeler, 5 januari 1781</td>\n",
       "      <td>17-06-2009 324-326-TR-def</td>\n",
       "      <td>2009-10-22 00:00:00</td>\n",
       "      <td>business</td>\n",
       "      <td>1781</td>\n",
       "      <td>1781</td>\n",
       "      <td>ligten van copien Extracten of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>post ryders of eenige andere</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken,</td>\n",
       "      <td>4</td>\n",
       "      <td>677</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-348</td>\n",
       "      <td>6</td>\n",
       "      <td>18Da</td>\n",
       "      <td>To Margaretha Berewout-Huurdeman, 30 januari 1781</td>\n",
       "      <td>17-06-2009 428-432-TR-def2</td>\n",
       "      <td>2009-10-22 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1781</td>\n",
       "      <td>1781</td>\n",
       "      <td>ook eenige ingelyd groente of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>niets van myne agter gelatene</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken</td>\n",
       "      <td>3</td>\n",
       "      <td>868</td>\n",
       "      <td>koopman</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-339</td>\n",
       "      <td>6</td>\n",
       "      <td>18S, 18Da</td>\n",
       "      <td>To Jacob Neuhoff, 1 februari 1781</td>\n",
       "      <td>4-1-2008 185-188-TR-def</td>\n",
       "      <td>2008-07-08 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1781</td>\n",
       "      <td>1781</td>\n",
       "      <td>vernomen nog hoe de suyker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Bedanke UEd voor de toegezondene</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Boeken,</td>\n",
       "      <td>4</td>\n",
       "      <td>319</td>\n",
       "      <td>boekverkoper</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-341</td>\n",
       "      <td>6</td>\n",
       "      <td>18Da</td>\n",
       "      <td>To J.M. van Vloten, 26 september 1780</td>\n",
       "      <td>5-1-2008 115-119-TR-def</td>\n",
       "      <td>2008-04-24 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1780</td>\n",
       "      <td>1780</td>\n",
       "      <td>houde my daarontrent Verder gerécommandeert,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>26 september 1780 Nota Van</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Boeken</td>\n",
       "      <td>4</td>\n",
       "      <td>319</td>\n",
       "      <td>boekverkoper</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-341</td>\n",
       "      <td>6</td>\n",
       "      <td>18Da</td>\n",
       "      <td>To J.M. van Vloten, 26 september 1780</td>\n",
       "      <td>5-1-2008 115-119-TR-def</td>\n",
       "      <td>2008-04-24 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1780</td>\n",
       "      <td>1780</td>\n",
       "      <td>&amp; voor d’Heer J.M.Van Vloten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Hr van Tiel die uE</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken</td>\n",
       "      <td>3</td>\n",
       "      <td>1545</td>\n",
       "      <td>eigenaar plantage</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-341</td>\n",
       "      <td>6</td>\n",
       "      <td>18Da</td>\n",
       "      <td>To Jan Jacob de Wind, 21 januari 1781</td>\n",
       "      <td>5-1-2008 212-215-TR-def</td>\n",
       "      <td>2009-02-18 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1781</td>\n",
       "      <td>1781</td>\n",
       "      <td>houdt, heeft niet kunnen klaar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>om uE Copij van die</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken</td>\n",
       "      <td>3</td>\n",
       "      <td>1545</td>\n",
       "      <td>eigenaar plantage</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-341</td>\n",
       "      <td>6</td>\n",
       "      <td>18Da</td>\n",
       "      <td>To Jan Jacob de Wind, 21 januari 1781</td>\n",
       "      <td>5-1-2008 212-215-TR-def</td>\n",
       "      <td>2009-02-18 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1781</td>\n",
       "      <td>1781</td>\n",
       "      <td>te senden, het welk pr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>de Datums als in Zyn</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boek</td>\n",
       "      <td>3</td>\n",
       "      <td>1545</td>\n",
       "      <td>eigenaar plantage</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-341</td>\n",
       "      <td>6</td>\n",
       "      <td>18Da</td>\n",
       "      <td>To Jan Jacob de Wind, 21 januari 1781</td>\n",
       "      <td>5-1-2008 212-215-TR-def</td>\n",
       "      <td>2009-02-18 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1781</td>\n",
       "      <td>1781</td>\n",
       "      <td>genoteert staat, de reeden is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>leezen van diverse, voornaemlijk Historische,</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Boeken</td>\n",
       "      <td>2</td>\n",
       "      <td>359</td>\n",
       "      <td>stuurman</td>\n",
       "      <td></td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-750</td>\n",
       "      <td>6</td>\n",
       "      <td>18D</td>\n",
       "      <td>To Jan Lukas Doeve, 15 januari 1781</td>\n",
       "      <td>650-652-TR-def</td>\n",
       "      <td>unknown</td>\n",
       "      <td>private</td>\n",
       "      <td>1781</td>\n",
       "      <td>1781</td>\n",
       "      <td>zodaenig zult bevlijtigd hebben dat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>heeft UE schryf om een</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boek</td>\n",
       "      <td>4</td>\n",
       "      <td>518</td>\n",
       "      <td>assistent</td>\n",
       "      <td></td>\n",
       "      <td>1750</td>\n",
       "      <td>1750</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-317</td>\n",
       "      <td>6</td>\n",
       "      <td>18A, 18Da</td>\n",
       "      <td>To Abraham Entink, 28 oktober 1780</td>\n",
       "      <td>722-726-TR-def</td>\n",
       "      <td>2007-10-21 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1780</td>\n",
       "      <td>1780</td>\n",
       "      <td>ik weet niet hoe veel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>die moet nu ook gedurig</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken</td>\n",
       "      <td>4</td>\n",
       "      <td>518</td>\n",
       "      <td>assistent</td>\n",
       "      <td></td>\n",
       "      <td>1750</td>\n",
       "      <td>1750</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-317</td>\n",
       "      <td>6</td>\n",
       "      <td>18A, 18Da</td>\n",
       "      <td>To Abraham Entink, 28 oktober 1780</td>\n",
       "      <td>722-726-TR-def</td>\n",
       "      <td>2007-10-21 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1780</td>\n",
       "      <td>1780</td>\n",
       "      <td>hebbe, ik ben alle jare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ik het wissiltie wegens die</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>boeken</td>\n",
       "      <td>1</td>\n",
       "      <td>229</td>\n",
       "      <td>kapitein</td>\n",
       "      <td></td>\n",
       "      <td>1710</td>\n",
       "      <td>1718</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-336</td>\n",
       "      <td>6</td>\n",
       "      <td>18A, 18Da</td>\n",
       "      <td>To Gerrit Harmeijer, 7 oktober 1780</td>\n",
       "      <td>KB 336-018-TR-def</td>\n",
       "      <td>2008-11-21 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1780</td>\n",
       "      <td>1780</td>\n",
       "      <td>die onse Zoon Gerrit heeft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ik myn liede man wat</td>\n",
       "      <td>boek</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>bokken</td>\n",
       "      <td>1</td>\n",
       "      <td>176</td>\n",
       "      <td>derde waak</td>\n",
       "      <td></td>\n",
       "      <td>1740</td>\n",
       "      <td>1748</td>\n",
       "      <td>...</td>\n",
       "      <td>HCA 30-750</td>\n",
       "      <td>6</td>\n",
       "      <td>18Da</td>\n",
       "      <td>To Christiaan de Cerff, december 1779</td>\n",
       "      <td>KB c14-1-c14-2-TR-def</td>\n",
       "      <td>2010-12-06 00:00:00</td>\n",
       "      <td>private</td>\n",
       "      <td>1779</td>\n",
       "      <td>1779</td>\n",
       "      <td>wat kastengen wat nuyten wat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      left context lemma 0  \\\n",
       "3                         Schrijfpampier a 6 Sr t     boek   \n",
       "4                   voorne missive, dat UEDs mijn     boek   \n",
       "5                verbeeld hebbe, dat wat geleerde     boek   \n",
       "6             beijde, accuratesse goede order der     boek   \n",
       "7                       rollen matten MR & Eenige     boek   \n",
       "8                             te Senden, & wat de     boek   \n",
       "9                       laaten wagten tot ik mijn     boek   \n",
       "10                              & houw nu alle de     boek   \n",
       "11                      gantsche regel die in myn     boek   \n",
       "16                       van concept en wilde syn     boek   \n",
       "17               ’t Eijschen, van onvertueren van     boek   \n",
       "18                   post ryders of eenige andere     boek   \n",
       "21                  niets van myne agter gelatene     boek   \n",
       "22               Bedanke UEd voor de toegezondene     boek   \n",
       "23                     26 september 1780 Nota Van     boek   \n",
       "24                             Hr van Tiel die uE     boek   \n",
       "25                            om uE Copij van die     boek   \n",
       "26                           de Datums als in Zyn     boek   \n",
       "27  leezen van diverse, voornaemlijk Historische,     boek   \n",
       "28                         heeft UE schryf om een     boek   \n",
       "29                        die moet nu ook gedurig     boek   \n",
       "30                    ik het wissiltie wegens die     boek   \n",
       "31                           ik myn liede man wat     boek   \n",
       "\n",
       "   universal_dependency 0    word 0 aantal_paginas aantal_woorden  \\\n",
       "3                    NOUN     boek.              2            440   \n",
       "4                    NOUN    boeken              2            291   \n",
       "5                    NOUN    boeken              2            291   \n",
       "6                    NOUN  boecken,              2            559   \n",
       "7                    NOUN    boeken              3            844   \n",
       "8                    NOUN    boeken              3            844   \n",
       "9                    NOUN    boeken              2            630   \n",
       "10                   NOUN    boeken              2            630   \n",
       "11                   NOUN      Boek              3           1448   \n",
       "16                   NOUN    boeken              2            669   \n",
       "17                   NOUN    boeken              2            669   \n",
       "18                   NOUN   boeken,              4            677   \n",
       "21                   NOUN    boeken              3            868   \n",
       "22                   NOUN   Boeken,              4            319   \n",
       "23                   NOUN    Boeken              4            319   \n",
       "24                   NOUN    boeken              3           1545   \n",
       "25                   NOUN    boeken              3           1545   \n",
       "26                   NOUN      boek              3           1545   \n",
       "27                   NOUN    Boeken              2            359   \n",
       "28                   NOUN      boek              4            518   \n",
       "29                   NOUN    boeken              4            518   \n",
       "30                   NOUN    boeken              1            229   \n",
       "31                   NOUN    bokken              1            176   \n",
       "\n",
       "           adr_beroep adr_bijzonderheden adr_geb_decennium adr_geb_jaar  \\\n",
       "3                                                  unknown      unknown   \n",
       "4          secretaris                                 1750         1751   \n",
       "5          secretaris                                 1750         1751   \n",
       "6               reder                                 1750         1757   \n",
       "7                                                     1730         1736   \n",
       "8                                                     1730         1736   \n",
       "9                                                  unknown      unknown   \n",
       "10                                                 unknown      unknown   \n",
       "11                                                 unknown      unknown   \n",
       "16            koopman                              unknown      unknown   \n",
       "17            koopman                              unknown      unknown   \n",
       "18                                                 unknown      unknown   \n",
       "21            koopman                              unknown      unknown   \n",
       "22       boekverkoper                              unknown      unknown   \n",
       "23       boekverkoper                              unknown      unknown   \n",
       "24  eigenaar plantage                              unknown      unknown   \n",
       "25  eigenaar plantage                              unknown      unknown   \n",
       "26  eigenaar plantage                              unknown      unknown   \n",
       "27           stuurman                              unknown      unknown   \n",
       "28          assistent                                 1750         1750   \n",
       "29          assistent                                 1750         1750   \n",
       "30           kapitein                                 1710         1718   \n",
       "31         derde waak                                 1740         1748   \n",
       "\n",
       "                        ...                         signatuur status  \\\n",
       "3                       ...                        HCA 30-322      6   \n",
       "4                       ...                        HCA 30-323      6   \n",
       "5                       ...                        HCA 30-323      6   \n",
       "6                       ...                        HCA 30-323      6   \n",
       "7                       ...                        HCA 30-323      6   \n",
       "8                       ...                        HCA 30-323      6   \n",
       "9                       ...                        HCA 30-319      6   \n",
       "10                      ...                        HCA 30-319      6   \n",
       "11                      ...                        HCA 30-368      6   \n",
       "16                      ...                        HCA 30-353      6   \n",
       "17                      ...                        HCA 30-353      6   \n",
       "18                      ...                        HCA 30-348      6   \n",
       "21                      ...                        HCA 30-339      6   \n",
       "22                      ...                        HCA 30-341      6   \n",
       "23                      ...                        HCA 30-341      6   \n",
       "24                      ...                        HCA 30-341      6   \n",
       "25                      ...                        HCA 30-341      6   \n",
       "26                      ...                        HCA 30-341      6   \n",
       "27                      ...                        HCA 30-750      6   \n",
       "28                      ...                        HCA 30-317      6   \n",
       "29                      ...                        HCA 30-317      6   \n",
       "30                      ...                        HCA 30-336      6   \n",
       "31                      ...                        HCA 30-750      6   \n",
       "\n",
       "         subcorpus                                              title  \\\n",
       "3       18V, 18Dbc                  To J.H. Martens, 11 november 1780   \n",
       "4              18D              To Gabriel Lixraaven, 10 januari 1781   \n",
       "5              18D              To Gabriel Lixraaven, 10 januari 1781   \n",
       "6              18D                 To David Wendorp, 16 december 1780   \n",
       "7              18D       To Magdalena Wendorp-Bagge, 16 december 1780   \n",
       "8              18D       To Magdalena Wendorp-Bagge, 16 december 1780   \n",
       "9   18S, 18A, 18Da       To Christiaan Frederik Coller, december 1780   \n",
       "10  18S, 18A, 18Da       To Christiaan Frederik Coller, december 1780   \n",
       "11       18S, 18Da       To Christina Bakker-Smits, 26 september 1780   \n",
       "16           18Dbc           To Johan Godfried Meeler, 5 januari 1781   \n",
       "17           18Dbc           To Johan Godfried Meeler, 5 januari 1781   \n",
       "18            18Da  To Margaretha Berewout-Huurdeman, 30 januari 1781   \n",
       "21       18S, 18Da                  To Jacob Neuhoff, 1 februari 1781   \n",
       "22            18Da              To J.M. van Vloten, 26 september 1780   \n",
       "23            18Da              To J.M. van Vloten, 26 september 1780   \n",
       "24            18Da              To Jan Jacob de Wind, 21 januari 1781   \n",
       "25            18Da              To Jan Jacob de Wind, 21 januari 1781   \n",
       "26            18Da              To Jan Jacob de Wind, 21 januari 1781   \n",
       "27             18D                To Jan Lukas Doeve, 15 januari 1781   \n",
       "28       18A, 18Da                 To Abraham Entink, 28 oktober 1780   \n",
       "29       18A, 18Da                 To Abraham Entink, 28 oktober 1780   \n",
       "30       18A, 18Da                To Gerrit Harmeijer, 7 oktober 1780   \n",
       "31            18Da              To Christiaan de Cerff, december 1779   \n",
       "\n",
       "                 trans_bestand          trans_datum type_brief  \\\n",
       "3    07-01-2009 032-034-TR-def  2009-04-15 00:00:00   business   \n",
       "4    08-01-2009 109-110-TR-def  2009-11-21 00:00:00    private   \n",
       "5    08-01-2009 109-110-TR-def  2009-11-21 00:00:00    private   \n",
       "6    08-01-2009 133-135-TR-def  2009-09-09 00:00:00    private   \n",
       "7    08-01-2009 149-151-TR-def  2009-06-10 00:00:00    private   \n",
       "8    08-01-2009 149-151-TR-def  2009-06-10 00:00:00    private   \n",
       "9             1108-1110-TR-def  2009-01-22 00:00:00    private   \n",
       "10            1108-1110-TR-def  2009-01-22 00:00:00    private   \n",
       "11            1156-1159-TR-def  2008-09-11 00:00:00    private   \n",
       "16   17-06-2009 324-326-TR-def  2009-10-22 00:00:00   business   \n",
       "17   17-06-2009 324-326-TR-def  2009-10-22 00:00:00   business   \n",
       "18  17-06-2009 428-432-TR-def2  2009-10-22 00:00:00    private   \n",
       "21     4-1-2008 185-188-TR-def  2008-07-08 00:00:00    private   \n",
       "22     5-1-2008 115-119-TR-def  2008-04-24 00:00:00    private   \n",
       "23     5-1-2008 115-119-TR-def  2008-04-24 00:00:00    private   \n",
       "24     5-1-2008 212-215-TR-def  2009-02-18 00:00:00    private   \n",
       "25     5-1-2008 212-215-TR-def  2009-02-18 00:00:00    private   \n",
       "26     5-1-2008 212-215-TR-def  2009-02-18 00:00:00    private   \n",
       "27              650-652-TR-def              unknown    private   \n",
       "28              722-726-TR-def  2007-10-21 00:00:00    private   \n",
       "29              722-726-TR-def  2007-10-21 00:00:00    private   \n",
       "30           KB 336-018-TR-def  2008-11-21 00:00:00    private   \n",
       "31       KB c14-1-c14-2-TR-def  2010-12-06 00:00:00    private   \n",
       "\n",
       "   witnessYear_from witnessYear_to  \\\n",
       "3              1780           1780   \n",
       "4              1781           1781   \n",
       "5              1781           1781   \n",
       "6              1780           1780   \n",
       "7              1780           1780   \n",
       "8              1780           1780   \n",
       "9              1780           1780   \n",
       "10             1780           1780   \n",
       "11             1780           1780   \n",
       "16             1781           1781   \n",
       "17             1781           1781   \n",
       "18             1781           1781   \n",
       "21             1781           1781   \n",
       "22             1780           1780   \n",
       "23             1780           1780   \n",
       "24             1781           1781   \n",
       "25             1781           1781   \n",
       "26             1781           1781   \n",
       "27             1781           1781   \n",
       "28             1780           1780   \n",
       "29             1780           1780   \n",
       "30             1780           1780   \n",
       "31             1779           1779   \n",
       "\n",
       "                                    right context  \n",
       "3                     50 ditto ongsneeden ditto a  \n",
       "4                bij berntrop laat verkoopen, als  \n",
       "5          aan gaat, schouten altoos geprafereert  \n",
       "6                & Voorsigtigheijd, die prijse ik  \n",
       "7                     Maar also die twee Scheepen  \n",
       "8                     aan betreft Zo Gelieft maar  \n",
       "9                    heeft, want weet anders niet  \n",
       "10                             & bonte & die sijn  \n",
       "11                          niet te vinden is, en  \n",
       "16      absolut ter secretarij versorgen Eyndelyk  \n",
       "17                 ligten van copien Extracten of  \n",
       "18                  ook eenige ingelyd groente of  \n",
       "21                     vernomen nog hoe de suyker  \n",
       "22   houde my daarontrent Verder gerécommandeert,  \n",
       "23                   & voor d’Heer J.M.Van Vloten  \n",
       "24                 houdt, heeft niet kunnen klaar  \n",
       "25                         te senden, het welk pr  \n",
       "26                  genoteert staat, de reeden is  \n",
       "27            zodaenig zult bevlijtigd hebben dat  \n",
       "28                          ik weet niet hoe veel  \n",
       "29                        hebbe, ik ben alle jare  \n",
       "30                     die onse Zoon Gerrit heeft  \n",
       "31                   wat kastengen wat nuyten wat  \n",
       "\n",
       "[23 rows x 102 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e0d060e1fc45a182e9fa553b6a03ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Sla uw resultaten op:'), Text(value='mijn_resultaten.csv'), Button(button_style='w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus_name=\"zeebrieven\"\n",
    "query=r'[lemma=\"boek\"]'\n",
    "# Request all metadata fields from corpus\n",
    "fields = get_available_metadata(\"corpus\", corpus_name)\n",
    "# Perform query and ask all metadata\n",
    "df_corpus = search_corpus(query, corpus_name, extra_fields_doc=fields[\"document\"])\n",
    "\n",
    "# All results\n",
    "display_df(df_corpus, title=\"All results:\")\n",
    "# Filter on year: > 1700\n",
    "df_filter_year = df_corpus[df_corpus[\"witnessYear_from\"].astype('int32') > 1700] # TODO: include this in filter_df method?\n",
    "display_df(df_filter_year, title=\"After 1700:\")\n",
    "\n",
    "# Filter on sender birth place Leiden\n",
    "df_filter_place = df_corpus[df_corpus[\"witnessYear_from\"].astype('int32') > 1700] # TODO: include this in filter_df method?\n",
    "display_df(df_filter_place, title=\"Sender born in Leiden:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs_env",
   "language": "python",
   "name": "cs_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
