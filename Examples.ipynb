{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples Chaining search\n",
    "This notebook contains a number of examples of chaining linguistic resources: corpora, lexica and treebanks. Try the examples, or copy the code and customize the examples in the [Sandbox](Sandbox.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of examples\n",
    "### Corpora\n",
    " * [Corpus search](#corpus-search)\n",
    " * [Frequency of *zeker*+verb and *vast*+verb compared](#freq-puur-zuiver)\n",
    " * [Train a POS tagger on an annotated corpus](#pos-tagger)\n",
    " * [Search in corpus and filter on metadata](#corpus-filter-metadata)\n",
    " * [Visualizing h-dropping](#visualizing-h-dropping)\n",
    " * [Generate lexicon from several corpora](#lexicon-several-corpora)\n",
    "\n",
    "### Lexica\n",
    " * [Lexicon search](#lexicon-search)\n",
    "\n",
    "### Corpus + lexicon\n",
    " * [Retrieve synonyms from DiaMaNT, look up in Gysseling](#synonyms-diamant-gysseling)\n",
    " * [Build a frequency list of the lemma of some corpus output](#freq-lemma-corpus)\n",
    " * [Find occurences of attributive adjectives not ending with -e, even though they are preceeded by a definite article](#adjective-e)\n",
    " * [Look up inflected forms and spelling variants for a given word form in a corpus](#inflected-spelling-corpus)\n",
    " * [Corpus frequency list of word forms from lexicon with given lemma](#corpus-frequency-lemma-pos)\n",
    " * [Build a frequency table of some corpus, based on word forms list of a given lexicon](#freqtable-lemmalist)\n",
    " * [Search corpus for wordforms of lemma not included in lexicon](#corpus-wordforms-not-lexicon)\n",
    " \n",
    "### Treebanks\n",
    " * [Treebank search](#treebank-search)\n",
    " * [Which objects of verb *geven* occur?](#treebank-objects-geven)\n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T10:51:07.839335Z",
     "start_time": "2019-03-04T10:51:07.835114Z"
    }
   },
   "source": [
    "## Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus search <a class=\"anchor\" id=\"corpus-search\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the cell below to show the UI, and fill in your search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T16:33:19.828905Z",
     "start_time": "2019-03-06T16:33:19.555862Z"
    }
   },
   "outputs": [],
   "source": [
    "from chaininglib.ui.search import create_corpus_ui\n",
    "\n",
    "# Create corpus UI, creates references to field contents\n",
    "corpusQueryField, corpusField = create_corpus_ui()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Click the cell below and press Run to perform the given query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T16:33:20.302632Z",
     "start_time": "2019-03-06T16:33:19.830380Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from chaininglib.search.CorpusQuery import *\n",
    "from chaininglib.ui.dfui import display_df\n",
    "\n",
    "#from chaininglib import search\n",
    "query= corpusQueryField.value\n",
    "corpus_name = corpusField.value\n",
    "df_corpus = create_corpus(corpus_name).pattern(query).search().kwic()\n",
    "#df_corpus = load_dataframe('mijn_resultaten.csv')\n",
    "display_df(df_corpus, labels=\"Results\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of *zeker*+verb and *vast*+verb compared <a class=\"anchor\" id=\"freq-puur-zuiver\"></a>\n",
    "* Below cell searches for *zeker*+verb and for *vast*+verb in the Letters as Loot (zeebrieven) corpus\n",
    "* Compare frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T16:33:20.909030Z",
     "start_time": "2019-03-06T16:33:20.304048Z"
    }
   },
   "outputs": [],
   "source": [
    "#from chaininglib import search\n",
    "from IPython.core.display import display, HTML\n",
    "from chaininglib.search.CorpusQuery import *\n",
    "from chaininglib.ui.dfui import display_df\n",
    "from chaininglib.utils.dfops import column_difference\n",
    "\n",
    "corpus_name = \"zeebrieven\"\n",
    "\n",
    "# Word 1: puur\n",
    "word1= \"zeker\"\n",
    "cq1 = create_corpus(corpus_name).pattern(r'[lemma=\"' + word1 + r'\"][pos=\"VRB.*\"]')\n",
    "df_corpus1 = cq1.search().kwic()\n",
    "display_df(df_corpus1, word1)\n",
    "\n",
    "# Word 2: zuiver\n",
    "word2 = \"vast\"\n",
    "cq2 = create_corpus(corpus_name).pattern(r'[lemma=\"' + word2 + r'\"][pos=\"VRB.*\"]')\n",
    "df_corpus2 = cq2.search().kwic()\n",
    "display_df(df_corpus2, word2)\n",
    "\n",
    "# Compute difference\n",
    "diff_left, diff_right, intersec = column_difference(df_corpus1[\"word 1\"], df_corpus2[\"word 1\"])\n",
    "# Elements of 1 that are not in 2\n",
    "display(HTML('Werkwoorden voor <b>' + word1 + '</b> niet in <b>' + word2 + '</b>: ' + \", \".join(diff_left)))\n",
    "# Elements of 2 that are not in 1\n",
    "display(HTML('Werkwoorden voor <b>' + word2 + '</b> niet in <b>' + word1 + '</b>: ' + \", \".join(diff_right)))\n",
    "# Elements both in 1 and 2\n",
    "display(HTML('Werkwoorden zowel voor <b>' + word1 + '</b> als voor <b>' + word2 + '</b>: ' + \", \".join(intersec)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a POS tagger on an annotated corpus <a class=\"anchor\" id=\"pos-tagger\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T16:33:21.728366Z",
     "start_time": "2019-03-06T16:33:20.911111Z"
    }
   },
   "outputs": [],
   "source": [
    "from chaininglib.ui.dfui import display_df\n",
    "from chaininglib.process.corpus import get_tagger\n",
    "from chaininglib.search.CorpusQuery import *\n",
    "from chaininglib.search.LexiconQuery import *\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# TODO: replace by historical lexicon\n",
    "base_lexicon=\"molex\"\n",
    "\n",
    "# we have a given word\n",
    "some_word = \"lopen\"\n",
    "\n",
    "# get the paradigm of the lemma our word is a part of\n",
    "l = create_lexicon(base_lexicon).lemma(some_word).search()\n",
    "df_paradigm = l.kwic()\n",
    "display_df(df_paradigm)\n",
    "\n",
    "# gather some pattern including our word, out of annotated corpora\n",
    "# here: DET + ADJ + 'loop'\n",
    "\n",
    "dfs_all_corpora = []\n",
    "\n",
    "for one_corpus in get_available_corpora():\n",
    "    print('querying '+one_corpus+'...')\n",
    "    c = create_corpus(one_corpus).word(some_word).detailed_context(True).search()\n",
    "    df_corpus = c.kwic() \n",
    "    \n",
    "    # store the results\n",
    "    dfs_all_corpora.append(df_corpus)\n",
    "\n",
    "\n",
    "# get a tagger trained with our corpus data\n",
    "tagger = get_tagger(dfs_all_corpora, pos_key = 'pos') \n",
    "\n",
    "# Use the trained tagger to tag unknown sentences\n",
    "# The input must be like: tagger.tag(['today','is','a','beautiful','day'])\n",
    "\n",
    "sentence = 'Zij lopen graag in het bos als het mooi weer is'\n",
    "tagged_sentence = tagger.tag( sentence.split() )\n",
    "\n",
    "print(tagged_sentence)\n",
    "\n",
    "\n",
    "# Know we can lemmatize each occurence of our lemma in the new sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search in corpus and filter on metadata <a class=\"anchor\" id=\"corpus-filter-metadata\"></a>\n",
    "First, we request all available metadata fields of the corpus. Then, we issue a search query, and request all metadata fields for the result. Finally, we filter on metadata values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T16:33:21.734400Z",
     "start_time": "2019-03-06T16:33:19.568Z"
    }
   },
   "outputs": [],
   "source": [
    "from chaininglib.search.metadata import get_available_metadata\n",
    "from chaininglib.utils.dfops import df_filter, property_freq\n",
    "from chaininglib.ui.dfui import display_df\n",
    "from chaininglib.search.CorpusQuery import *\n",
    "\n",
    "\n",
    "corpus_name=\"zeebrieven\"\n",
    "query=r'[lemma=\"boek\"]'\n",
    "# Request all metadata fields from corpus\n",
    "fields = get_available_metadata(corpus_name)\n",
    "# Perform query and ask all metadata\n",
    "c = create_corpus(corpus_name).pattern(query).extra_fields_doc(fields[\"document\"]).search()\n",
    "df_corpus = c.kwic()\n",
    "\n",
    "# Filter on year: > 1700\n",
    "df_filter_year = df_corpus[df_corpus[\"witnessYear_from\"].astype('int32') > 1700] \n",
    "display_df(df_filter_year, labels=\"After 1700\")\n",
    "\n",
    "# Filter on sender birth place Amsterdam\n",
    "condition = df_filter(df_corpus[\"afz_geb_plaats\"], pattern=\"Amsterdam\")\n",
    "df_filter_place = df_corpus[ condition ]\n",
    "display_df(df_filter_place, labels=\"Sender born in Amsterdam\")\n",
    "\n",
    "\n",
    "# Group by birth place\n",
    "df = property_freq(df_corpus,\"afz_loc_plaats\")\n",
    "display_df(df, labels=\"Most frequent sender locations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing h-dropping  <a class=\"anchor\" id=\"visualizing-h-dropping\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T16:33:21.735977Z",
     "start_time": "2019-03-06T16:33:19.573Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from chaininglib.search.CorpusQuery import *\n",
    "from chaininglib.search.metadata import get_available_metadata\n",
    "from chaininglib.ui.dfui import display_df\n",
    " \n",
    "corpus_to_search=\"zeebrieven\"\n",
    "group_by_column = 'afz_geb_plaats'\n",
    " \n",
    "fields = get_available_metadata(corpus_to_search)\n",
    " \n",
    "df_corpus1 = create_corpus(corpus_to_search).pattern(r'[lemma=\"h[aeo].*\" & word=\"[aeo].*\"]').extra_fields_doc(fields[\"document\"]).search().kwic()\n",
    "df_corpus2 = create_corpus(corpus_to_search).pattern(r'[lemma=\"h[aeo].*\" & word=\"h[aeo].*\"]').extra_fields_doc(fields[\"document\"]).search().kwic()\n",
    " \n",
    "#display_df( df_corpus1)\n",
    "#display_df( df_corpus2)\n",
    " \n",
    "display_df( df_corpus1[['lemma 0', group_by_column]].groupby(group_by_column).count().sort_values(ascending=False,by=['lemma 0']).head(25), labels=\"h-dropping\", mode='chart')\n",
    "display_df( df_corpus2[['lemma 0', group_by_column]].groupby(group_by_column).count().sort_values(ascending=False,by=['lemma 0']).head(25), labels=\"normal\", mode='chart')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate lexicon from several corpora <a class=\"anchor\" id=\"lexicon-several-corpora\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T16:33:21.745722Z",
     "start_time": "2019-03-06T16:33:19.598Z"
    }
   },
   "outputs": [],
   "source": [
    "from chaininglib.ui.dfui import display_df\n",
    "from chaininglib.process.corpus import extract_lexicon\n",
    "from chaininglib.search.CorpusQuery import *\n",
    "\n",
    "dfs_all_corpora = []\n",
    "for one_corpus in get_available_corpora(exclude=[\"nederlab\"]):\n",
    "    print('querying '+one_corpus+'...')\n",
    "    c = create_corpus(one_corpus).pos(\"NOU\").detailed_context(True).search()\n",
    "    df_corpus = c.kwic() \n",
    "    # store the results\n",
    "    dfs_all_corpora.append(df_corpus)\n",
    "\n",
    "    \n",
    "# extract lexicon and show the result\n",
    "extracted_lexicon = extract_lexicon(dfs_all_corpora, posColumnName=\"pos\") # For FCS: posColumnName=universal_dependency\n",
    "display(extracted_lexicon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexicon search <a class=\"anchor\" id=\"lexicon-search\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the cell below to show the UI, and fill in your search query in the UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T16:33:21.737060Z",
     "start_time": "2019-03-06T16:33:19.576Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from chaininglib.ui.search import create_lexicon_ui\n",
    "\n",
    "#from chaininglib import ui\n",
    "searchWordField, lexiconField = create_lexicon_ui()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Click the cell below and press Run to perform the given query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T16:33:21.737959Z",
     "start_time": "2019-03-06T16:33:19.578Z"
    }
   },
   "outputs": [],
   "source": [
    "from chaininglib.search.LexiconQuery import *\n",
    "from chaininglib.ui.dfui import display_df\n",
    "\n",
    "search_word = searchWordField.value\n",
    "lexicon_name = lexiconField.value\n",
    "# USER: can replace this by own custom query\n",
    "lex = create_lexicon(lexicon_name).lemma(search_word).search()\n",
    "df_lexicon = lex.kwic()\n",
    "display_df(df_lexicon)\n",
    "#df_columns_list = list(df_lexicon.columns.values)\n",
    "#df_lexicon_in_columns = df_lexicon[df_columns_list]\n",
    "#display(df_lexicon_in_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus + lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve synonyms from DiaMaNT, look up in Gysseling <a class=\"anchor\" id=\"synonyms-diamant-gysseling\"></a>\n",
    "* Below cell searches for term \"boek\" in DiaMaNT, and looks up all variants in Gysseling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T16:33:21.739111Z",
     "start_time": "2019-03-06T16:33:19.580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[F                                                                    "
     ]
    },
    {
     "data": {
      "text/html": [
       "Synoniemen voor <b>boek</b>: klachtenboek, schotschrift, inscriptie, vragenboekje, Boek, lijst, receptenboek, resolutieboek, algebraboek, schoolboek, acte, werk, schrijfboek, brievenboek, legende, oorkonde, tekst, aansprakelijk, herbarium, gewerk, toesluiten, gildeboek, boek, verponding, weesboek"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[F...Searching gysseling at result 0...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left context</th>\n",
       "      <th>lemma 0</th>\n",
       "      <th>pos 0</th>\n",
       "      <th>word 0</th>\n",
       "      <th>right context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.iiii. ghecorne gulde broeders die de</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=pl,inflection=e)</td>\n",
       "      <td>boeke</td>\n",
       "      <td>oudenden sin. si moghen elc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>viere ghecorne guldebroeders die de</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=pl,inflection=e)</td>\n",
       "      <td>boeke</td>\n",
       "      <td>houden si moghen elc haren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.iiii. ghecorne guldebroeders die de</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=pl,inflection=e)</td>\n",
       "      <td>boke</td>\n",
       "      <td>ouden si moghen elc haren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>secundi willelmus de lapide willelmus</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>boec</td>\n",
       "      <td>Jn elst. arnulphus de keelne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Heren M CC LXXX, due wart det</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>buec</td>\n",
       "      <td>begonnen. Desen csens es mer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>van poschen, due wart det</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>buec</td>\n",
       "      <td>begonnen. Desen pagt es mer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>van poschen, due wart det</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>buec</td>\n",
       "      <td>begonnen. Desen pagt es mer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>van poschen, due wart dit</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>buc</td>\n",
       "      <td>begonnen. Dese pegte es mer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>van poschen, due wart dit</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>buc</td>\n",
       "      <td>begonnen. Dit blift den bruderen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>van poschen, due wart dit</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>buc</td>\n",
       "      <td>begonnen. Dit sin degene die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>van posschen, due wart det</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>buec</td>\n",
       "      <td>begonnen. Desen csens sin we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>van posschen, due wart det</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>buec</td>\n",
       "      <td>begonnen. Desen csens sin we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Heren M CC LXXX, due wart det</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>buec</td>\n",
       "      <td>begonnen. Desen pagt sin de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Heren M CC LXXX, due wart det</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>buec</td>\n",
       "      <td>begonnen. Desen pagt sin de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dese</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>bouc</td>\n",
       "      <td>was ghemaect int iaer ons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ribode anduorden soude vp den</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>boech</td>\n",
       "      <td>.. xxxv s Jtem pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>de leie. Woutre van der</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=e)</td>\n",
       "      <td>bouke.</td>\n",
       "      <td>.xviij. d. Heinric mulkins. huus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>wolfaert met den alse, jan</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>bouc</td>\n",
       "      <td>, jan clais zone ende</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Dit es de</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>bouc</td>\n",
       "      <td>vander renten ende vander heruachtecheden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sente bamesse Woutre van der</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=e)</td>\n",
       "      <td>bouke</td>\n",
       "      <td>.xviij. d. sente bamesse ande</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tienne scellinghe arfelijcs cheins. ten</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=pl,inflection=n)</td>\n",
       "      <td>boecken</td>\n",
       "      <td>behoef sclousters van vorst. teghelde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gheset ten ambachte der voer ghenoemder</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=pl,inflection=e)</td>\n",
       "      <td>boecke</td>\n",
       "      <td>ende alse selc paiment alse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>.i. broet. Lammin van der</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=e)</td>\n",
       "      <td>boeke</td>\n",
       "      <td>.i. broet arnout gardiser over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>e[ne waerf] [was] Dar wa[s] [een]</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>bo[ec]</td>\n",
       "      <td>en[de] [hic] [las] Dat een</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>niemene vand soe gheme[ne] die</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>boec</td>\n",
       "      <td>hi segt ons ouer waer Dat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sijn leuen ewelike amen Dese</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>boec</td>\n",
       "      <td>es nuttelec sere Diene leest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sullen wesen Dar men desen</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>boec</td>\n",
       "      <td>sal lesen Salujt gheluc ende</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sal wesen Dar men desen</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>boec</td>\n",
       "      <td>sal lesen Ende sinen sijn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>wel dran leegt Andat dese</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>boec</td>\n",
       "      <td>hier seeght Ende hijt wille</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>biechten gan Hier ent de</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>boec</td>\n",
       "      <td>van der biechten Hier beghint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>gaue van genaden ouer al alst</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>boec</td>\n",
       "      <td>hier na getughen sal. [10] Wie dat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>beginne dede van den irsten</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=e)</td>\n",
       "      <td>boeke</td>\n",
       "      <td>ghewach daer se een edele</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Nu wil ic dit ander</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>boec</td>\n",
       "      <td>hier jnden daer men mach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>mi eer ic dat derde</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>boec</td>\n",
       "      <td>beginne om te vergederen te</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>[1] Hier begint dat derde</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>boec</td>\n",
       "      <td>van der g᨜eder sinte lutgarden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>na dien dat steet ind</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>boec</td>\n",
       "      <td>der gesteleker minnen Haer ureghd eens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>nv op dees stonde vten</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=e)</td>\n",
       "      <td>boeke</td>\n",
       "      <td>dies leuens dar ghi mi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>spreken af Hier beslute ict</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>boec</td>\n",
       "      <td>themale.. O edele leserse ende</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>Want als man hort en</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>b᨜k</td>\n",
       "      <td>lesen walsg is of d᨜tsg.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>tegenwordig en bin dat dit</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>buk</td>\n",
       "      <td>mi tegenwordig make mit der</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>sal v. togen. ᨐ dit</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>buk</td>\n",
       "      <td>heuet varwe inde worde. inde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>dat ic mi pine d᨜sgedain</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>buk</td>\n",
       "      <td>te scriuene inde te makene.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>seluer ᨝nm᨜tig gemakt mit dᨖsen</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=e)</td>\n",
       "      <td>buke</td>\n",
       "      <td>te digtene inde te scriuene.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>d᨜n dᨖ leringe. dat dᨖt</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>buk</td>\n",
       "      <td>lᨔrt. Jnde seget. hᨖ sal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>beginsel. dar ᨝mbe sal man dit</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>buk</td>\n",
       "      <td>dicke horen. Dar ᨝mbe segt dᨖ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>v. te d᨜ne dat dᨖt</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>buk</td>\n",
       "      <td>seget. beide mit munde inde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Als du lesis in en</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>buk</td>\n",
       "      <td>pinse dat dar gen valgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>coitus hiwelech coeternus eweleke codex</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>buch</td>\n",
       "      <td>coercere bedwingen coherere te samene hangen coequare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>te stornisse exicialis dolec exodus ein</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>boech</td>\n",
       "      <td>exorcizare beswerren exorcismus besweringe exorcista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>ligteleke leuita diaken leuiticus ein</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>buec</td>\n",
       "      <td>leua wenster hant leuus slinc leuca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>offren, smaken Libatio offrande liber</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>buek</td>\n",
       "      <td>libellus bucsken librarjus schriuere liberi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>te makene, ende makdender af grote</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=pl,inflection=e)</td>\n",
       "      <td>bueke</td>\n",
       "      <td>ende grote [ghescreften] die vele</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>ende men brachte hem enen</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>boec</td>\n",
       "      <td>dat was de prophecie Ysaie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>propheten. Doe ontploec Ihesus din</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>boec</td>\n",
       "      <td>ende quam ten irsten male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>hadde, so loec hi den</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=sg,inflection=0)</td>\n",
       "      <td>boec</td>\n",
       "      <td>weder toe ende gavene op</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>want hi screef in sinen</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=pl,inflection=n)</td>\n",
       "      <td>boeken</td>\n",
       "      <td>van mi. Ende ochte ghi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>dat mogdi pruuen ute Moyses</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=pl,inflection=n)</td>\n",
       "      <td>buken</td>\n",
       "      <td>bi din warde dat God</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>gescreuen en sijn [in] desen</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=pl,inflection=e)</td>\n",
       "      <td>boeke,</td>\n",
       "      <td>mar dese sijn gescreuen, om dat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>gescreuen en sijn in desen</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=pl,inflection=e)</td>\n",
       "      <td>boeke;</td>\n",
       "      <td>want soude ment al bescriuen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>ende dat hi leerde, die</td>\n",
       "      <td>BOEK</td>\n",
       "      <td>NOU(type=common,number=pl,inflection=e)</td>\n",
       "      <td>bueke</td>\n",
       "      <td>die men daer af maken soude,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1635 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                left context lemma 0  \\\n",
       "0      .iiii. ghecorne gulde broeders die de    BOEK   \n",
       "1        viere ghecorne guldebroeders die de    BOEK   \n",
       "2       .iiii. ghecorne guldebroeders die de    BOEK   \n",
       "3      secundi willelmus de lapide willelmus    BOEK   \n",
       "4              Heren M CC LXXX, due wart det    BOEK   \n",
       "5                  van poschen, due wart det    BOEK   \n",
       "6                  van poschen, due wart det    BOEK   \n",
       "7                  van poschen, due wart dit    BOEK   \n",
       "8                  van poschen, due wart dit    BOEK   \n",
       "9                  van poschen, due wart dit    BOEK   \n",
       "10                van posschen, due wart det    BOEK   \n",
       "11                van posschen, due wart det    BOEK   \n",
       "12             Heren M CC LXXX, due wart det    BOEK   \n",
       "13             Heren M CC LXXX, due wart det    BOEK   \n",
       "14                                      Dese    BOEK   \n",
       "15             ribode anduorden soude vp den    BOEK   \n",
       "16                   de leie. Woutre van der    BOEK   \n",
       "17                wolfaert met den alse, jan    BOEK   \n",
       "18                                 Dit es de    BOEK   \n",
       "19              sente bamesse Woutre van der    BOEK   \n",
       "20   tienne scellinghe arfelijcs cheins. ten    BOEK   \n",
       "21   gheset ten ambachte der voer ghenoemder    BOEK   \n",
       "22                 .i. broet. Lammin van der    BOEK   \n",
       "23         e[ne waerf] [was] Dar wa[s] [een]    BOEK   \n",
       "24            niemene vand soe gheme[ne] die    BOEK   \n",
       "25              sijn leuen ewelike amen Dese    BOEK   \n",
       "26                sullen wesen Dar men desen    BOEK   \n",
       "27                   sal wesen Dar men desen    BOEK   \n",
       "28                 wel dran leegt Andat dese    BOEK   \n",
       "29                  biechten gan Hier ent de    BOEK   \n",
       "..                                       ...     ...   \n",
       "234            gaue van genaden ouer al alst    BOEK   \n",
       "235              beginne dede van den irsten    BOEK   \n",
       "236                      Nu wil ic dit ander    BOEK   \n",
       "237                      mi eer ic dat derde    BOEK   \n",
       "238                [1] Hier begint dat derde    BOEK   \n",
       "239                    na dien dat steet ind    BOEK   \n",
       "240                   nv op dees stonde vten    BOEK   \n",
       "241              spreken af Hier beslute ict    BOEK   \n",
       "242                     Want als man hort en    BOEK   \n",
       "243               tegenwordig en bin dat dit    BOEK   \n",
       "244                      sal v. togen. ᨐ dit    BOEK   \n",
       "245                 dat ic mi pine d᨜sgedain    BOEK   \n",
       "246          seluer ᨝nm᨜tig gemakt mit dᨖsen    BOEK   \n",
       "247                  d᨜n dᨖ leringe. dat dᨖt    BOEK   \n",
       "248           beginsel. dar ᨝mbe sal man dit    BOEK   \n",
       "249                       v. te d᨜ne dat dᨖt    BOEK   \n",
       "250                       Als du lesis in en    BOEK   \n",
       "251  coitus hiwelech coeternus eweleke codex    BOEK   \n",
       "252  te stornisse exicialis dolec exodus ein    BOEK   \n",
       "253    ligteleke leuita diaken leuiticus ein    BOEK   \n",
       "254    offren, smaken Libatio offrande liber    BOEK   \n",
       "255       te makene, ende makdender af grote    BOEK   \n",
       "256                ende men brachte hem enen    BOEK   \n",
       "257       propheten. Doe ontploec Ihesus din    BOEK   \n",
       "258                    hadde, so loec hi den    BOEK   \n",
       "259                  want hi screef in sinen    BOEK   \n",
       "260              dat mogdi pruuen ute Moyses    BOEK   \n",
       "261             gescreuen en sijn [in] desen    BOEK   \n",
       "262               gescreuen en sijn in desen    BOEK   \n",
       "263                  ende dat hi leerde, die    BOEK   \n",
       "\n",
       "                                       pos 0   word 0  \\\n",
       "0    NOU(type=common,number=pl,inflection=e)    boeke   \n",
       "1    NOU(type=common,number=pl,inflection=e)    boeke   \n",
       "2    NOU(type=common,number=pl,inflection=e)     boke   \n",
       "3    NOU(type=common,number=sg,inflection=0)     boec   \n",
       "4    NOU(type=common,number=sg,inflection=0)     buec   \n",
       "5    NOU(type=common,number=sg,inflection=0)     buec   \n",
       "6    NOU(type=common,number=sg,inflection=0)     buec   \n",
       "7    NOU(type=common,number=sg,inflection=0)      buc   \n",
       "8    NOU(type=common,number=sg,inflection=0)      buc   \n",
       "9    NOU(type=common,number=sg,inflection=0)      buc   \n",
       "10   NOU(type=common,number=sg,inflection=0)     buec   \n",
       "11   NOU(type=common,number=sg,inflection=0)     buec   \n",
       "12   NOU(type=common,number=sg,inflection=0)     buec   \n",
       "13   NOU(type=common,number=sg,inflection=0)     buec   \n",
       "14   NOU(type=common,number=sg,inflection=0)     bouc   \n",
       "15   NOU(type=common,number=sg,inflection=0)    boech   \n",
       "16   NOU(type=common,number=sg,inflection=e)   bouke.   \n",
       "17   NOU(type=common,number=sg,inflection=0)     bouc   \n",
       "18   NOU(type=common,number=sg,inflection=0)     bouc   \n",
       "19   NOU(type=common,number=sg,inflection=e)    bouke   \n",
       "20   NOU(type=common,number=pl,inflection=n)  boecken   \n",
       "21   NOU(type=common,number=pl,inflection=e)   boecke   \n",
       "22   NOU(type=common,number=sg,inflection=e)    boeke   \n",
       "23   NOU(type=common,number=sg,inflection=0)   bo[ec]   \n",
       "24   NOU(type=common,number=sg,inflection=0)     boec   \n",
       "25   NOU(type=common,number=sg,inflection=0)     boec   \n",
       "26   NOU(type=common,number=sg,inflection=0)     boec   \n",
       "27   NOU(type=common,number=sg,inflection=0)     boec   \n",
       "28   NOU(type=common,number=sg,inflection=0)     boec   \n",
       "29   NOU(type=common,number=sg,inflection=0)     boec   \n",
       "..                                       ...      ...   \n",
       "234  NOU(type=common,number=sg,inflection=0)     boec   \n",
       "235  NOU(type=common,number=sg,inflection=e)    boeke   \n",
       "236  NOU(type=common,number=sg,inflection=0)     boec   \n",
       "237  NOU(type=common,number=sg,inflection=0)     boec   \n",
       "238  NOU(type=common,number=sg,inflection=0)     boec   \n",
       "239  NOU(type=common,number=sg,inflection=0)     boec   \n",
       "240  NOU(type=common,number=sg,inflection=e)    boeke   \n",
       "241  NOU(type=common,number=sg,inflection=0)     boec   \n",
       "242  NOU(type=common,number=sg,inflection=0)      b᨜k   \n",
       "243  NOU(type=common,number=sg,inflection=0)      buk   \n",
       "244  NOU(type=common,number=sg,inflection=0)      buk   \n",
       "245  NOU(type=common,number=sg,inflection=0)      buk   \n",
       "246  NOU(type=common,number=sg,inflection=e)     buke   \n",
       "247  NOU(type=common,number=sg,inflection=0)      buk   \n",
       "248  NOU(type=common,number=sg,inflection=0)      buk   \n",
       "249  NOU(type=common,number=sg,inflection=0)      buk   \n",
       "250  NOU(type=common,number=sg,inflection=0)      buk   \n",
       "251  NOU(type=common,number=sg,inflection=0)     buch   \n",
       "252  NOU(type=common,number=sg,inflection=0)    boech   \n",
       "253  NOU(type=common,number=sg,inflection=0)     buec   \n",
       "254  NOU(type=common,number=sg,inflection=0)     buek   \n",
       "255  NOU(type=common,number=pl,inflection=e)    bueke   \n",
       "256  NOU(type=common,number=sg,inflection=0)     boec   \n",
       "257  NOU(type=common,number=sg,inflection=0)     boec   \n",
       "258  NOU(type=common,number=sg,inflection=0)     boec   \n",
       "259  NOU(type=common,number=pl,inflection=n)   boeken   \n",
       "260  NOU(type=common,number=pl,inflection=n)    buken   \n",
       "261  NOU(type=common,number=pl,inflection=e)   boeke,   \n",
       "262  NOU(type=common,number=pl,inflection=e)   boeke;   \n",
       "263  NOU(type=common,number=pl,inflection=e)    bueke   \n",
       "\n",
       "                                             right context  \n",
       "0                              oudenden sin. si moghen elc  \n",
       "1                               houden si moghen elc haren  \n",
       "2                                ouden si moghen elc haren  \n",
       "3                             Jn elst. arnulphus de keelne  \n",
       "4                             begonnen. Desen csens es mer  \n",
       "5                              begonnen. Desen pagt es mer  \n",
       "6                              begonnen. Desen pagt es mer  \n",
       "7                              begonnen. Dese pegte es mer  \n",
       "8                         begonnen. Dit blift den bruderen  \n",
       "9                             begonnen. Dit sin degene die  \n",
       "10                            begonnen. Desen csens sin we  \n",
       "11                            begonnen. Desen csens sin we  \n",
       "12                             begonnen. Desen pagt sin de  \n",
       "13                             begonnen. Desen pagt sin de  \n",
       "14                               was ghemaect int iaer ons  \n",
       "15                                      .. xxxv s Jtem pro  \n",
       "16                        .xviij. d. Heinric mulkins. huus  \n",
       "17                                   , jan clais zone ende  \n",
       "18               vander renten ende vander heruachtecheden  \n",
       "19                           .xviij. d. sente bamesse ande  \n",
       "20                   behoef sclousters van vorst. teghelde  \n",
       "21                             ende alse selc paiment alse  \n",
       "22                          .i. broet arnout gardiser over  \n",
       "23                              en[de] [hic] [las] Dat een  \n",
       "24                               hi segt ons ouer waer Dat  \n",
       "25                            es nuttelec sere Diene leest  \n",
       "26                            sal lesen Salujt gheluc ende  \n",
       "27                               sal lesen Ende sinen sijn  \n",
       "28                             hier seeght Ende hijt wille  \n",
       "29                           van der biechten Hier beghint  \n",
       "..                                                     ...  \n",
       "234                     hier na getughen sal. [10] Wie dat  \n",
       "235                              ghewach daer se een edele  \n",
       "236                               hier jnden daer men mach  \n",
       "237                            beginne om te vergederen te  \n",
       "238                         van der g᨜eder sinte lutgarden  \n",
       "239                 der gesteleker minnen Haer ureghd eens  \n",
       "240                                 dies leuens dar ghi mi  \n",
       "241                         themale.. O edele leserse ende  \n",
       "242                               lesen walsg is of d᨜tsg.  \n",
       "243                            mi tegenwordig make mit der  \n",
       "244                           heuet varwe inde worde. inde  \n",
       "245                            te scriuene inde te makene.  \n",
       "246                           te digtene inde te scriuene.  \n",
       "247                               lᨔrt. Jnde seget. hᨖ sal  \n",
       "248                          dicke horen. Dar ᨝mbe segt dᨖ  \n",
       "249                            seget. beide mit munde inde  \n",
       "250                                pinse dat dar gen valgs  \n",
       "251  coercere bedwingen coherere te samene hangen coequare  \n",
       "252   exorcizare beswerren exorcismus besweringe exorcista  \n",
       "253                    leua wenster hant leuus slinc leuca  \n",
       "254            libellus bucsken librarjus schriuere liberi  \n",
       "255                      ende grote [ghescreften] die vele  \n",
       "256                             dat was de prophecie Ysaie  \n",
       "257                              ende quam ten irsten male  \n",
       "258                               weder toe ende gavene op  \n",
       "259                                 van mi. Ende ochte ghi  \n",
       "260                                   bi din warde dat God  \n",
       "261                        mar dese sijn gescreuen, om dat  \n",
       "262                           want soude ment al bescriuen  \n",
       "263                           die men daer af maken soude,  \n",
       "\n",
       "[1635 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81102e7523146fd92dc1af22f01e888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Sla uw resultaten op:'), Text(value='mijn_resultaten.csv'), Button(button_style='w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from chaininglib.search.CorpusQuery import *\n",
    "from chaininglib.search.LexiconQuery import *\n",
    "from IPython.core.display import display, HTML\n",
    "from chaininglib.search.corpusQueries import corpus_query\n",
    "from chaininglib.process.lexicon import get_diamant_synonyms\n",
    "from chaininglib.ui.dfui import display_df\n",
    "\n",
    "search_word = \"boek\"\n",
    "lexicon_name = \"diamant\"\n",
    "corpus= \"gysseling\"\n",
    "\n",
    "# First, lookup synonyms in DiaMaNT\n",
    "lq = create_lexicon(lexicon_name).lemma(search_word).search()\n",
    "df_lexicon = lq.kwic()\n",
    "\n",
    "syns = get_diamant_synonyms(df_lexicon)\n",
    "syns.add(search_word) # Also add search word itself\n",
    "display(HTML('Synoniemen voor <b>' + search_word + '</b>: ' + \", \".join(syns)))\n",
    "\n",
    "# Search for all synonyms in corpus\n",
    "## Create queries: search by lemma\n",
    "syns_queries = [corpus_query(lemma=syn) for syn in syns]\n",
    "\n",
    "## Search for all synonyms in corpus\n",
    "df = pd.DataFrame()\n",
    "for one_pattern in syns_queries:\n",
    "    cq = create_corpus(corpus).pattern(one_pattern).search()\n",
    "    df = df.append(cq.kwic())\n",
    "display_df(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Build a frequency list of the lemma of some corpus output <a class=\"anchor\" id=\"freq-lemma-corpus\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T16:33:21.740311Z",
     "start_time": "2019-03-06T16:33:19.583Z"
    }
   },
   "outputs": [],
   "source": [
    "from chaininglib.search.CorpusQuery import *\n",
    "from chaininglib.process.corpus import *\n",
    "from chaininglib.ui.dfui import *\n",
    "\n",
    "# do some corpus search\n",
    "\n",
    "corpus_to_search=\"zeebrieven\"\n",
    "df_corpus = create_corpus(corpus_to_search).detailed_context(True).pos(\"NOU.*\").search().kwic()\n",
    "display_df(df_corpus)\n",
    "\n",
    "# compute and display a table of the frequencies of the lemmata\n",
    "\n",
    "freq_df = get_frequency_list(df_corpus)\n",
    "display_df(freq_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-16T15:46:20.519833Z",
     "start_time": "2019-01-16T15:46:20.516208Z"
    }
   },
   "source": [
    "### Find occurences of attributive adjectives not ending with -e, even though they are preceeded by a definite article <a class=\"anchor\" id=\"adjective-e\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T16:33:21.741214Z",
     "start_time": "2019-03-06T16:33:19.585Z"
    }
   },
   "outputs": [],
   "source": [
    "from chaininglib.search.CorpusQuery import *\n",
    "from chaininglib.search.LexiconQuery import *\n",
    "from chaininglib.utils.dfops import df_filter\n",
    "from chaininglib.ui.dfui import display_df\n",
    "\n",
    "# TODO: zeebrieven and molex are not from same time period. But lexiconservice does not support regex\n",
    "corpus_to_search=\"zeebrieven\"\n",
    "lexicon_to_search=\"molex\"\n",
    "\n",
    "# CORPUS: get [article + attributive adjective + nouns] combinations in which the adjective does not end with -e\n",
    "print('Get occurences of attributive adjectives not ending with -e')\n",
    "cq = create_corpus(corpus_to_search).pattern(r'[lemma=\"de|het\"][word=\"^g(.+)[^e]$\" & pos=\"ADJ\"][pos=\"NOUN\"]')\n",
    "df_corpus = cq.search().kwic()\n",
    "display(df_corpus)\n",
    "\n",
    "# LEXICON: get adjectives the lemma of which does not end with -e\n",
    "lq = create_lexicon(lexicon_to_search).lemma('^g(.+)[^e]$').pos('ADJ').search()\n",
    "df_lexicon = lq.search().kwic()\n",
    "\n",
    "# LEXICON: get adjectives having a final -e in definite attributive use\n",
    "print('Filtering lexicon results')\n",
    "final_e_condition = df_filter(df_lexicon[\"wordform\"], 'e$')\n",
    "df_lexicon_form_e = df_lexicon[ final_e_condition ]\n",
    "\n",
    "# RESULT: get the records out of our first list in which the -e-less-adjectives match the lemma form of our last list\n",
    "print('List of attributive adjectives not ending with -e even though they should have a final -e:')\n",
    "e_forms = list(df_lexicon_form_e.lemma)\n",
    "no_final_e_condition = df_filter(df_corpus[\"word 1\"], query=set(e_forms), method=\"isin\")\n",
    "result_df = df_corpus[ no_final_e_condition ]\n",
    "display_df( result_df )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look up inflected forms and spelling variants for a given lemma in a corpus <a class=\"anchor\" id=\"inflected-spelling-corpus\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T16:33:21.742176Z",
     "start_time": "2019-03-06T16:33:19.586Z"
    }
   },
   "outputs": [],
   "source": [
    "from chaininglib.ui.dfui import display_df\n",
    "from chaininglib.search.CorpusQuery import *\n",
    "from chaininglib.search.LexiconQuery import *\n",
    "\n",
    "# Corpus Gysseling and lexicon mnwlex are from same period: 1250-1550\n",
    "lexicon_to_search=\"mnwlex\"\n",
    "corpus_to_search=\"gysseling\"\n",
    "\n",
    "##############################################\n",
    "# TODO  zelfde met meerdere lemmata en gegroepeerd \n",
    "##############################################\n",
    "\n",
    "lemma_to_look_for=\"denken\"\n",
    "\n",
    "# LEXICON: Search for the inflected forms of a lemma in a morphosyntactic lexicon\n",
    "lq = create_lexicon(lexicon_to_search).lemma(lemma_to_look_for).search()\n",
    "df_lexicon = lq.kwic()\n",
    "display_df(df_lexicon)\n",
    "\n",
    "# Put all inflected forms into a list\n",
    "inflected_wordforms = list(df_lexicon.wordform)\n",
    "\n",
    "# CORPUS: Look up the inflected forms in a (possibly unannotated) corpus\n",
    "# beware: If the corpus is not annotated, all we can do is searching for the inflected words\n",
    "#         But if the corpus is lemmatized, we have to make sure we're retrieving correct data by specifying the lemma as well\n",
    "annotated_corpus = True\n",
    "query = r'[lemma=\"'+lemma_to_look_for+r'\" & word=\"'+r\"|\".join(inflected_wordforms)+r'\"]' if annotated_corpus else r'[word=\"'+r\"|\".join(inflected_wordforms)+r'\"]'\n",
    "cq = create_corpus(corpus_to_search).pattern(query).search()\n",
    "df_corpus = cq.kwic() \n",
    "display_df(df_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus frequency list of word forms from lexicon with given lemma <a class=\"anchor\" id=\"corpus-frequency-lemma-pos\"></a>\n",
    "Build a function with which we can gather all word forms for a lemma from a lexicon, and use that function to build a frequency list of those lemmata in a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T17:02:10.420299Z",
     "start_time": "2019-03-06T17:02:09.804448Z"
    }
   },
   "outputs": [],
   "source": [
    "from chaininglib.search.LexiconQuery import *\n",
    "from chaininglib.search.CorpusQuery import *\n",
    "from chaininglib.process.corpus import get_frequency_list\n",
    "from chaininglib.ui.dfui import display_df\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# build a function as required. We will run it afterwards\n",
    "\n",
    "def get_frequency_list_given_a_corpus(lexicon, lemma, corpus):\n",
    "    \n",
    "    # LEXICON: get a lemmata list to work with\n",
    "\n",
    "    # query the lexicon\n",
    "    lq = create_lexicon(lexicon).lemma(lemma).search()\n",
    "    df_lexicon = lq.kwic()\n",
    "\n",
    "    # Put the results into an array, so we can loop through the found lemmata\n",
    "    lexicon_wordforms_arr = [w.lower() for w in df_lexicon[\"wordform\"]]\n",
    "    print(lexicon_wordforms_arr)\n",
    "    # Instantiate a DataFrame, in which we will gather all single wordform occurences\n",
    "    df_full_list = pd.DataFrame()\n",
    "\n",
    "\n",
    "    # CORPUS: loop through the wordforms list, query the corpus with each wordform, and count the results\n",
    "\n",
    "    # It's a good idea to query more than one wordform at at the time,\n",
    "    # but not too many, otherwise the server will get overloaded!\n",
    "    nr_of_wordforms_to_query_atonce = 100\n",
    "\n",
    "    # loop over wordforms list \n",
    "    for i in range(0, len(lexicon_wordforms_arr), nr_of_wordforms_to_query_atonce):\n",
    "        \n",
    "        # slice to small array of lemmata to query at once\n",
    "        small_wordforms_arr = lexicon_wordforms_arr[i : i+nr_of_wordforms_to_query_atonce] \n",
    "\n",
    "        # join set of wordforms to send them in a query all at once\n",
    "        # beware: single quotes need escaping\n",
    "        wordforms_list = \"|\".join(small_wordforms_arr).replace(\"'\", \"\\\\\\\\'\")\n",
    "        cq = create_corpus(corpus).pattern(r'[word=\"' + wordforms_list + r'\"]').search()\n",
    "        df_corpus = cq.kwic()\n",
    "\n",
    "        # add the results to the full list\n",
    "        print(df_corpus)\n",
    "        df_full_list = pd.concat( [df_full_list, df_corpus[\"word 0\"]] )     \n",
    "        \n",
    "\n",
    "    # make sure the columnswith contains the wordforms is same as given to get_frequency_list function\n",
    "    column_name=\"word\"\n",
    "    df_full_list.columns = [column_name]\n",
    "\n",
    "    # we're done with querying, build the frequency list now\n",
    "    freq_df = get_frequency_list(df_full_list, column_name=column_name)\n",
    "\n",
    "    return freq_df\n",
    "\n",
    "    \n",
    "# run it!\n",
    "# Corpus Gysseling and lexicon mnwlex are from same period: 1250-1550\n",
    "lexicon=\"mnwlex\"\n",
    "corpus_to_search=\"gysseling\"\n",
    "lemma=\"vader\"\n",
    "\n",
    "freq_df = get_frequency_list_given_a_corpus(lexicon, lemma, corpus_to_search)\n",
    "\n",
    "display_df(freq_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a frequency table of some corpus, based on word forms list of a given lexicon <a class=\"anchor\" id=\"freqtable-lemmalist\"></a>\n",
    "For this case study, you need to run the previous case study first, because it generates a function we need here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T17:07:09.638407Z",
     "start_time": "2019-03-06T17:07:01.867635Z"
    }
   },
   "outputs": [],
   "source": [
    "from chaininglib.utils.dfops import get_rank_diff\n",
    "from chaininglib.ui.dfui import display_df\n",
    "\n",
    "# For this case study, you need to run the previous case study first, because it generates a function we need here\n",
    "\n",
    "# Use lexica and corpora from same period\n",
    "base_lexicon1=\"mnwlex\"\n",
    "corpus_to_search1=\"gysseling\"\n",
    "\n",
    "base_lexicon2=\"lexicon_service_db\"\n",
    "corpus_to_search1=\"zeebrieven\"\n",
    "\n",
    "lemma=\"het\"\n",
    "\n",
    "# build frequency tables of two corpora\n",
    "\n",
    "df_frequency_list1 = get_frequency_list_given_a_corpus(base_lexicon1, lemma, corpus_to_search1)\n",
    "# sort and display\n",
    "df_top25_descending = df_frequency_list1.sort_values(ascending=False,by=['token count']).head(25)\n",
    "df_top25_ascending =  df_frequency_list1.sort_values(ascending=True, by=['rank']).head(25)\n",
    "display_df( df_top25_ascending )\n",
    "print(type(df_top25_descending['token count']))\n",
    "display_df( df_top25_descending['token count'], labels='chart df1', mode='chart' )\n",
    "\n",
    "df_frequency_list2 = get_frequency_list_given_a_corpus(base_lexicon2, lemma, corpus_to_search2)\n",
    "# sort and display\n",
    "df_top25_descending = df_frequency_list2.sort_values(ascending=False,by=['token count']).head(25)\n",
    "df_top25_ascending =  df_frequency_list2.sort_values(ascending=True, by=['rank']).head(25)\n",
    "display_df( df_top25_ascending )\n",
    "display_df( df_top25_descending['token count'], labels='chart df2', mode='chart' )\n",
    "\n",
    "\n",
    "# TODO: lemmata tonen die in 1 of 2 ontbreken\n",
    "\n",
    "# compute the rank diff of lemmata in frequency tables\n",
    "\n",
    "# sort and display\n",
    "df_rankdiffs = get_rank_diff(df_frequency_list1, df_frequency_list2)\n",
    "\n",
    "display_df(df_rankdiffs.sort_values(by=['rank_diff']).head(25))\n",
    "\n",
    "df_top25_descending = df_rankdiffs.sort_values(ascending=False, by=['rank_diff']).head(25)\n",
    "display_df( df_top25_descending['rank_diff'], labels='chart large diff', mode='chart' )\n",
    "\n",
    "df_top25_ascending = df_rankdiffs.sort_values(ascending=True, by=['rank_diff']).head(25)\n",
    "display_df( df_top25_ascending['rank_diff'], labels='chart small diff', mode='chart' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search corpus for wordforms of lemma not included in lexicon <a class=\"anchor\" id=\"corpus-wordforms-not-lexicon\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T17:09:38.260298Z",
     "start_time": "2019-03-06T17:09:38.236906Z"
    }
   },
   "outputs": [],
   "source": [
    "from chaininglib.search.LexiconQuery import *\n",
    "from chaininglib.search.CorpusQuery import *\n",
    "from chaininglib.ui.dfui import display_df\n",
    "\n",
    "# Let's build a function to do the job:\n",
    "# The function will require a lexicon name and a part-of-speech to limit the search to, and the name of a corpus to be searched.\n",
    "# It will return a Pandas DataFrame associating lemmata to their paradigms ('known_wordforms' column) and\n",
    "# missing wordforms found in the corpus ('unknown_wordforms' column).\n",
    "\n",
    "def get_missing_wordforms(lexicon_lemmas, lexicon_wordforms, lexicon_pos, corpus_pos, corpus):    \n",
    "    \n",
    "    print('Finding missing wordforms in a lexicon can take a long time...');\n",
    "    \n",
    "    # LEXICON: \n",
    "    # get a lemmata list having a given part-of-speech\n",
    "    \n",
    "    lq = create_lexicon(lexicon_lemmas).pos(lexicon_pos).search()\n",
    "    df_lexicon = lq.kwic()\n",
    "    \n",
    "    # Put the results into an array, so we can loop through the list of lemmata\n",
    "    lexicon_lemmata_arr = [w.lower() for w in df_lexicon[\"wordform\"]]\n",
    "    \n",
    "    # Test array, instead of querying Molex\n",
    "    #lexicon_lemmata_arr = [\"denken\", \"doen\", \"hebben\", \"maken\"]\n",
    "    \n",
    "    # Prepare the output:\n",
    "    # instantiate a DataFrame for storing lemmata and mssing wordforms\n",
    "    df_enriched_lexicon = pd.DataFrame(index=lexicon_lemmata_arr, columns=['lemma', 'pos', 'known_wordforms', 'unknown_wordforms'])\n",
    "    df_enriched_lexicon.index.name = 'lemmata'\n",
    "    \n",
    "    # CORPUS: \n",
    "    # loop through the lemmata list, query the corpus for each lemma, \n",
    "    # and compute paradigms differences between both\n",
    "\n",
    "    \n",
    "    # loop through the lemmata list\n",
    "    # and query the corpus for occurances of the lemmata\n",
    "    \n",
    "    # It's a good idea to work with more than one lemma at the time (speed)!\n",
    "    nr_of_lemmata_to_query_atonce = 100\n",
    "    \n",
    "    for i in range(0, len(lexicon_lemmata_arr), nr_of_lemmata_to_query_atonce):\n",
    "        \n",
    "        # slice to small array of lemmata to query at once\n",
    "        small_lemmata_arr = lexicon_lemmata_arr[i : i+nr_of_lemmata_to_query_atonce]\n",
    "        \n",
    "        # join set of lemmata to send them in a query all at once\n",
    "        # beware: single quotes need escaping\n",
    "        lemmata_list = \"|\".join(small_lemmata_arr).replace(\"'\", \"\\\\\\\\'\")\n",
    "        print(lemmata_list)\n",
    "        cq = create_corpus(corpus).pattern(r'[lemma=\"' + lemmata_list + r'\" & pos=\"'+corpus_pos+'\"]').search()\n",
    "        df_corpus = cq.kwic()\n",
    "        \n",
    "        # if the corpus gave results,\n",
    "        # query the lexicon for the same lemmata\n",
    "        # and compare the paradigms!\n",
    "        \n",
    "        if (len(df_corpus)>0):\n",
    "            small_lemmata_set = set(small_lemmata_arr)\n",
    "            for one_lemma in small_lemmata_set: \n",
    "                print(one_lemma)\n",
    "                # look up the known wordforms in the lexicon\n",
    "                ql = create_lexicon(lexicon_wordforms).lemma(one_lemma).search()\n",
    "                df_known_wordforms = ql.kwic()\n",
    "                \n",
    "                # we have a lexicon paradigm to compare, do the job now\n",
    "                if (len(df_known_wordforms) != 0):\n",
    "                    \n",
    "                    # gather the lexicon wordforms in a set\n",
    "                    known_wordforms = set( df_known_wordforms['wordform'].str.lower() )\n",
    "                    \n",
    "                    # gather the corpus wordforms (of the same lemma) in a set too\n",
    "                    corpus_lemma_filter = (df_corpus['lemma 0'] == one_lemma)\n",
    "                    corpus_wordforms = set( (df_corpus[ corpus_lemma_filter ])['word 0'].str.lower() )\n",
    "                    \n",
    "                    # Now compute the differences:\n",
    "                    # gather in a set all the corpus wordforms that cannot be found in the lexicon wordforms \n",
    "                    unknown_wordforms = corpus_wordforms.difference(known_wordforms)\n",
    "\n",
    "                    # If we found some missing wordforms, add the results to the output!\n",
    "                    \n",
    "                    if (len(unknown_wordforms) !=0):                        \n",
    "                        # The index of our results will be a key consisting of lemma + part-of-speech\n",
    "                        # Part-of-speech is needed to distinguish homonyms with different grammatical categories.\n",
    "                        # Of course, we need to take glosses into account too to do a truely correct job\n",
    "                        # But we didn't do it here\n",
    "                        key = one_lemma + lexicon_pos\n",
    "                        df_enriched_lexicon.at[key, 'lemma'] = one_lemma\n",
    "                        df_enriched_lexicon.at[key, 'pos'] = lexicon_pos\n",
    "                        df_enriched_lexicon.at[key, 'known_wordforms'] = known_wordforms\n",
    "                        df_enriched_lexicon.at[key, 'unknown_wordforms'] = unknown_wordforms\n",
    "                \n",
    "    # return non-empty results, t.i. cases in which we found some wordforms\n",
    "    return df_enriched_lexicon[ df_enriched_lexicon['unknown_wordforms'].notnull() ]\n",
    "\n",
    "\n",
    "# Run the function!\n",
    "\n",
    "lexicon_lemmas=\"molex\"\n",
    "lexicon_wordforms=\"lexicon_service_db\"\n",
    "corpus_to_search=\"zeebrieven\"\n",
    "\n",
    "lemma=\"boek\"\n",
    "\n",
    "df = get_missing_wordforms(lexicon_lemmas, lexicon_wordforms, \"VERB\", \"VRB\", corpus_to_search)\n",
    "\n",
    "# After such a heavy process, it's a good idea to save the results\n",
    "\n",
    "df.to_csv( \"missing_wordforms.csv\", index=False)\n",
    "\n",
    "display_df(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treebanks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treebank search <a class=\"anchor\" id=\"treebank-search\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T16:33:21.746920Z",
     "start_time": "2019-03-06T16:33:19.600Z"
    }
   },
   "outputs": [],
   "source": [
    "from chaininglib.search.TreebankQuery import *\n",
    "\n",
    "\n",
    "print (\"search...\")\n",
    "\n",
    "tbq = create_treebank().pattern(\"xquery //node[@cat='pp' and node[@cat='ap' and node[@cat='np']]]\").search()\n",
    "\n",
    "print (\"get XML...\")\n",
    "\n",
    "xml = tbq.xml()\n",
    "print(xml)\n",
    "\n",
    "print (\"get trees and their string representations...\")\n",
    "\n",
    "trees = tbq.trees()\n",
    "\n",
    "for tree in trees:\n",
    "    display(tree.toString())\n",
    "\n",
    "df = tbq.kwic()\n",
    "    \n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which kind of nouns are used in a prepositional complement of the verb *geven* ? <a class=\"anchor\" id=\"treebank-objects-geven\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T16:33:21.748403Z",
     "start_time": "2019-03-06T16:33:19.603Z"
    }
   },
   "outputs": [],
   "source": [
    "from chaininglib.search.TreebankQuery import *\n",
    "\n",
    "\n",
    "print (\"search...\")\n",
    "\n",
    "tbq = create_treebank().pattern(r'xquery //node[node[@rel=\"hd\" and @pt=\"ww\" and @root=\"geven\"] and node[@rel=\"obj1\" and @pt=\"n\"]]').search()\n",
    "\n",
    "\n",
    "print (\"get list of nouns which are part of an PP, as argument of predicate 'geven'...\")\n",
    "\n",
    "trees = tbq.trees()\n",
    "\n",
    "list_of_nouns = []\n",
    "for tree in trees:\n",
    "    nouns = tree.extract(['pp', 'np'])\n",
    "    list_of_nouns = list_of_nouns + nouns\n",
    "    \n",
    "\n",
    "display(list_of_nouns)\n",
    "    \n",
    "df = tbq.kwic(align_lemma='geven')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
