# Chaining search installation

# in Linux

Create virtual environment
In the virtual environment, local copies of all Python dependencies will be installed. 
Install venv for python3, eg. on Ubuntu:
```
$ sudo apt install python3-venv
```

Create and activate virtual environment:
```
$ python3 -m venv cs_env
$ source cs_env/bin/activate
```

Install dependencies inside virtual environment
```
pip install -r requirements.txt
jupyter contrib nbextension install --sys-prefix
jupyter nbextensions_configurator enable --sys-prefix
python3 -m ipykernel install --user --name cs_env
```

Run Jupyter notebook
```
jupyter notebook
```

-----------------------------------------------

# in Windows

Download the Python-installer from https://www.python.org/
Install!
When the installer asks, tell it to add Python to PATH

Upgrade the Python Package Installer (PIP)
```
python -m pip install -U pip
```

Create and activate virtual environment:
```
pip install virtualenv
cd <project location>
virtualenv env
.\env\Scripts\activate.bat
```

Install dependencies inside virtual environment
```
pip install ipykernel
ipython kernel install --user --name=cs_env
pip3 install -r requirements.txt
```

Run Jupyter notebook
```
jupyter notebook
```


-----------------------------------------------
######################################
# API
######################################

######################################
## Corpus search
######################################

+==========================================================================
! create_corpus_ui()
+==========================================================================
! Output: N/A
!
! Build a GUI for corpus search
+--------------------------------------------------------------------------

+==========================================================================
! search_corpus_allwords(corpus_name TEXT)
+==========================================================================
! Output: dataframe
!
! Get all words of a corpus, given a corpus name
!
! Example:
! df_corpus = search_corpus_allwords("gysseling")
! display(df_corpus)
+--------------------------------------------------------------------------

+==========================================================================
! search_corpus(query TEXT, corpus_name TEXT)
+==========================================================================
! Output: dataframe
!
! Search a corpus given a query  (generated by corpus_query_lemma() or such)
! and a corpus name
!
! Example:
! df_corpus = search_corpus(r'[pos="ADJ"][word="huis"]', "chn")
! display(df_corpus)
+--------------------------------------------------------------------------

+==========================================================================
! search_corpus_multiple(queries, corpus_name TEXT)
+==========================================================================
! Output: dictionary, associating corpus names (key) to dataframes (values)
!
! Perform multiple corpus searches and store the results into a dictionary
+--------------------------------------------------------------------------

+==========================================================================
! corpus_query_lemma(word TEXT)
+==========================================================================
! Output: corpus query string
!
! Build the query for getting occurances of a given lemma within a given corpus
!
! Example:
! lemma_query = corpus_query_lemma("lopen")
! df_corpus = search_corpus(lemma_query, "chn")
! display(df_corpus)
+--------------------------------------------------------------------------



######################################
## Lexicon search
######################################

+==========================================================================
! create_lexicon_ui()
+==========================================================================
! Output: N/A
!
! Build a GUI for lexicon search
+--------------------------------------------------------------------------

+==========================================================================
! search_lexicon_allwords(lexicon_name TEXT)
+==========================================================================
! Output: N/A
!
! Get all words of a lexicon, given its name
+--------------------------------------------------------------------------

+==========================================================================
! search_lexicon(query TEXT, lexicon_name TEXT)
+==========================================================================
! Output: dataframe
!
! Search a lexicon, given a query (generated by lexicon_query() or such)
! and lexicon name
+--------------------------------------------------------------------------

+==========================================================================
! lexicon_query(word TEXT, pos TEXT, lexicon_name TEXT)
+==========================================================================
! Output: query string
!
! Build the query for getting the paradigm etc. of a given lemma in a given lexicon
! The resulting query string is to be used as a parameter of search_lexicon() 
+--------------------------------------------------------------------------

+==========================================================================
! lexicon_query_allwords(lexicon_name TEXT)
+==========================================================================
! Output: query string
!
! Build the query for getting all words of a given lexicon
! The resulting query string is to be used as a parameter of search_lexicon() 
+--------------------------------------------------------------------------



######################################
## Processing methods
######################################

+==========================================================================
! _parse_xml(text)
+==========================================================================
! Output: dataframe
!
! Convert the XML output of a lexicon or corpus search
! into a dataframe for further processing
+--------------------------------------------------------------------------

+==========================================================================
! column_difference(df_column1 TEXT, df_column2 TEXT)
+==========================================================================
! Output: 	[1] array of words only in df_column1
! 			[2] array of words only in df_column2
! 			[3] array of words both in df_column1 and df_column2
!
! Compute differences and similarities between two dataframes
+--------------------------------------------------------------------------

+==========================================================================
! diamant_get_synonyms(df)
+==========================================================================
! Output: a set of lemmata OR a set of synonym definitions
!
! Get lemmata or definitions out of a dataframe filled with Diamant data
! The output set content depends on the result type
+--------------------------------------------------------------------------


+==========================================================================
! get_frequency_list(lexicon TEXT, pos TEXT, corpus TEXT)
+==========================================================================
! Output: a dataframes with lemmata (index) and frequencies (column)
!
! Build a lemmata frequency list of a corpus, 
! given a lexicon (for obvious reasons limited to some part-of-speech).
+--------------------------------------------------------------------------


+==========================================================================
! get_rank_diff(df1 DATAFRAME, df2 DATAFRAME)
+==========================================================================
! Output: a dataframes with lemmata (index), ranks of both input dataframes, 
! and the rank_diff.
!
! Compare the ranks of words in two dataframes, 
! and compute a rank_diff
+--------------------------------------------------------------------------


+==========================================================================
! display_df_chart(df1 DATAFRAME, column TEXT, title TEXT)
+==========================================================================
! Output: N/A 
!
! Draw a horizontal chart representing a dataframe.
! One axis is the index of the dataframe, and the other axis
! is the given column, which holds the values to plot in the chart.
+--------------------------------------------------------------------------


######################################
## Saving dataframes and re-loading those
###################################### 

+==========================================================================
! create_save_dataframe_ui(dataframe)
+==========================================================================
! Output: N/A
!
! Build a GUI for saving the results of some lexicon or corpus query to a 
! CSV file.
! Use load_dataframe(filepath) to reload the results later on.
+--------------------------------------------------------------------------

+==========================================================================
! load_dataframe(filepath)
+==========================================================================
! Output: dataframe
!
! (Re)load some dataframe previously saved
+--------------------------------------------------------------------------


######################################
## Show dataframe content
######################################

+==========================================================================
! view_multiple_results(dataframes DICTIONARY, labels ARRAY)
+==========================================================================
! Output: N/A
!
! Show the content of multiple dataframes out of an dictionary associating 
! labels (eg. corpus or lexicon names) to dataframes (values)
+--------------------------------------------------------------------------



######################################
## Utilities
######################################

+==========================================================================
! containsRegex(word TEXT)
+==========================================================================
! Output: boolean
!
! Check if some string contains a regular expression
+--------------------------------------------------------------------------


