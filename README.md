# Chaining search installation

# in Linux

Create virtual environment
In the virtual environment, local copies of all Python dependencies will be installed. 
Install venv for python3, eg. on Ubuntu:
```
$ sudo apt install python3-venv
```

Create and activate virtual environment:
```
$ python3 -m venv cs_env
$ source cs_env/bin/activate
```

Install dependencies inside virtual environment
```
pip install -r requirements.txt
jupyter contrib nbextension install --sys-prefix
jupyter nbextensions_configurator enable --sys-prefix
python3 -m ipykernel install --user --name cs_env
```

Run Jupyter notebook
```
jupyter notebook
```

-----------------------------------------------

# in Windows

## Step 1

First download the code of this project. To do so, click on the 'Clone or download' button on top of the github project page. Click on 'Download ZIP' and save the file to the location of your choice.

Open the Windows explorer, browse to the file location, and unzip the file. 

Then browse the unzipped folder till you find the 'Chaining search.ipynb' file. Copy its exact location (full path): you will need it later on.

## Step  2

Download the Python-installer from https://www.python.org/  

Install!

When the installer asks, tell it to add Python to PATH

## Step  3

Now, open a Command prompt window. To do so, press keys Windows+R and then type 'cmd' (and press enter).

In the Command prompt window, upgrade the Python Package Installer (PIP) by typing:
```
python -m pip install -U pip
```

Still in the Command prompt window, create the virtual environment:
```
pip install virtualenv
```
Switch to the folder where you unzipped the project code (your copied that location at the beginning):

```
cd <project location>
```

Now you're ready to activate the virtual environment. Type:
```
virtualenv env
.\env\Scripts\activate.bat
```

As a final step in the Command prompt, install the dependencies:
```
pip install ipykernel
ipython kernel install --user --name=cs_env
pip3 install -r requirements.txt
``` 

## Step  4

Run the Jupyter notebook!
```
jupyter notebook
```

Done!


## Next sessions

You're done with installing. So, in the next sessions, restarting the notebook will be easy!

Open a Command prompt window (press keys Windows+R and then type 'cmd', remember?).
Then go to the project folder (fill in the right path here):

```
cd <project location>
```

Activate the virtual environment:
```
.\env\Scripts\activate.bat
```

Run the Jupyter notebook!
```
jupyter notebook
```

-----------------------------------------------
######################################
# API
######################################

######################################
## Corpus search
######################################

+==========================================================================
! create_corpus_ui()
+==========================================================================
! Output: N/A
!
! Build a GUI for corpus search
+--------------------------------------------------------------------------

+==========================================================================
! search_corpus_allwords(corpus_name TEXT)
+==========================================================================
! Output: dataframe
!
! Get all words of a corpus, given a corpus name
!
! Example:
! df_corpus = search_corpus_allwords("gysseling")
! display(df_corpus)
+--------------------------------------------------------------------------

+==========================================================================
! search_corpus(query TEXT, corpus_name TEXT)
+==========================================================================
! Output: dataframe
!
! Search a corpus given a query  (generated by corpus_query_lemma() or such)
! and a corpus name
!
! Example:
! df_corpus = search_corpus(r'[pos="ADJ"][word="huis"]', "chn")
! display(df_corpus)
+--------------------------------------------------------------------------

+==========================================================================
! search_corpus_multiple(queries, corpus_name TEXT)
+==========================================================================
! Output: dictionary, associating corpus names (key) to dataframes (values)
!
! Perform multiple corpus searches and store the results into a dictionary
+--------------------------------------------------------------------------

+==========================================================================
! corpus_query_lemma(word TEXT)
+==========================================================================
! Output: corpus query string
!
! Build the query for getting occurances of a given lemma within a given corpus
!
! Example:
! lemma_query = corpus_query_lemma("lopen")
! df_corpus = search_corpus(lemma_query, "chn")
! display(df_corpus)
+--------------------------------------------------------------------------



######################################
## Lexicon search
######################################

+==========================================================================
! create_lexicon_ui()
+==========================================================================
! Output: N/A
!
! Build a GUI for lexicon search
+--------------------------------------------------------------------------

+==========================================================================
! search_lexicon_allwords(lexicon_name TEXT)
+==========================================================================
! Output: N/A
!
! Get all words of a lexicon, given its name
+--------------------------------------------------------------------------

+==========================================================================
! search_lexicon(query TEXT, lexicon_name TEXT)
+==========================================================================
! Output: dataframe
!
! Search a lexicon, given a query (generated by lexicon_query() or such)
! and lexicon name
+--------------------------------------------------------------------------

+==========================================================================
! lexicon_query(word TEXT, pos TEXT, lexicon_name TEXT)
+==========================================================================
! Output: query string
!
! Build the query for getting the paradigm etc. of a given lemma in a given lexicon
! The resulting query string is to be used as a parameter of search_lexicon() 
+--------------------------------------------------------------------------

+==========================================================================
! lexicon_query_allwords(lexicon_name TEXT)
+==========================================================================
! Output: query string
!
! Build the query for getting all words of a given lexicon
! The resulting query string is to be used as a parameter of search_lexicon() 
+--------------------------------------------------------------------------



######################################
## Processing methods
######################################

+==========================================================================
! _parse_xml(text)
+==========================================================================
! Output: dataframe
!
! Convert the XML output of a lexicon or corpus search
! into a dataframe for further processing
+--------------------------------------------------------------------------

+==========================================================================
! column_difference(df_column1 TEXT, df_column2 TEXT)
+==========================================================================
! Output: 	[1] array of words only in df_column1
! 			[2] array of words only in df_column2
! 			[3] array of words both in df_column1 and df_column2
!
! Compute differences and similarities between two dataframes
+--------------------------------------------------------------------------

+==========================================================================
! diamant_get_synonyms(df)
+==========================================================================
! Output: a set of lemmata OR a set of synonym definitions
!
! Get lemmata or definitions out of a dataframe filled with Diamant data
! The output set content depends on the result type
+--------------------------------------------------------------------------


+==========================================================================
! get_frequency_list(lexicon TEXT, pos TEXT, corpus TEXT)
+==========================================================================
! Output: a dataframes with lemmata (index) and frequencies (column)
!
! Build a lemmata frequency list of a corpus, 
! given a lexicon (for obvious reasons limited to some part-of-speech).
+--------------------------------------------------------------------------


+==========================================================================
! get_rank_diff(df1 DATAFRAME, df2 DATAFRAME)
+==========================================================================
! Output: a dataframes with lemmata (index), ranks of both input dataframes, 
! and the rank_diff.
!
! Compare the ranks of words in two dataframes, 
! and compute a rank_diff
+--------------------------------------------------------------------------


+==========================================================================
! display_df_chart(df1 DATAFRAME, column TEXT, title TEXT)
+==========================================================================
! Output: N/A 
!
! Draw a horizontal chart representing a dataframe.
! One axis is the index of the dataframe, and the other axis
! is the given column, which holds the values to plot in the chart.
+--------------------------------------------------------------------------


######################################
## Saving dataframes and re-loading those
###################################### 

+==========================================================================
! create_save_dataframe_ui(dataframe)
+==========================================================================
! Output: N/A
!
! Build a GUI for saving the results of some lexicon or corpus query to a 
! CSV file.
! Use load_dataframe(filepath) to reload the results later on.
+--------------------------------------------------------------------------

+==========================================================================
! load_dataframe(filepath)
+==========================================================================
! Output: dataframe
!
! (Re)load some dataframe previously saved
+--------------------------------------------------------------------------


######################################
## Show dataframe content
######################################

+==========================================================================
! view_multiple_results(dataframes DICTIONARY, labels ARRAY)
+==========================================================================
! Output: N/A
!
! Show the content of multiple dataframes out of an dictionary associating 
! labels (eg. corpus or lexicon names) to dataframes (values)
+--------------------------------------------------------------------------



######################################
## Utilities
######################################

+==========================================================================
! containsRegex(word TEXT)
+==========================================================================
! Output: boolean
!
! Check if some string contains a regular expression
+--------------------------------------------------------------------------


